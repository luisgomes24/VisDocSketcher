{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b44e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8dd21",
   "metadata": {},
   "source": [
    "<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #008080;\"><b style=\"color:white;\">Crotalus horridus. A RattleSnake!</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf89ba",
   "metadata": {},
   "source": [
    "\"The timber rattlesnake, canebrake rattlesnake, or banded rattlesnake (Crotalus horridus) is a species of venomous, sometimes highly venomous, pit viper endemic to eastern North America. This is the only rattlesnake species in most of the populous Northeastern United States and is second only to its relatives to the west, the prairie rattlesnake, as the most northerly distributed venomous snake in North America. No subspecies are currently recognized.\"\n",
    "\n",
    "\"The timber rattlesnake was one of the many reptile species originally described by Carl Linnaeus in the landmark 1758 10th edition of his Systema Naturae, and still bears its original name Crotalus horridus.\"\n",
    "\n",
    "https://en.wikipedia.org/wiki/Timber_rattlesnake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506f846",
   "metadata": {},
   "source": [
    "#All script by Ting Liu https://www.kaggle.com/code/tingtingliuliu/kernel59f18a2057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751242f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = glob.glob('../input/snakeclef2022/SnakeCLEF2022-medium_size/SnakeCLEF2022-medium_size/1999/Crotalus_horridus/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f675f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "img = tf.keras.preprocessing.image.load_img(random.choice(imgs_path))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0abe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jpg(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b32158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32)/127.5 - 1\n",
    "    input_mask = tf.cast(input_mask, tf.float32)/127.5 - 1\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ed574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = read_jpg(image_path)\n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    input_image = image[:, :w, :]\n",
    "    input_mask = image[:, w:, :]\n",
    "    input_image = tf.image.resize(input_image, (256, 256))\n",
    "    input_mask = tf.image.resize(input_mask, (256, 256))\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_mask, input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a87bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bbe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for img, musk in train_dataset.take(1):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(img[0]))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(musk[0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We don't have validation file\n",
    "#imgs_path_test = glob.glob('../input/anime-sketch-colorization-pair/data/val/*.png')\n",
    "imgs_path_test = glob.glob('../input/snakeclef2022/SnakeCLEF2022-small_size/SnakeCLEF2022-small_size/1999/Crotalus_horridus/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices(imgs_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e29dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(image_path):\n",
    "    image = read_jpg(image_path)\n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    input_image = image[:, :w, :]\n",
    "    input_mask = image[:, w:, :]\n",
    "    input_image = tf.image.resize(input_image, (256, 256))\n",
    "    input_mask = tf.image.resize(input_mask, (256, 256))\n",
    "    \n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_mask, input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_test.map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c050ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, musk in dataset_test.take(1):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(img[0]))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(musk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "#    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                               use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "#    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "#    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "#    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False)(down3) # (bs, 32, 32, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same')(leaky_relu) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d500e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "#tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385259a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b38600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_input, example_target in dataset_test.take(1):\n",
    "    generate_images(generator, example_input, example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34973c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2586c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs+1):\n",
    "        if epoch%10 == 0:\n",
    "            for example_input, example_target in test_ds.take(1):\n",
    "                generate_images(generator, example_input, example_target)\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print('.', end='')\n",
    "            train_step(input_image, target, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(train_dataset, EPOCHS, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23c448",
   "metadata": {},
   "source": [
    "#Since Ting Liu didn't provide any (any at all) information about the steps we've performed, I (with my very poor skills) can only suppose that is a TF/Keras/ReLU/tanh activation/Adam Optimizer/CNN???  And RattleSnakes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e4bbe",
   "metadata": {},
   "source": [
    "#Acknowledgement:\n",
    "\n",
    "Ting Liu https://www.kaggle.com/code/tingtingliuliu/kernel59f18a2057"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
