{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bafaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/kaggle/input/tmdb-top-10000-popular-movies-dataset/TMDb_updated.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61885b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d751e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef580074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b11c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae90e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_language'].value_counts().head(5).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712660c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.groupby('original_language').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['vote_average']>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f194e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a41e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_overview=df['overview'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= example_overview.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2eedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "for i in texts:\n",
    "    text.append(i.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f894b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for word in text: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        words.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "stem = [] \n",
    "\n",
    "for word in words:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
