{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428c90a0",
   "metadata": {},
   "source": [
    "# Visual Search on OEBB\n",
    "Here we run visual search on a number of the OEBB examples using a number of hand-taken photos as the basis for identifying new, better photos in the full dataset.\n",
    "1. Create feature vectors for all of the iNovitas images along the track\n",
    "1. Create multi-scale feature vectors for all the images of important objects\n",
    "1. Match them on a few test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dir = '../input/extracting-obb-images/'\n",
    "img_zip = os.path.join(img_dir, 'images.zip')\n",
    "!unzip -q {img_zip} -d ../working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed in Kaggle, but required in Jupyter\n",
    "%matplotlib inline \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # showing and rendering figures\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "img_paths = {\n",
    "    int(os.path.basename(x).split('_')[0]): x\n",
    "    for x in \n",
    "    glob(os.path.join('..', 'working', '*.png'))\n",
    "}\n",
    "print('loaded', len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cffd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pd.read_csv(os.path.join(img_dir, 'image_subset.csv'))\n",
    "img_df.columns = ['idx', 'jnk'] + img_df.columns.tolist()[2:]\n",
    "img_df['local_path'] = img_df['idx'].map(img_paths.get)\n",
    "img_df.drop(['jnk'], axis=1, inplace=True)\n",
    "img_df.dropna(inplace=True)\n",
    "img_df = img_df.sample(8000).sort_values(['timecode'])\n",
    "print(img_df.shape)\n",
    "img_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3797b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, c_row in img_df.sample(5).iterrows():\n",
    "    print(c_row['local_path'], imread(c_row['local_path']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8882c5",
   "metadata": {},
   "source": [
    "## Specify the pretrained model to use\n",
    "Here we specify the pretrained model as well as the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6462639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "MIN_DIM_SIZE = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62973fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "IMG_SIZE = (336, 512) # slightly smaller than vgg16 normally expects\n",
    "core_idg = ImageDataGenerator(samplewise_center=False, \n",
    "                              samplewise_std_normalization=False, \n",
    "                              horizontal_flip = False, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.01, \n",
    "                              width_shift_range = 0.01, \n",
    "                              rotation_range = 0, \n",
    "                              shear_range = 0.00,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range=0.01,\n",
    "                             preprocessing_function = preprocess_input)\n",
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0815b",
   "metadata": {},
   "source": [
    "# Make our feature-encoding model\n",
    "This downloads the weights and calculates the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pretrained_model = PTModel(input_shape = (None, None)+(3,), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')\n",
    "feature_output_shape = base_pretrained_model.predict(np.zeros((1,)+IMG_SIZE+(3,))).shape[1:]\n",
    "print('Features Shape:', feature_output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8ca35",
   "metadata": {},
   "source": [
    "## Generate our feature database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7976ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "data_loops = 1\n",
    "MASTER_CROP_OFFSET = 4\n",
    "out_frame = []\n",
    "out_xy = []\n",
    "out_feat = []\n",
    "for scale_down_idx in range(1):\n",
    "    # make the images a multiple scales\n",
    "    scale_down = 2**scale_down_idx\n",
    "    train_gen = flow_from_dataframe(core_idg, img_df, \n",
    "                             path_col = 'local_path',\n",
    "                            y_col = 'idx', \n",
    "                            target_size = (IMG_SIZE[0]//scale_down, IMG_SIZE[1]//scale_down),\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                               shuffle = False)\n",
    "    CROP_OFFSET = MASTER_CROP_OFFSET//scale_down\n",
    "    for i, (c_x, c_idx) in zip(tqdm_notebook(range(data_loops*train_gen.n//train_gen.batch_size)), \n",
    "                            train_gen):\n",
    "        \n",
    "        c_y_vec = base_pretrained_model.predict(c_x)\n",
    "        frame_coords = np.arange(c_y_vec.shape[0])\n",
    "        x_coords = np.linspace(0, 1, c_y_vec.shape[1]+2*CROP_OFFSET)[CROP_OFFSET:-CROP_OFFSET]\n",
    "        y_coords = np.linspace(0, 1, c_y_vec.shape[2]+2*CROP_OFFSET)[CROP_OFFSET:-CROP_OFFSET]\n",
    "        fr_c, xx_c, yy_c = np.meshgrid(frame_coords, x_coords, y_coords, indexing = 'ij')\n",
    "        out_frame += [c_idx[fr_c.ravel()]]\n",
    "        out_xy += [np.stack([xx_c.ravel(), yy_c.ravel()], -1)]\n",
    "        out_feat += [c_y_vec.reshape((-1, c_y_vec.shape[-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_frame = np.concatenate(out_frame,0)\n",
    "out_xy = np.concatenate(out_xy, 0)\n",
    "out_feat = np.concatenate(out_feat,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6a9f3",
   "metadata": {},
   "source": [
    "# Load Signal Images\n",
    "Here we load a few signal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85312ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_img_dir = '../input/oebb-signal/'\n",
    "sig_images = {os.path.splitext(f)[0]: imread(os.path.join(base_path, f))[:, :, :3]\n",
    "     for base_path, _, files in os.walk(sig_img_dir) \n",
    "     for f in files\n",
    "    if os.path.splitext(f.upper())[1][1:] in ['JPG', 'PNG']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(3, 6, figsize = (20, 10))\n",
    "for c_ax, (c_id, c_img) in zip(m_axs.flatten(), sig_images.items()):\n",
    "    c_ax.imshow(c_img)\n",
    "    c_ax.set_title(c_id)\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84465f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = sig_images['Hauptsignal Ausleger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728598e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "def image_to_multiscale_features(in_img, scale_steps = 3):\n",
    "    img_prep = preprocess_input(in_img) \n",
    "    max_ds = np.floor(np.min(img_prep.shape[:2])/MIN_DIM_SIZE)\n",
    "    min_ds = np.ceil(np.max(img_prep.shape[:2])/np.min(IMG_SIZE))\n",
    "    c_vec = []\n",
    "    scale_vec = np.unique(np.linspace(min_ds, max_ds, scale_steps))\n",
    "    print(scale_vec)\n",
    "    for c_s in scale_vec:\n",
    "        c_tensor = np.expand_dims(zoom(img_prep, (1/c_s, 1/c_s, 1), order=2), 0)\n",
    "        c_feat = base_pretrained_model.predict(c_tensor)\n",
    "        c_feat = c_feat.reshape((-1, c_feat.shape[-1]))\n",
    "        c_vec += [c_feat]\n",
    "        c_vec += [np.mean(c_feat, 0, keepdims=True)] # global average pooling\n",
    "    return np.concatenate(c_vec, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec = image_to_multiscale_features(ref_img)\n",
    "print(ref_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99394461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_features(all_vecs, feat_db, comb_func = np.max):\n",
    "    \"\"\"\n",
    "    all_vecs are all of the image vectors from the current search query\n",
    "    feat_db is all of the vectors in the database\n",
    "    comb_func is the function to combine the scores of all the query vectors together\n",
    "     - np.max takes the best match in each image\n",
    "     - np.mean takes the best average match across multiple scales\n",
    "    \"\"\"\n",
    "    dot_score = []\n",
    "    for in_vec in all_vecs:\n",
    "        dot_score += [np.dot(feat_db, in_vec)]\n",
    "    # combine dot_scores\n",
    "    dot_score = np.stack(dot_score, 0)\n",
    "    dot_score = comb_func(dot_score, 0)\n",
    "    dot_score = dot_score/dot_score.max() # normalize by maximum score\n",
    "    return dot_score, np.argsort(-1*dot_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da879fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f_score, f_rank = compare_features(ref_vec, out_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg(in_img, in_reg):\n",
    "    x_dim, y_dim = in_img.shape[0], in_img.shape[1]\n",
    "    return in_img[int(x_dim*in_reg[0]):int(x_dim*in_reg[1]),\n",
    "                  int(y_dim*in_reg[2]):int(y_dim*in_reg[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676972a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches(query_img, rank_vec, score_vec, top_matches=5):\n",
    "    x_dim = 0.25\n",
    "    y_dim = x_dim*query_img.shape[1]/query_img.shape[0]\n",
    "    fig, m_axs = plt.subplots(top_matches, 3, figsize = (15, 6*top_matches))\n",
    "    for c_ax in m_axs.flatten():\n",
    "        c_ax.axis('off')\n",
    "    for k_idx, (ax_in, ax_full, ax_out) in zip(rank_vec, m_axs):\n",
    "        ax_in.imshow(query_img)\n",
    "        ax_in.set_title('Search Query')\n",
    "        c_frame = out_frame[k_idx]\n",
    "        c_x, c_y = out_xy[k_idx]\n",
    "        c_path = img_df[img_df['idx']==c_frame]['local_path'].values[0]\n",
    "        in_img = imread(c_path)\n",
    "        ax_full.imshow(in_img)\n",
    "        ax_full.set_title(c_path.split('/')[-2:])\n",
    "        cur_reg = (100*np.clip([c_x-x_dim, c_x+x_dim, c_y-y_dim, c_y+y_dim], 0, 1)).astype(int)/100\n",
    "        ax_out.imshow(get_reg(in_img, cur_reg))\n",
    "        ax_out.set_title('Score: {:2.1f}%\\n{}'.format(100*score_vec[k_idx], cur_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matches(ref_img, f_rank, f_score, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec847ba",
   "metadata": {},
   "source": [
    "# Combine all of the scores together\n",
    "Make a dataframe with all of the metadata and score information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_vec = {c_row['idx']: dict(**c_row) \n",
    "                   for _, c_row in img_df.iterrows()}\n",
    "score_df = pd.DataFrame([dict(**score_vec[f], score=s) for f, s in zip(out_frame, f_score)])\n",
    "score_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387137b",
   "metadata": {},
   "source": [
    "## Match to path\n",
    "Here we show the highest scoring positions on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_grp_df = score_df.groupby(['idx', 'easting', 'northing']).agg({'score': 'max'}).reset_index()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "cut_off = np.percentile(score_grp_df['score'], 99.5)\n",
    "below_df = score_grp_df[score_grp_df['score']<cut_off]\n",
    "above_df = score_grp_df[score_grp_df['score']>=cut_off]\n",
    "ax1.plot(below_df['easting'], below_df['northing'], 'b.-', alpha=0.2, label='Below')\n",
    "ax1.plot(above_df['easting'], above_df['northing'], 'rs', alpha=1, ms=10, label='Above')\n",
    "ax1.legend()\n",
    "ax2.hist(score_grp_df['score'], 30);\n",
    "ax2.axvline(cut_off, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdfc0a",
   "metadata": {},
   "source": [
    "# Run all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d68e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_vec_scores = {}\n",
    "for c_ref, c_ref_img in tqdm_notebook(sig_images.items()):\n",
    "    c_ref_vec = image_to_multiscale_features(c_ref_img)\n",
    "    sig_vec_scores[c_ref] = compare_features(c_ref_vec, out_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_ref, c_ref_img in tqdm_notebook(sig_images.items()):\n",
    "    cf_score, cf_rank = sig_vec_scores[c_ref] \n",
    "    plot_matches(c_ref_img, cf_rank, cf_score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5049fff",
   "metadata": {},
   "source": [
    "# Save Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf776de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up temporary files\n",
    "!rm -rf ../working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e83d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('search_index.h5', 'w') as f:\n",
    "    f.create_dataset('frame', data=out_frame, compression = 5)\n",
    "    f.create_dataset('xy_pos', data=out_xy, compression = 5)\n",
    "    f.create_dataset('features', data=out_feat, compression = 8)\n",
    "!ls -lh *.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83545aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_mat = [np.expand_dims(out_frame, -1), out_xy]\n",
    "col_name_mat = ['idx', 'img_x_pos', 'img_y_pos']\n",
    "for c_ref, c_ref_img in sig_images.items():\n",
    "    cf_score, cf_rank = sig_vec_scores[c_ref] \n",
    "    col_list_mat+=[np.expand_dims(cf_score, -1)]\n",
    "    col_name_mat+=['Match_Score_{}'.format(c_ref)]\n",
    "\n",
    "feature_map_df = pd.DataFrame(np.concatenate(col_list_mat, -1), \n",
    "                              columns=col_name_mat)\n",
    "feature_map_df['idx'] = feature_map_df['idx'].map(int)\n",
    "feature_map_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b698f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_space_df = pd.merge(img_df, feature_map_df, on='idx')\n",
    "img_space_df.sample(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e710744",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_space_df.to_csv('match_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
