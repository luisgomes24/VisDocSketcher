{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71f274",
   "metadata": {},
   "source": [
    "* **Needed Libraries**\n",
    "\n",
    "> Sequential provides us to add our layers with order.\n",
    "\n",
    "> In my model, I plan to use \n",
    "    1. Convolutional layers(CNN), \n",
    "    2. Maxpooling layers, \n",
    "    3. Activation layers, \n",
    "    4. Droupout Layers, \n",
    "    5. Fully Connected Layers.\n",
    "  \n",
    "> I need to make preprocessing to my data; therefore, I need to import ralated libraries, namely \n",
    "    1. ImageDataGenerator\n",
    "    2. img_to_array => convert image to array\n",
    "    3. load_img => to load image\n",
    "    \n",
    "> To plot and visualize the data and results, matplotlib.pyplot will be used. \n",
    "\n",
    "> To learn how many class I have, glob library will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image  import ImageDataGenerator, img_to_array,load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6f417",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f59df",
   "metadata": {},
   "source": [
    "**Our Train and Test Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b732ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/fruits/fruits-360/Training/\"\n",
    "test_path = \"/kaggle/input/fruits/fruits-360/Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c17286",
   "metadata": {},
   "source": [
    "> Lets look at one example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(train_path + \"Apple Golden 1/0_100.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.title(\"Apple Golden\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f59f8",
   "metadata": {},
   "source": [
    "**Shape of images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b10c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_image = img_to_array(img)\n",
    "print(shape_of_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8d8b0",
   "metadata": {},
   "source": [
    "**Number of Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd500a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob(train_path + \"/*\")\n",
    "number_of_class = len(classes)\n",
    "print(\"Number of class : \" , number_of_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ae405",
   "metadata": {},
   "source": [
    "# Data Generation - Train and Test\n",
    "\n",
    "> We may have not adequate image to train and test data to classify them. Therefore, we should generate more images with using our real data, namely images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                   shear_range = 0.3,\n",
    "                   horizontal_flip = True,\n",
    "                   zoom_range = 0.3)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                                   target_size = shape_of_image.shape[:2],\n",
    "                                                   batch_size = 32,\n",
    "                                                   color_mode = 'rgb',\n",
    "                                                   class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_path,\n",
    "                                                   target_size = shape_of_image.shape[:2],\n",
    "                                                   batch_size = 32,\n",
    "                                                   color_mode = 'rgb',\n",
    "                                                   class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4268c4",
   "metadata": {},
   "source": [
    "# Implementing CNN Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98e79d",
   "metadata": {},
   "source": [
    "**Initializing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84819dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b69a6",
   "metadata": {},
   "source": [
    "**3 Convolutional Layers and 3 Max Pooling Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),activation = 'relu', input_shape = shape_of_image.shape))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation = 'relu', input_shape = shape_of_image.shape))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu', input_shape = shape_of_image.shape))\n",
    "model.add(MaxPooling2D())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12db7",
   "metadata": {},
   "source": [
    "**Flatten process and Fully Conncected Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb37822",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cabf17b",
   "metadata": {},
   "source": [
    "> To learn different proporties of image, we use Dropout\n",
    "\n",
    "**Dropout and Output Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_class,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6e60f",
   "metadata": {},
   "source": [
    "**Compiling Our Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5c692",
   "metadata": {},
   "source": [
    "**Batch and its size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "number_of_batch = 1600 // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1480c23",
   "metadata": {},
   "source": [
    "**Fitting Our Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6848e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch = number_of_batch,\n",
    "    epochs = 100,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = 800 // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addbb8f",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa297bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"trial.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5384d",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a45919",
   "metadata": {},
   "source": [
    "> To evaluate our model, We can utilize graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0859ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())\n",
    "plt.plot(hist.history[\"loss\"],label = \"Train Loss\")\n",
    "plt.plot(hist.history[\"val_loss\"],label = \"Validaton Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7220ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history[\"accuracy\"],label = \"Train Accuracy\")\n",
    "plt.plot(hist.history[\"val_accuracy\"],label = \"Validaton Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75720d4",
   "metadata": {},
   "source": [
    "**Save History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"traial.json\",\"w\") as f:\n",
    "    json.dump(hist.history,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad1998",
   "metadata": {},
   "source": [
    "**Load History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "with codecs.open(\"traial.json\",\"r\",encoding = \"utf-8\") as f:\n",
    "    h = json.loads(f.read())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
