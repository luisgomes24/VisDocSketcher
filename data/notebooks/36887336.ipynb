{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39109a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5af961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/playground-series-s3e12/train.csv\", index_col='id').reset_index(drop=True)\n",
    "df_test = pd.read_csv(\"/kaggle/input/playground-series-s3e12/test.csv\", index_col='id').reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1).copy()\n",
    "y = df['target']\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X, y)\n",
    "plot_tree(model, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=2023)\n",
    "\n",
    "valid_preds_1 = []\n",
    "calcs_1 = []\n",
    "valid_targets_1 = []\n",
    "test_preds_1 = []\n",
    "losses = []\n",
    "\n",
    "rate = 0.0\n",
    "\n",
    "features = ['gravity', 'cond', 'calc']\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 2023,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.7,\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "for train_ind, valid_ind in kfold.split(X=df, y=df.target):\n",
    "    X_test = df_test.copy()\n",
    "    X_train = df.iloc[train_ind]\n",
    "    X_valid = df.iloc[valid_ind]\n",
    "    y_train = X_train.pop('target')\n",
    "    y_valid = X_valid.pop('target')\n",
    "    \n",
    "    X_train = X_train[features]\n",
    "    X_valid = X_valid[features]\n",
    "    X_test = X_test[features]\n",
    "    \n",
    "    X_train.loc[X_train.calc >= 9.5, 'calc'] = np.nan\n",
    "    X_valid.loc[X_valid.calc >= 9.5, 'calc'] = np.nan\n",
    "    X_test.loc[X_test.calc >= 9.5, 'calc'] = np.nan\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    train_preds = model.predict_proba(X_train)[:, 1]\n",
    "    valid_loss = roc_auc_score(y_valid, valid_preds)\n",
    "    train_loss = roc_auc_score(y_train, train_preds)\n",
    "    \n",
    "    rate = abs(train_loss - valid_loss)\n",
    "    \n",
    "    k = 0\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    k = 1\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    k = 2\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    print(\"Rate:\", rate)\n",
    "    print(f\"Previous Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Previous Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(f\"Previous Importance of {features[2]}: {feature_importances[2]}\")\n",
    "    print(\"Previous Loss:\", valid_loss)\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    valid_preds_1 += list(valid_preds)\n",
    "    valid_targets_1 += list(y_valid)\n",
    "    \n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    test_preds_1.append(test_preds)\n",
    "    \n",
    "    loss = roc_auc_score(y_valid, valid_preds)\n",
    "    losses.append(loss)\n",
    "    rate = 1 - loss\n",
    "    \n",
    "    calcs_1.append(X_train.calc)\n",
    "    print(f\"Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(f\"Previous Importance of {features[2]}: {feature_importances[2]}\")\n",
    "    print(\"Loss:\", loss)\n",
    "    \n",
    "print(np.mean(losses))\n",
    "\n",
    "model.predict(X_train) == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d57b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=2023)\n",
    "\n",
    "valid_preds_2 = []\n",
    "valid_targets_2 = []\n",
    "test_preds_2 = []\n",
    "losses = []\n",
    "\n",
    "rate = 0.0\n",
    "\n",
    "features = ['osmo', 'cond', 'gravity']\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 2023,\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "for train_ind, valid_ind in kfold.split(X=df, y=df.target):\n",
    "    X_test = df_test.copy()\n",
    "    X_train = df.iloc[train_ind]\n",
    "    X_valid = df.iloc[valid_ind]\n",
    "    y_train = X_train.pop('target')\n",
    "    y_valid = X_valid.pop('target')\n",
    "    \n",
    "    X_train = X_train[features]\n",
    "    X_valid = X_valid[features]\n",
    "    X_test = X_test[features]\n",
    "    \n",
    "    X_train.loc[X_train.osmo >= 921, 'osmo'] = np.nan\n",
    "    X_valid.loc[X_valid.osmo >= 921, 'osmo'] = np.nan\n",
    "    X_test.loc[X_test.osmo >= 921, 'osmo'] = np.nan\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    train_preds = model.predict_proba(X_train)[:, 1]\n",
    "    valid_loss = roc_auc_score(y_valid, valid_preds)\n",
    "    train_loss = roc_auc_score(y_train, train_preds)\n",
    "    \n",
    "    rate = abs(train_loss - valid_loss)\n",
    "    \n",
    "    k = 0\n",
    "    feature_importances = model.feature_importances_\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    k = 1\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    print(\"Rate:\", rate)\n",
    "    print(f\"Previous Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Previous Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(\"Previous Loss:\", valid_loss)\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    valid_preds_2 += list(valid_preds)\n",
    "    valid_targets_2 += list(y_valid)\n",
    "    \n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    test_preds_2.append(test_preds)\n",
    "    \n",
    "    loss = roc_auc_score(y_valid, valid_preds)\n",
    "    losses.append(loss)\n",
    "    rate = 1 - loss\n",
    "    \n",
    "    print(f\"Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(\"Loss:\", loss)\n",
    "    \n",
    "print(np.mean(losses))\n",
    "\n",
    "model.predict(X_train) == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=2023)\n",
    "\n",
    "valid_preds_3 = []\n",
    "valid_targets_3 = []\n",
    "test_preds_3 = []\n",
    "losses = []\n",
    "\n",
    "rate = 0.0\n",
    "\n",
    "features = ['gravity', 'osmo', 'calc']\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 2023,\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "for train_ind, valid_ind in kfold.split(X=df, y=df.target):\n",
    "    X_test = df_test.copy()\n",
    "    X_train = df.iloc[train_ind]\n",
    "    X_valid = df.iloc[valid_ind]\n",
    "    y_train = X_train.pop('target')\n",
    "    y_valid = X_valid.pop('target')\n",
    "    \n",
    "    X_train = X_train[features]\n",
    "    X_valid = X_valid[features]\n",
    "    X_test = X_test[features]\n",
    "    \n",
    "    X_train.loc[X_train.osmo >= 921, 'osmo'] = np.nan\n",
    "    X_valid.loc[X_valid.osmo >= 921, 'osmo'] = np.nan\n",
    "    X_test.loc[X_test.osmo >= 921, 'osmo'] = np.nan\n",
    "    \n",
    "    X_train.loc[X_train.calc >= 9, 'calc'] = np.nan\n",
    "    X_valid.loc[X_valid.calc >= 9, 'calc'] = np.nan\n",
    "    X_test.loc[X_test.calc >= 9, 'calc'] = np.nan\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    train_preds = model.predict_proba(X_train)[:, 1]\n",
    "    valid_loss = roc_auc_score(y_valid, valid_preds)\n",
    "    train_loss = roc_auc_score(y_train, train_preds)\n",
    "    \n",
    "    rate = abs(train_loss - valid_loss)\n",
    "    \n",
    "    k = 0\n",
    "    feature_importances = model.feature_importances_\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    k = 1\n",
    "    indexes_to_fillna = X_train[features[k]].sample(frac=rate*feature_importances[k], random_state=2023).index\n",
    "    X_train.loc[indexes_to_fillna, features[k]] = np.nan\n",
    "    \n",
    "    print(\"Rate:\", rate)\n",
    "    print(f\"Previous Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Previous Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(\"Previous Loss:\", valid_loss)\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=500)\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    valid_preds_3 += list(valid_preds)\n",
    "    valid_targets_3 += list(y_valid)\n",
    "    \n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    test_preds_3.append(test_preds)\n",
    "    \n",
    "    loss = roc_auc_score(y_valid, valid_preds)\n",
    "    losses.append(loss)\n",
    "    rate = 1 - loss\n",
    "    \n",
    "    print(f\"Importance of {features[0]}: {feature_importances[0]}\")\n",
    "    print(f\"Importance of {features[1]}: {feature_importances[1]}\")\n",
    "    print(\"Loss:\", loss)\n",
    "    \n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds_df = pd.DataFrame({\n",
    "    'preds_1': valid_preds_1,\n",
    "    'preds_2': valid_preds_2,\n",
    "    'preds_3': valid_preds_3,\n",
    "    'target': valid_targets_3,\n",
    "})\n",
    "\n",
    "test_preds_df = pd.DataFrame({\n",
    "    'preds_1': np.mean(np.column_stack(test_preds_1), axis=1),\n",
    "    'preds_2': np.mean(np.column_stack(test_preds_2), axis=1),\n",
    "    'preds_3': np.mean(np.column_stack(test_preds_3), axis=1),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c22a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3fa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=2023)\n",
    "\n",
    "test_preds = np.zeros((10*10, len(test_preds_df)))\n",
    "\n",
    "k = 0\n",
    "losses = []\n",
    "for train_ind, valid_ind in kfold.split(X=valid_preds_df, y=valid_preds_df.target):\n",
    "    X_train = valid_preds_df.iloc[train_ind]\n",
    "    X_valid = valid_preds_df.iloc[valid_ind]\n",
    "    y_train = X_train.pop('target')\n",
    "    y_valid = X_valid.pop('target')\n",
    "    \n",
    "    model = LogisticRegression(C=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_pred = model.predict_proba(test_preds_df)[:, 1]\n",
    "    test_preds[k] = test_pred\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    losses.append(roc_auc_score(y_valid, valid_preds))\n",
    "    print(losses[-1])\n",
    "    k += 1\n",
    "    \n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69beeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "\n",
    "perm = PermutationImportance(model).fit(X_valid, y_valid)\n",
    "eli5.show_weights(perm, feature_names=X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"/kaggle/input/playground-series-s3e12/sample_submission.csv\")\n",
    "\n",
    "ss.target = np.mean(np.column_stack(test_preds), axis=1)\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930508b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.target.hist(bins=40, rwidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce31b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
