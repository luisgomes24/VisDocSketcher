{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd6e41b",
   "metadata": {},
   "source": [
    "#### Based on [`\"Using GAN for Generating Hand-written Digit Images\" by Naoki Shibuya`](https://github.com/naokishibuya/deep-learning/blob/master/python/gan_mnist.ipynb)\n",
    "\n",
    "## ✒️ Styling, Libraries, and Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>        \n",
    "h2,h3 {text-shadow:4px 4px 4px #aaa;} \n",
    "span {color:black; text-shadow:4px 4px 4px #aaa;}\n",
    "div.output_prompt {color:#39d4be;}; div.input_prompt {color:#37c9e1;} \n",
    "div.output_area pre,div.output_subarea {color:#39d4be;}\n",
    "div.output_stderr pre {background-color:ghostwhite;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import h5py,cv2,os\n",
    "import pandas as pd,numpy as np,pylab as pl\n",
    "import keras as ks,tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Input,Activation,Dense,LSTM\n",
    "from keras.layers import Flatten,Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D,GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU\n",
    "np.set_printoptions(precision=8); rn=np.random.randint(5000)\n",
    "from keras import __version__\n",
    "print('keras version:',__version__)\n",
    "print('tensorflow version:',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):    \n",
    "    x=(x-.5)*2\n",
    "    return np.clip(x,-1,1)\n",
    "def deprocess(x):\n",
    "    x=(x/2+.5)*255\n",
    "#    np.place(x,x>220,255)\n",
    "    x=np.clip(x,0,255)\n",
    "    x=np.uint8(x)\n",
    "    return x.reshape(28,28)\n",
    "def latent_samples(n_samples,sample_size):\n",
    "    return np.random.normal(loc=0,scale=1,\n",
    "                            size=(n_samples,sample_size))\n",
    "latent_sample784=latent_samples(1,784)\n",
    "def display_images(generated_images):\n",
    "    n_images=len(generated_images)\n",
    "    rows=4; cols=n_images//rows    \n",
    "    pl.figure(figsize=(cols,rows))\n",
    "    for i in range(n_images):\n",
    "        img=deprocess(generated_images[i])\n",
    "        pl.subplot(rows,cols,i+1)\n",
    "        pl.imshow(img,cmap=pl.cm.bone)\n",
    "        pl.xticks([]); pl.yticks([])\n",
    "    pl.tight_layout(); pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448547e",
   "metadata": {},
   "source": [
    "## ✒️ Loading & Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../input/train.csv\")\n",
    "id_images=[\"%s%s\" %(\"pixel\",pixel_no) for pixel_no in range(0,784)]\n",
    "train_images=np.array(df_train[id_images])\n",
    "train_images=train_images.astype('float32').reshape(-1,784)\n",
    "pl.imshow(np.squeeze(train_images[rn].reshape(28,28)),\n",
    "          cmap=pl.cm.bone);pl.show()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"../input/test.csv\")\n",
    "id_images=[\"%s%s\" %(\"pixel\",pixel_no) for pixel_no in range(0,784)]\n",
    "test_images=np.array(df_test[id_images])\n",
    "test_images=test_images.astype('float32').reshape(-1,784)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028293c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.imshow(np.squeeze(latent_sample784).reshape(28,28),\n",
    "          cmap=pl.cm.bone); pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33feeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real=preprocess(train_images)\n",
    "X_test_real =preprocess(test_images)\n",
    "display_images(X_train_real[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a38d37",
   "metadata": {},
   "source": [
    "## ✒️ Keras GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65231d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(model,trainable):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=trainable\n",
    "def simple_GAN(sample_size, \n",
    "               g_hidden_size, \n",
    "               d_hidden_size, \n",
    "               leaky_alpha, \n",
    "               g_learning_rate,\n",
    "               d_learning_rate):    \n",
    "    ks.backend.clear_session()    \n",
    "    generator=Sequential([Dense(g_hidden_size,input_shape=(sample_size,)),\n",
    "                          LeakyReLU(alpha=leaky_alpha),\n",
    "                          Dense(784),Activation('tanh')], \n",
    "                         name='generator')    \n",
    "    discriminator=Sequential([Dense(d_hidden_size,input_shape=(784,)),\n",
    "                              LeakyReLU(alpha=leaky_alpha),\n",
    "                              Dense(1),Activation('sigmoid')], \n",
    "                             name='discriminator')        \n",
    "    gan=Sequential([generator,discriminator])    \n",
    "    discriminator.compile(optimizer=Adam(lr=d_learning_rate), \n",
    "                          loss='binary_crossentropy')\n",
    "    gan.compile(optimizer=Adam(lr=g_learning_rate), \n",
    "                loss='binary_crossentropy')   \n",
    "    return gan,generator,discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48277c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size     = 128     \n",
    "g_hidden_size   = 784     # generator\n",
    "d_hidden_size   = 128     # discriminator\n",
    "leaky_alpha     = .02\n",
    "g_learning_rate = .0001  # generator\n",
    "d_learning_rate = .0005  # discriminator\n",
    "epochs          = 200\n",
    "batch_size      = 64      \n",
    "valid_size      = 16     \n",
    "smooth          = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_fake_labels(size):\n",
    "    return np.ones([size,1]),np.zeros([size,1])\n",
    "y_real5,y_fake5=real_fake_labels(5)\n",
    "print('Real\\n',list(y_real5),'\\nFake\\n',list(y_fake5))\n",
    "y_train_real,y_train_fake=real_fake_labels(batch_size)\n",
    "y_valid_real,y_valid_fake=real_fake_labels(valid_size)\n",
    "gan,generator,discriminator=\\\n",
    "simple_GAN(sample_size,g_hidden_size,d_hidden_size,\n",
    "           leaky_alpha,g_learning_rate,d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "for e in range(epochs):\n",
    "    for i in range(len(X_train_real)//batch_size):\n",
    "        # real images\n",
    "        X_batch_real=X_train_real[i*batch_size:(i+1)*batch_size]        \n",
    "        # latent samples and generated letter images\n",
    "        batch_latent_samples=latent_samples(batch_size,sample_size)\n",
    "        X_batch_fake=generator.predict_on_batch(batch_latent_samples)        \n",
    "        # train the discriminator to detect real and fake images\n",
    "        trainable(discriminator,True)\n",
    "        discriminator.train_on_batch(X_batch_real,y_train_real*(1.-smooth))\n",
    "        discriminator.train_on_batch(X_batch_fake,y_train_fake)\n",
    "        # train the generator via GAN\n",
    "        trainable(discriminator,False)\n",
    "        gan.train_on_batch(batch_latent_samples,y_train_real)    \n",
    "    # evaluate\n",
    "    X_valid_real=X_test_real[np.random.choice(len(X_test_real), \n",
    "                                              valid_size,replace=False)]    \n",
    "    valid_latent_samples=latent_samples(valid_size,sample_size)\n",
    "    X_valid_fake=generator.predict_on_batch(valid_latent_samples)\n",
    "    d_loss=discriminator.test_on_batch(X_valid_real,y_valid_real)\n",
    "    d_loss+=discriminator.test_on_batch(X_valid_fake,y_valid_fake)\n",
    "    g_loss=gan.test_on_batch(valid_latent_samples,y_valid_real)     \n",
    "    losses.append((d_loss,g_loss))\n",
    "    st=\"Epoch: %d/%d | Discriminator Loss: %.4f | \"+\\\n",
    "       \"Generator Loss: %.4f | DL > GL: %s\"\n",
    "    if (e+1)%int(10)==0:\n",
    "        print(st%((e+1,epochs,d_loss,g_loss,d_loss>g_loss)))\n",
    "        if ((g_loss<.9) and (d_loss>g_loss)):\n",
    "            latent_examples=latent_samples(32,sample_size)\n",
    "            generated_digits=generator.predict(latent_examples)\n",
    "            display_images(generated_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682f80a",
   "metadata": {},
   "source": [
    "## ✒️ Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss(losses,n):\n",
    "    indices=[i*n for i in range(len(losses)//n)]\n",
    "    n_losses=np.array(losses)[indices,:]    \n",
    "    pl.figure(figsize=(12,6))\n",
    "    pl.plot(n_losses.T[0],'-o',c='#37c9e1',lw=1,\n",
    "            label='Discriminator')\n",
    "    pl.plot(n_losses.T[1],'-o',c='#39d4be',lw=1,\n",
    "            label='Generator')\n",
    "    pl.title(\"Training Loss Functions\")\n",
    "    pl.legend(); pl.show()\n",
    "display_loss(losses,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_examples=latent_samples(32,sample_size)\n",
    "generated_digits=generator.predict(latent_examples)\n",
    "display_images(generated_digits)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
