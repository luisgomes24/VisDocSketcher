{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28cf496",
   "metadata": {},
   "source": [
    "# 1. Loading and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56008dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/diamonds/diamonds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a825e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452181cc",
   "metadata": {},
   "source": [
    "**Since the author mentioned that there are some data duplicates detected lets get rid of duplicated data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=['carat', 'cut', 'color', 'clarity', 'price'], keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79163211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['carat', 'cut', 'color', 'clarity', 'price'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc741ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b25b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cut'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94cd73",
   "metadata": {},
   "source": [
    "**I prefer to label encode the cut myself as it is ordinal data (means ranking matters). The cut grading is further explained on this website https://www.loosediamondsreviews.com/diamondcut.html**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f92a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_grades = {\n",
    "    \"b'Fair'\": 0,\n",
    "    \"b'Good'\": 1,\n",
    "    \"b'Very Good'\": 2,\n",
    "    \"b'Premium'\": 3,\n",
    "    \"b'Ideal'\": 4\n",
    "}\n",
    "cut_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clarity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36ecf8",
   "metadata": {},
   "source": [
    "**I will also encode clarity myself as per cut grades. Clarity grading is further explained on this website https://www.americangemsociety.org/buying-diamonds-with-confidence/4cs-of-diamonds/understanding-diamond-clarity-the-4cs-of-diamonds/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ac227",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarity_grades = {\n",
    "    \"b'I1'\": 0,\n",
    "    \"b'SI2'\": 1,\n",
    "    \"b'SI1'\": 2,\n",
    "    \"b'VS2'\": 3,\n",
    "    \"b'VS1'\": 4,\n",
    "    \"b'VVS2'\": 5,\n",
    "    \"b'VVS1'\": 6,\n",
    "    \"b'IF'\": 7\n",
    "}\n",
    "clarity_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cut_encoded'] = df['cut'].map(cut_grades)\n",
    "df['clarity_encoded'] = df['clarity'].map(clarity_grades)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4691aa0",
   "metadata": {},
   "source": [
    "**As for color as there is no ranking involved I'll encode the color**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_encoded = pd.get_dummies(df['color'], drop_first=True, prefix='color')\n",
    "color_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, color_encoded], axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa24923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['cut', 'color', 'clarity'], axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4abb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d13d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8342337",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e037a3",
   "metadata": {},
   "source": [
    "**From the 2 graphs above it can be seen that there is significant correlation between carat, x, y, and z with price**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28121e8",
   "metadata": {},
   "source": [
    "# 2. Preparing data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ac21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis='columns')\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61985567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6217f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0f2a6",
   "metadata": {},
   "source": [
    "# 3. Model exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'GB Regressor': GradientBoostingRegressor(),\n",
    "    'RF Regressor': RandomForestRegressor(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'SGD Regressor': SGDRegressor(),\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    'SVR': SVR(),\n",
    "    'CatBoost': CatBoostRegressor(),\n",
    "    'Kernel Ridge': KernelRidge(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor()\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_mean_mses = []\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, scoring='neg_mean_squared_error')\n",
    "    model_names.append(model_name)\n",
    "    model_mean_mses.append(-scores.mean())\n",
    "    print(f'Model mean MSE calculation completed for {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame()\n",
    "model_scores['model'] = model_names\n",
    "model_scores['mean mse'] = model_mean_mses\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc73896",
   "metadata": {},
   "source": [
    "**From the model comparison CatBoostRegressor has the lowest MSE. Therefore, we will proceed with CatBoostRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e675f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = CatBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254eabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8126d",
   "metadata": {},
   "source": [
    "# 4. Model validation using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = final_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1052d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_predicted)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "correlation_stats = spearmanr(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ee948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE = {mse:.4f}, MAE = {mae:.4f}, Correlation = {correlation_stats.correlation}, Correlation P-value = {correlation_stats.pvalue}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
