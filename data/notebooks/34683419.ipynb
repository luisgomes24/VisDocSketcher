{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d062ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML, Javascript\n",
    "\n",
    "# ----- Notebook Theme -----\n",
    "color_map = ['#16a085', '#e8f6f3', '#d0ece7', '#a2d9ce', '#73c6b6', '#45b39d', \n",
    "                        '#16a085', '#138d75', '#117a65', '#0e6655', '#0b5345']\n",
    "\n",
    "prompt = color_map[-1]\n",
    "main_color = color_map[0]\n",
    "strong_main_color = color_map[1]\n",
    "custom_colors = [strong_main_color, main_color]\n",
    "\n",
    "css_file = ''' \n",
    "\n",
    "div #notebook {\n",
    "background-color: white;\n",
    "line-height: 20px;\n",
    "}\n",
    "\n",
    "#notebook-container {\n",
    "%s\n",
    "margin-top: 2em;\n",
    "padding-top: 2em;\n",
    "border-top: 4px solid %s; /* light orange */\n",
    "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
    "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
    "}\n",
    "\n",
    "div .input {\n",
    "margin-bottom: 1em;\n",
    "}\n",
    "\n",
    ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
    "color: %s; /* light orange */\n",
    "font-weight: 600;\n",
    "}\n",
    "\n",
    "div.input_area {\n",
    "border: none;\n",
    "    background-color: %s; /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n",
    "    border-top: 2px solid %s; /* light orange */\n",
    "}\n",
    "\n",
    "div.input_prompt {\n",
    "color: %s; /* light blue */\n",
    "}\n",
    "\n",
    "div.output_prompt {\n",
    "color: %s; /* strong orange */\n",
    "}\n",
    "\n",
    "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
    "background: %s; /* light orange */\n",
    "}\n",
    "\n",
    "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
    "    border-color: %s; /* light orange */\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected:before {\n",
    "background: %s; /* light orange */\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected {\n",
    "border-color: %s; /* light orange */\n",
    "\n",
    "}\n",
    "'''\n",
    "def to_rgb(h): \n",
    "    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n",
    "\n",
    "main_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\n",
    "open('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba, main_color,  main_color, prompt, main_color, main_color, main_color, main_color))\n",
    "\n",
    "def nb(): \n",
    "    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\n",
    "nb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f318b336",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/AILab-MLTools/LightAutoML/master/imgs/LightAutoML_logo_big.png\" alt=\"LightAutoML logo\" style=\"width:70%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12209a97",
   "metadata": {},
   "source": [
    "# LightAutoML baseline\n",
    "\n",
    "Official LightAutoML github repository is [here](https://github.com/AILab-MLTools/LightAutoML). \n",
    "\n",
    "### Do not forget to put upvote for the notebook and the ⭐️ for github repo if you like it using the button below - one click for you, great pleasure for us ☺️ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8483243",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '<iframe src=\"https://ghbtns.com/github-btn.html?user=AILab-MLTools&repo=LightAutoML&type=star&count=true&size=large\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"LightAutoML GitHub\"></iframe>'\n",
    "HTML(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5a98a",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea8d1c",
   "metadata": {},
   "source": [
    "### 0.0. install LightAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c48e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62921c",
   "metadata": {},
   "source": [
    "### 0.1. Import libraries\n",
    "\n",
    "Here we will import the libraries we use in this kernel:\n",
    "- Standard python libraries for timing, working with OS etc.\n",
    "- Essential python DS libraries like numpy, pandas, scikit-learn and torch (the last we will use in the next cell)\n",
    "- LightAutoML modules: presets for AutoML, task and report generation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df83114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.report.report_deco import ReportDeco\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8930a7fb",
   "metadata": {},
   "source": [
    "### 0.2. Constants\n",
    "\n",
    "Here we setup the constants to use in the kernel:\n",
    "- `N_THREADS` - number of vCPUs for LightAutoML model creation\n",
    "- `RANDOM_STATE` - random seed for better reproducibility\n",
    "- `TEST_SIZE` - houldout data part size \n",
    "- `TIMEOUT` - limit in seconds for model to train\n",
    "- `TARGET_NAME` - target column name in dataset\n",
    "- `N_FOLDS` - number folds for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "RANDOM_STATE = 21\n",
    "# TEST_SIZE = 0.2\n",
    "TIMEOUT = 0.5 * 3600\n",
    "TARGET_NAME = 'quality'\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd5b1b",
   "metadata": {},
   "source": [
    "### 0.3. Imported models setup\n",
    "\n",
    "For better reproducibility fix numpy random seed with max number of threads for Torch (which usually try to use all the threads on server):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5db51a",
   "metadata": {},
   "source": [
    "### 0.4. Data loading\n",
    "Let's check the data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('/kaggle/input/playground-series-s3e5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f'{INPUT_DIR}/train.csv')\n",
    "train_data['is_generated'] = 1\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbaed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f'{INPUT_DIR}/test.csv')\n",
    "test_data['is_generated'] = 1\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ac047",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b75c6",
   "metadata": {},
   "source": [
    "### 0.5. Feature engineering\n",
    "Let's make same new features and/or data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = pd.read_csv('/kaggle/input/wine-quality-dataset/WineQT.csv')\n",
    "extra_data['is_generated'] = 0\n",
    "print(extra_data.shape)\n",
    "extra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, extra_data], axis=0).drop_duplicates()\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335db13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92d95e",
   "metadata": {},
   "source": [
    "Thanks to [kotrying](https://www.kaggle.com/code/kotrying/ps-s3e5-using-polars/notebook)'s notebook for the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b75c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    # From https://www.kaggle.com/code/kotrying/ps-s3e5-using-polars/notebook\n",
    "    data['log1p residual sugar'] = np.log1p(data['residual sugar'])\n",
    "    data['citric acid per alcohol'] = data['citric acid'] / data['alcohol']\n",
    "    data['citric acid type'] = data['citric acid'].apply(lambda x: 0 if x==0 else (1 if x==0.49 else 2))\n",
    "    data['pH round1'] = round(data['pH'], 1)\n",
    "    ph_dict = train_data.groupby(by='pH round1')['alcohol'].mean().to_dict()\n",
    "    data['alcohol mean groupby pH'] = data['pH round1'].map(ph_dict)\n",
    "    \n",
    "    # From https://www.kaggle.com/competitions/playground-series-s3e5/discussion/383685\n",
    "    data['acidity_ratio'] = data['fixed acidity'] / data['volatile acidity']\n",
    "    data['free_sulfur/total_sulfur'] = data['free sulfur dioxide'] / data['total sulfur dioxide']\n",
    "    data['sugar/alcohol'] = data['residual sugar'] / data['alcohol']\n",
    "    data['alcohol/density'] = data['alcohol'] / data['density']\n",
    "    data['total_acid'] = data['fixed acidity'] + data['volatile acidity'] + data['citric acid']\n",
    "    data['sulphates/chlorides'] = data['sulphates'] / data['chlorides']\n",
    "    data['bound_sulfur'] = data['total sulfur dioxide'] - data['free sulfur dioxide']\n",
    "    data['alcohol/pH'] = data['alcohol'] / data['pH']\n",
    "    data['alcohol/acidity'] = data['alcohol'] / data['total_acid']\n",
    "    data['alkalinity'] = data['pH'] + data['alcohol']\n",
    "    data['mineral'] = data['chlorides'] + data['sulphates'] + data['residual sugar']\n",
    "    data['density/pH'] = data['density'] / data['pH']\n",
    "    data['total_alcohol'] = data['alcohol'] + data['residual sugar']\n",
    "    \n",
    "    # From https://www.kaggle.com/competitions/playground-series-s3e5/discussion/382698\n",
    "    data['acid/density'] = data['total_acid']  / data['density']\n",
    "    data['sulphate/density'] = data['sulphates']  / data['density']\n",
    "    data['sulphates/acid'] = data['sulphates'] / data['volatile acidity']\n",
    "    data['sulphates*alcohol'] = data['sulphates'] * data['alcohol']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "for data in [train_data, test_data]:\n",
    "    data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73114f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = RobustScaler()\n",
    "\n",
    "sc_features = [feature for feature in test_data.columns if feature not in ['Id']]\n",
    "train_data[sc_features] = sc.fit_transform(train_data[sc_features])\n",
    "test_data[sc_features] = sc.transform(test_data[sc_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a31f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041da7ad",
   "metadata": {},
   "source": [
    "# 1. Task definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6990c2",
   "metadata": {},
   "source": [
    "### 1.1. Task type\n",
    "\n",
    "On the cell below we create Task object - the class to setup what task LightAutoML model should solve with specific loss and metric if necessary (more info can be found [here](https://lightautoml.readthedocs.io/en/latest/generated/lightautoml.tasks.base.Task.html#lightautoml.tasks.base.Task) in our documentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(name = 'multiclass',\n",
    "            metric = 'accuracy',\n",
    "#             loss = 'f1'\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322576f3",
   "metadata": {},
   "source": [
    "### 1.2. Feature roles setup\n",
    "To solve the task, we need to setup columns roles. The **only role you must setup is target role**, everything else (drop, numeric, categorical, group, weights etc.) is up to user - LightAutoML models have automatic columns typization inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05715bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME,\n",
    "         'drop': ['Id']\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228272cf",
   "metadata": {},
   "source": [
    "### 1.3. LightAutoML model creation - TabularAutoML preset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7005a",
   "metadata": {},
   "source": [
    "In next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n",
    "\n",
    "<img src=\"https://github.com/AILab-MLTools/LightAutoML/raw/master/imgs/tutorial_blackbox_pipeline.png\" alt=\"TabularAutoML preset pipeline\" style=\"width:75%;\"/>\n",
    "\n",
    "in just several lines. Let's discuss the params we can setup:\n",
    "- `task` - the type of the ML task (the only **must have** parameter)\n",
    "- `timeout` - time limit in seconds for model to train\n",
    "- `cpu_limit` - vCPU count for model to use\n",
    "- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n",
    "\n",
    "**Important note**: `reader_params` key is one of the YAML config keys, which is used inside `TabularAutoML` preset. [More details](https://github.com/AILab-MLTools/blob/master/lightautoml/automl/presets/tabular_config.yml) on its structure with explanation comments can be found on the link attached. Each key from this config can be modified with user settings during preset object initialization. To get more info about different parameters setting (for example, ML algos which can be used in `general_params->use_algos`) please take a look at our [article on TowardsDataScience](https://towardsdatascience.com/lightautoml-preset-usage-tutorial-2cce7da6f936).\n",
    "\n",
    "Moreover, to receive the automatic report for our model we will use `ReportDeco` decorator and work with the decorated version in the same way as we do with usual one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(task = task,\n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]}\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa12ec",
   "metadata": {},
   "source": [
    "# 2. AutoML training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60aa446",
   "metadata": {},
   "source": [
    "To run autoML training use fit_predict method:\n",
    "- `train_data` - Dataset to train.\n",
    "- `roles` - Roles dict.\n",
    "- `verbose` - Controls the verbosity: the higher, the more messages.\n",
    "        <1  : messages are not displayed;\n",
    "        >=1 : the computation process for layers is displayed;\n",
    "        >=2 : the information about folds processing is also displayed;\n",
    "        >=3 : the hyperparameters optimization process is also displayed;\n",
    "        >=4 : the training process for every algorithm is displayed;\n",
    "\n",
    "Note: out-of-fold prediction is calculated during training and returned from the fit_predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f038c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "oof_pred = automl.fit_predict(train_data, roles=roles, verbose=3)\n",
    "print(f'oof_pred:\\n{oof_pred}\\nShape = {oof_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a049bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fast_fi = automl.get_feature_scores('fast')\n",
    "fast_fi.set_index('Feature')['Importance'].plot.bar(figsize=(20, 10), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_data[['Id', TARGET_NAME]]\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328380bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    preds['pred_' + str(i)] = oof_pred.data[:, i]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985021f5",
   "metadata": {},
   "source": [
    "Assign classes by maximum class probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFs = np.argmax(preds[['pred_' + str(i) for i in range(6)]].values, axis = 1)\n",
    "OOFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2142092",
   "metadata": {},
   "source": [
    "Let’s see classification accuracy on train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (OOFs == preds[TARGET_NAME].map(automl.reader.class_mapping)).mean()\n",
    "print(f'Out-of-fold accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903c9b4",
   "metadata": {},
   "source": [
    "Also to estimate the quality of classification, we can use the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(preds[TARGET_NAME].map(automl.reader.class_mapping),\n",
    "                             OOFs)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt = 'd')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "inverse_class_mapping = {y: x for x,y in automl.reader.class_mapping.items()}\n",
    "labels = [inverse_class_mapping[i] for i in range(len(inverse_class_mapping))]\n",
    "ax.xaxis.set_ticklabels(labels, rotation = 90)\n",
    "ax.yaxis.set_ticklabels(labels, rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cb437",
   "metadata": {},
   "source": [
    "# 3. Predict and save\n",
    "Predict and save submissions to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "print(f'Prediction for test data:\\n{test_pred}\\nShape = {test_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bd5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = submission[['Id']]\n",
    "for i in range(6):\n",
    "    sub['pred_' + str(i)] = test_pred.data[:,i]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEs = pd.Series(np.argmax(sub[['pred_' + str(i) for i in range(6)]].values, axis = 1)).map(inverse_class_mapping)\n",
    "TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4406605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[TARGET_NAME] = TEs\n",
    "sub[['Id', TARGET_NAME]].to_csv('LightAutoML.csv', index=False)\n",
    "sub[['Id', TARGET_NAME]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a430f",
   "metadata": {},
   "source": [
    "# Additional materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6aadb",
   "metadata": {},
   "source": [
    "- [Official LightAutoML github repo](https://github.com/AILab-MLTools/LightAutoML)\n",
    "- [LightAutoML documentation](https://lightautoml.readthedocs.io/en/latest)\n",
    "- [LightAutoML tutorials](https://github.com/AILab-MLTools/LightAutoML/tree/master/examples/tutorials)\n",
    "- LightAutoML course:\n",
    "    - [Part 1 - general overview](https://ods.ai/tracks/automl-course-part1) \n",
    "    - [Part 2 - LightAutoML specific applications](https://ods.ai/tracks/automl-course-part2)\n",
    "    - [Part 3 - LightAutoML customization](https://ods.ai/tracks/automl-course-part3)\n",
    "- [OpenDataScience AutoML benchmark leaderboard](https://ods.ai/competitions/automl-benchmark/leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56f02f",
   "metadata": {},
   "source": [
    "### If you still like the notebook, do not forget to put upvote for the notebook and the ⭐️ for github repo if you like it using the button below - one click for you, great pleasure for us ☺️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '<iframe src=\"https://ghbtns.com/github-btn.html?user=sb-ai-lab&repo=LightAutoML&type=star&count=true&size=large\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"LightAutoML GitHub\"></iframe>'\n",
    "HTML(s)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
