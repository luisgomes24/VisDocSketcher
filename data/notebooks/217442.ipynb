{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380009ab",
   "metadata": {},
   "source": [
    "A script to show how to get started with segmenting superpixels in PETCT images. Here we show both 2d, 3d, single channel and multichannel analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util.montage import montage2d\n",
    "import os\n",
    "import h5py\n",
    "make_proj = lambda x: np.sum(x,1)[::-1]\n",
    "make_mip = lambda x: np.max(x,1)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf1419",
   "metadata": {},
   "source": [
    "# Loading and Displaying PET and CT\n",
    "Here we load the PET and CT data from a single patient and show the projection image for CT and the MIP view for the PET data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2669f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "with h5py.File(os.path.join('..', 'input', 'lab_petct_vox_5.00mm.h5'), 'r') as p_data:\n",
    "    id_list = list(p_data['ct_data'].keys())\n",
    "    print(list(p_data.keys()))\n",
    "    ct_image = p_data['ct_data'][id_list[0]].value\n",
    "    pet_image = p_data['pet_data'][id_list[0]].value\n",
    "    label_image = (p_data['label_data'][id_list[0]].value>0).astype(np.uint8)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\n",
    "ct_proj = make_proj(ct_image)\n",
    "suv_max = make_mip(pet_image)\n",
    "lab_proj = make_proj(label_image)\n",
    "ax1.imshow(ct_proj, cmap = 'bone')\n",
    "ax1.set_title('CT Image')\n",
    "ax2.imshow(np.sqrt(suv_max), cmap = 'magma')\n",
    "ax2.set_title('SUV Image')\n",
    "ax3.imshow(lab_proj, cmap = 'gist_earth')\n",
    "ax3.set_title('Tumor Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d013eb",
   "metadata": {},
   "source": [
    "# Make a Superpixel Segmentation of the images\n",
    "We make basic superpixels for the CT image here. The primary parameters we adjust are the \n",
    "\n",
    " - **n_segments** the number of different segments to make (approximately)\n",
    " - **compactness** the weight of spatial dimensions versus image intensity (low values are more irregularly shaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a1efb",
   "metadata": {},
   "source": [
    "# Combined PET/CT Super-pixels\n",
    "Here we use image data from both PET and CT\n",
    "# Full 3D Superpixels\n",
    "Here we make full 3D superpixels for PETCT and show a simple rendering of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_weight = 1.0 # how strongly to weight the pet_signal (1.0 is the same as CT)\n",
    "petct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n",
    "                            pet_weight*(suv_slice).clip(0,5)/5.0\n",
    "                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "petct_segs = slic(petct_vol, \n",
    "                  n_segments = 2000, \n",
    "                  compactness = 0.1,\n",
    "                 multichannel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c84321",
   "metadata": {},
   "outputs": [],
   "source": [
    "petct_max_segs = make_mip(petct_segs)\n",
    "ct_proj = make_proj(petct_vol[:,:,:,0])\n",
    "suv_mip = make_mip(petct_vol[:,:,:,1])\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (14, 6))\n",
    "ax1.imshow(suv_mip, cmap = 'magma')\n",
    "ax1.set_title('SUV Image')\n",
    "ax2.imshow(petct_max_segs, cmap = plt.cm.rainbow)\n",
    "ax2.set_title('Segmented Image')\n",
    "ax3.imshow(mark_boundaries(suv_mip, petct_max_segs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dba32",
   "metadata": {},
   "source": [
    "## Compare Segments to Labels\n",
    "We look at each superpixel and see how many different labels are inside it. We want each superpixel to be an 'atomic' unit of the image and so we only want one in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027de999",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.unique(petct_segs):\n",
    "    cur_region_mask = petct_segs == idx\n",
    "    labels_in_region = label_image[cur_region_mask]\n",
    "    labeled_regions_inside = np.unique(labels_in_region)\n",
    "    if len(labeled_regions_inside)>1:\n",
    "        print('Superpixel id', idx, 'regions', len(labeled_regions_inside))\n",
    "        print('\\n',pd.value_counts(labels_in_region))\n",
    "        print('Missclassified Pixels:', np.sum(pd.value_counts(labels_in_region)[1:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc418f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(labels_in_region)[1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_labels = [i for i in np.unique(label_image) if i>=0]\n",
    "fig, m_axs = plt.subplots(len(nz_labels), 2, figsize = (5, 15))\n",
    "for (ax1, ax2), i_label in zip(m_axs, nz_labels):\n",
    "    out_sp = np.zeros_like(petct_segs)\n",
    "    cur_label_mask = label_image == i_label\n",
    "    labels_in_region = petct_segs[cur_label_mask]\n",
    "    \n",
    "    superpixels_in_region = np.unique(labels_in_region)\n",
    "    for i, sp_idx in enumerate(superpixels_in_region):\n",
    "        out_sp[petct_segs == sp_idx] = i+1\n",
    "    \n",
    "    ax1.imshow(make_proj(cur_label_mask), cmap = 'bone')\n",
    "    ax1.set_title('Label Map {}'.format(i_label) if i_label>0 else 'Background Label')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(make_proj(out_sp), cmap = 'gist_earth')\n",
    "    ax2.set_title('Superpixels ({})'.format(len(superpixels_in_region)))\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89ce50",
   "metadata": {},
   "source": [
    "## Show the superpixels for each label\n",
    "Here we can show which superpixels are inside each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.unique(label_image):\n",
    "    cur_region_mask = label_image == idx\n",
    "    labels_in_region = petct_segs[cur_region_mask]\n",
    "    labeled_regions_inside = np.unique(labels_in_region)\n",
    "    print('Label id', idx, 'superpixels inside', len(labeled_regions_inside))\n",
    "    #print(pd.value_counts(labels_in_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b98bd",
   "metadata": {},
   "source": [
    "# Optimize Superpixel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_score(gt_labels, sp_segs):\n",
    "    # type: (np.ndarray, np.ndarray) -> float\n",
    "    \"\"\"\n",
    "    Score how well the superpixels match to the ground truth labels. \n",
    "    Here we use a simple penalty of number of pixels misclassified\n",
    "    :param gt_labels: the ground truth labels (from an annotation tool)\n",
    "    :param sp_segs: the superpixel segmentation\n",
    "    :return: the score (lower is better)\n",
    "    \"\"\"\n",
    "    out_score = 0\n",
    "    for idx in np.unique(sp_segs):\n",
    "        cur_region_mask = sp_segs == idx\n",
    "        labels_in_region = gt_labels[cur_region_mask]\n",
    "        out_score += np.sum(pd.value_counts(labels_in_region)[1:].values)\n",
    "    return out_score\n",
    "\n",
    "print('Label Score', label_score(label_image, petct_segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new superpixels\n",
    "def make_superpixel(pet_weight = 1.0, # how strongly to weight the pet_signal (1.0 is the same as CT)\n",
    "                    n_segments = 1000, # number of segments\n",
    "                    compactness = 0.1): # how compact the segments are\n",
    "    \n",
    "    t_petct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n",
    "                            pet_weight*(suv_slice).clip(0,5)/5.0\n",
    "                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)\n",
    "    petct_segs = slic(t_petct_vol, \n",
    "                  n_segments = n_segments, \n",
    "                  compactness = compactness,\n",
    "                 multichannel = True)\n",
    "    return petct_segs\n",
    "\n",
    "def make_and_score(*args, **kwargs):\n",
    "    n_segs = make_superpixel(*args, **kwargs)\n",
    "    return label_score(label_image, n_segs)\n",
    "# run it quickly with 10000 segments and it should have many fewer misclassified\n",
    "print('Misclassified Pixels', make_and_score(n_segments = 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 3 different values for n_segments to see how the performance changes\n",
    "n_segments = [10, 100, 1000]\n",
    "n_score = [make_and_score(n_segments = c_seg) for c_seg in n_segments]\n",
    "print(n_score)\n",
    "plt.plot(n_segments, n_score, 'b-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the values\n",
    "from scipy.optimize import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4df1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_segs = np.zeros_like(petct_segs)\n",
    "kept_comps = 0\n",
    "for i in np.unique(petct_segs):\n",
    "    if pet_image[petct_segs == i].mean()>1.5:\n",
    "        bright_segs[petct_segs == i] = 1\n",
    "        kept_comps+=1\n",
    "print('Kept', kept_comps,'of', len(np.unique(petct_segs)))\n",
    "bright_sum_segs = make_proj(bright_segs)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14, 6))\n",
    "ax1.imshow(suv_max, cmap = 'magma')\n",
    "ax1.set_title('SUV Image')\n",
    "ax2.imshow(bright_sum_segs, cmap = plt.cm.bone)\n",
    "ax2.set_title('Segments Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from skimage import measure\n",
    "def show_3d_mesh(image, threshold):\n",
    "    p = image[::-1].swapaxes(1,2)\n",
    "    \n",
    "    verts, faces = measure.marching_cubes(p, threshold)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n",
    "    mesh.set_facecolor([.1, 1, .1])\n",
    "    mesh.set_edgecolor([1, 0, 0])\n",
    "    \n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "    \n",
    "    ax.view_init(80, 5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_3d_mesh(bright_segs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a221d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "def show_pet_3d(image, pet_signal, threshold):\n",
    "    p = image[::-1].swapaxes(1,2)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    \n",
    "    verts, faces = measure.marching_cubes(p, 0)\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n",
    "    mesh.set_facecolor([.1, 1, .1])\n",
    "    mesh.set_edgecolor([1, 0, 0])\n",
    "    \n",
    "    ax1.add_collection3d(mesh)\n",
    "\n",
    "    ax1.set_xlim(0, p.shape[0])\n",
    "    ax1.set_ylim(0, p.shape[1])\n",
    "    ax1.set_zlim(0, p.shape[2])\n",
    "    \n",
    "    ax1.view_init(80, 5)\n",
    "    \n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    p_pet = pet_signal[::-1].swapaxes(1,2)\n",
    "    \n",
    "    verts, faces = measure.marching_cubes(p_pet, threshold)\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n",
    "    mesh.set_facecolor([1, 0, .1])\n",
    "    mesh.set_edgecolor([.1, 0, 1.0])\n",
    "    \n",
    "    ax2.add_collection3d(mesh)\n",
    "\n",
    "    ax2.set_xlim(0, p.shape[0])\n",
    "    ax2.set_ylim(0, p.shape[1])\n",
    "    ax2.set_zlim(0, p.shape[2])\n",
    "    ax2.view_init(80, 5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_seg_pet = pet_image.copy()\n",
    "bright_seg_pet[bright_segs==0] = 0\n",
    "_ = show_pet_3d(bright_segs, bright_seg_pet, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb90d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
