{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047820fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3692e27",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "I am going to go through the task submissions for [Contest #12: UFC Fight Night Covington vs. Woodley](https://www.kaggle.com/mdabbert/ultimate-ufc-dataset/tasks?taskId=2124)  and see what set of predictions was the most profitable (if any!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93f3ea",
   "metadata": {},
   "source": [
    "# Submissions\n",
    "\n",
    "There are 2 submissions.  \n",
    "\n",
    "1. The dummy file (gives each fighter a .5 probability of winning. Therefore will bet every underdog with greater than +100 odds.)\n",
    "2. mdabbert's (my!) submission. A GaussianNB Classifier using the following features: ['B_Weight_lbs', 'B_Flyweight_rank', 'B_avg_TD_landed', 'B_Light Heavyweight_rank', 'B_Lightweight_rank', 'R_avg_TD_landed', 'R_Middleweight_rank', 'R_Height_cms', 'R_avg_SIG_STR_pct', 'B_age', 'R_longest_win_streak', 'lose_streak_dif', 'R_win_by_Decision_Majority', 'longest_win_streak_dif', 'avg_sub_att_dif', 'sig_str_dif', 'B_avg_SUB_ATT', 'R_win_by_TKO_Doctor_Stoppage', 'B_draw', 'R_win_by_Decision_Split', 'age_dif', 'R_odds']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75715042",
   "metadata": {},
   "source": [
    "# Open All Submissions and add to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64cb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will help us keep track of the submissions\n",
    "sub_name_list = ['dummy', 'mdabbert']\n",
    "score_list = [] #We can keep the scores here\n",
    "\n",
    "#Put the submissions in dataframe form and add to a list.\n",
    "sub_list = []\n",
    "temp_df = pd.read_csv(\"/kaggle/input/dummy-sub-for-ufc-contest-12/task-dummy.csv\")\n",
    "sub_list.append(temp_df)\n",
    "\n",
    "temp_df = pd.read_csv(\"/kaggle/input/submission-for-91920-ufc-contest/mdabbert-9-19-20-submission.csv\")\n",
    "sub_list.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"/kaggle/input/ultimate-ufc-dataset/most-recent-event.csv\")\n",
    "\n",
    "#We only need the fighter names, odds, and winner\n",
    "\n",
    "results_df = results_df[['R_fighter', 'B_fighter', 'R_ev', 'B_ev', 'Winner']]\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d99e5",
   "metadata": {},
   "source": [
    "`Red` won 10 of 13 fights.  More `Red` wins is normally a good sign when it comes to model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703bf44",
   "metadata": {},
   "source": [
    "# Iterate the submissions and see how everyone did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a specific bet EV based on winning_ev and probability.\n",
    "def get_bet_ev(ev, prob):\n",
    "    \n",
    "    return(ev*prob - (1-prob)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to determine the bet of each fight.  We will use probabilities and the ev to \n",
    "#determine profitable bets\n",
    "def get_bet(R_prob, B_prob, R_ev, B_ev):\n",
    "    red_ev = get_bet_ev(R_ev, R_prob)\n",
    "    blue_ev = get_bet_ev(B_ev, B_prob)\n",
    "    if red_ev > 0:\n",
    "        return('Red')\n",
    "    if blue_ev > 0:\n",
    "        return('Blue')\n",
    "    \n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05950623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(winner, bet, R_ev, B_ev):\n",
    "    if bet == 'None':\n",
    "        return 0\n",
    "    if (bet == 'Blue' and winner == 'Blue'):\n",
    "        return B_ev\n",
    "    if (bet == 'Red' and winner == 'Red'):\n",
    "        return R_ev\n",
    "    else:\n",
    "        return (-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a helper function to make this easier\n",
    "\n",
    "def get_score(sub, results):\n",
    "#    display(sub)\n",
    "#    display(results)\n",
    "    #Let's merge the two dataframes\n",
    "    merge_df = pd.merge(sub, results)\n",
    "    #display(merge_df)\n",
    "    #We can get the proper bet by using a lambda function\n",
    "    merge_df['Bet'] = merge_df.apply(lambda x: get_bet(x['R_prob'],x['B_prob'],x['R_ev'],x['B_ev']), axis=1)\n",
    "    merge_df['Profit'] = merge_df.apply(lambda x: get_profit(x['Winner'], x['Bet'], x['R_ev'], x['B_ev']), axis=1)\n",
    "    display(merge_df)\n",
    "    return(sum(merge_df['Profit']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a0145",
   "metadata": {},
   "source": [
    "# Submission #1: Dummy Submission\n",
    "\n",
    "These are the results of the dummy submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "score_list.append(get_score(sub_list[z], results_df))\n",
    "print(f\"{sub_name_list[z]}'s bets saw a total profit of {score_list[z]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c36196",
   "metadata": {},
   "source": [
    "Dummy had a bad night.  Losing 445 units on 10 bets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437da0c",
   "metadata": {},
   "source": [
    "# Submission #2: mdabbert's Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1\n",
    "score_list.append(get_score(sub_list[z], results_df))\n",
    "print(f\"{sub_name_list[z]}'s bets saw a total profit of {score_list[z]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b3579",
   "metadata": {},
   "source": [
    "mdabbert won 7 bets and lost 5.  He picked two underdogs correctly and ended up 259.47 units on 12 total bets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b02e19",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "\n",
    "* `dummy`: -445.00 units\n",
    "* `mdabbert`: +259.47 units\n",
    "\n",
    "mdabbert is the winner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac667d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
