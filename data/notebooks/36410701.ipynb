{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dea1d5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "Pattern recognition and image classification has surprisingly become one of the efficient methods of malware detection/classification. Back in 2011, the researchers from University of California (Santa Barbara, California, USA) - L. Nataraj, S. Karthikeyan, G. Jacob, and B. S. Manjunath - proposed a simple yet effective method for visualizing and classifying malware using image processing techniques. Malware binaries can be visualized as gray-scale images, with the observation that for many malware families, the images belonging to the same family appear very similar in layout and texture. Motivated by this visual similarity, a classification method using standard image features had been proposed by the researcher team. Neither disassembly nor code execution is required for such a classification. Preliminary experimental results were quite promising with 98% classification accuracy on a malware database of 9,458 samples with 25 different malware families (see their public paper per https://vision.ece.ucsb.edu/sites/default/files/publications/nataraj_vizsec_2011_paper.pdf for more info).\n",
    "\n",
    "\n",
    "The purpose of this notebook is to demonstrate that the hybrid **CoatNet** DL model architecture can bring more accurate malware detection/classification results on MalImg dataset, compared to the results of original inventors of Malware visualizing and classifying method mentioned above.\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- CoatNet implementation reused from\n",
    "https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/coatnet\n",
    "- Data preprocessing and brief EDA inspired by https://www.kaggle.com/code/tiletisaitejareddy/malware-classification-ism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ba5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "import sys\n",
    "import os\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7724698",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "train_root_path = \"../input/malimg-dataset9010/dataset_9010/dataset_9010/malimg_dataset/train\"\n",
    "val_root_path = \"../input/malimg-dataset9010/dataset_9010/dataset_9010/malimg_dataset/validation\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "batches = ImageDataGenerator().flow_from_directory(directory=train_root_path, target_size=(64,64), batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6efdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6036cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(batches)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize=(20,30), rows=10, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = 10 # len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(0,50):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(list(batches.class_indices.keys())[np.argmax(titles[i])], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b64f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(imgs, titles = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = batches.class_indices.keys()\n",
    "perc = (sum(labels)/labels.shape[0])*100\n",
    "\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(classes,perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "# we do not need to apply one-hot encoding to the labels as in https://keras.io/examples/vision/swin_transformers/\n",
    "# since the dataset data is already prepared for the multi-class classification\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914ebbb",
   "metadata": {},
   "source": [
    "# CoatNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6ea8f",
   "metadata": {},
   "source": [
    "**CoAtNet** is a hybrid neural network architecture where the best of CNN and Attention-based transformer models is conjugated in a single model architecture. It has been invented Zihang Dai, Hanxiao Liu, Quoc V. Le, and Mingxing Tan from Google Research team (their inventions published in https://arxiv.org/pdf/2106.04803.pdf).\n",
    "\n",
    "Transformers have attracted increasing interests in computer vision/image pattern recognition. However, they still fall behind the state-of-the-art convolutional networks. \n",
    "\n",
    "The authors of **CoAtNet** demonstrated that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, they invented CoAtNets, a family of hybrid models built from two key insights: \n",
    "\n",
    "- (1) depthwise Convolution and self-Attention can be naturally unified via simple relative attention. \n",
    "- (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency.\n",
    "\n",
    "In the scope of this case study, the implementation of CoatNet from *Keras_cv_attention_models* Python package (per https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/convnext) has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_cv_attention_models import coatnet\n",
    "# requires \n",
    "input_shape=(64,64,3)  # (64,64,3) \n",
    "num_epochs = 40\n",
    "\n",
    "batch_size = 128 # 128\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "num_epochs = 40\n",
    "validation_split = 0.1\n",
    "weight_decay = 0.0001\n",
    "label_smoothing = 0.1\n",
    "\n",
    "model = coatnet.CoAtNet0(\n",
    "    input_shape=input_shape, \n",
    "    num_classes=num_classes, \n",
    "    drop_connect_rate=0.2,\n",
    "    classifier_activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "    optimizer=tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    ),\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',patience=4, verbose=1,  factor=0.4, min_lr=0.0001)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0.00001, patience=8, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_fit = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_split=validation_split,\n",
    "    verbose =1,\n",
    "    callbacks=[early_stop,lr_reduction]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830297c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d690d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(model_fit.history['loss'], label='train loss')\n",
    "plt.plot(model_fit.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Swin_LossVal_loss.jpg',format='jpg')\n",
    "\n",
    "plt.close()\n",
    "# plot the accuracy\n",
    "plt.plot(model_fit.history['accuracy'], label='train acc')\n",
    "plt.plot(model_fit.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Swin_AccVal_acc.jpg',format=\"jpg\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e1d76",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = model.predict(x_test, verbose=0) \n",
    "y_pred=np.argmax(pred_x,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebe82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = np.argmax(y_test, axis=1)\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66810069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "c_matrix = metrics.confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec150641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231172c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names= batches.class_indices.keys()\n",
    "confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Print the precision and recall, among other metrics\n",
    "report =  metrics.classification_report(y_test2, y_pred, digits=3, output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose().reset_index()\n",
    "df = df.rename(columns={\"index\": \"class_label\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5be18a",
   "metadata": {},
   "source": [
    "Let's review the part of the classification report related to each individual class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cfbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rep = metrics.precision_recall_fscore_support(y_test2, y_pred)\n",
    "out_dict = {\n",
    "             \"precision\" : clf_rep[0].round(3)\n",
    "            ,\"recall\" : clf_rep[1].round(3)\n",
    "            ,\"f1-score\" : clf_rep[2].round(3)\n",
    "            ,\"support\" : clf_rep[3]\n",
    "            }\n",
    "out_df = pd.DataFrame(out_dict).reset_index().rename(columns={\"index\": \"class_label\"})\n",
    "class_label_values = dict(zip(range(0,len(batches.class_indices)), batches.class_indices))\n",
    "out_df['class_label'] = out_df['class_label'].map(class_label_values)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e53194",
   "metadata": {},
   "source": [
    "Now let's review the aggregated values from  the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display aggregated values - selecting rows based on condition \n",
    "options = ['accuracy', 'macro avg',  'weighted avg']\n",
    "agg_df = df[df['class_label'].isin(options)]\n",
    "agg_df"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
