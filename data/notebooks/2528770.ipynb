{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1691e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01561378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.author.value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f966d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop = train_df[train_df['author'] == \"HPL\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c769183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(index_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f513d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.author.value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1011bf",
   "metadata": {},
   "source": [
    "## Downloading BERT Addon From Official GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.author = (train_df.author == \"EAP\").astype('uint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Files,Model And Configurations from -- https://github.com/google-research/bert\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd051c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_folder'\n",
    "with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ce1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
    "BERT_PRETRAINED_DIR = f'{folder}/uncased_L-12_H-768_A-12'\n",
    "OUTPUT_DIR = f'{folder}/outputs'\n",
    "print(f'>> Model output directory: {OUTPUT_DIR}')\n",
    "print(f'>>  BERT pretrained directory: {BERT_PRETRAINED_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df = train_df.sample(5000)\n",
    "train, test = train_test_split(train_df, test_size = 0.4, random_state=1326)\n",
    "train_lines, train_labels = train.text.values, train.author.values\n",
    "test_lines, test_labels = test.text.values, test.author.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(lines, set_type, labels=None):\n",
    "#Generate data for the BERT model\n",
    "    guid = f'{set_type}'\n",
    "    examples = []\n",
    "    if guid == 'train':\n",
    "        for line, label in zip(lines, labels):\n",
    "            text_a = line\n",
    "            label = str(label)\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    else:\n",
    "        for line in lines:\n",
    "            text_a = line\n",
    "            label = '0'\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    return examples\n",
    "\n",
    "# Model Hyper Parameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000 #if you wish to finetune a model on a larger dataset, use larger interval\n",
    "# each checpoint weights about 1,5gb\n",
    "ITERATIONS_PER_LOOP = 1000\n",
    "NUM_TPU_CORES = 8\n",
    "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
    "\n",
    "label_list = ['0', '1']\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
    "train_examples = create_examples(train_lines, 'train', labels=train_labels)\n",
    "\n",
    "tpu_cluster_resolver = None #Since training will happen on GPU, we won't need a cluster resolver\n",
    "#TPUEstimator also supports training on CPU and GPU. You don't need to define a separate tf.estimator.Estimator.\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=INIT_CHECKPOINT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available  \n",
    "    use_one_hot_embeddings=True)\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available \n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df742f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please wait...')\n",
    "train_features = run_classifier.convert_examples_to_features(\n",
    "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "print('>> Started training at {} '.format(datetime.datetime.now()))\n",
    "print('  Num examples = {}'.format(len(train_examples)))\n",
    "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_fn = run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print('>> Finished training at {}'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There is a weird bug in original code.\n",
    "When predicting, estimator returns an empty dict {}, without batch_size.\n",
    "I redefine input_fn_builder and hardcode batch_size, irnoring 'params' for now.\n",
    "\"\"\"\n",
    "\n",
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  all_input_ids = []\n",
    "  all_input_mask = []\n",
    "  all_segment_ids = []\n",
    "  all_label_ids = []\n",
    "\n",
    "  for feature in features:\n",
    "    all_input_ids.append(feature.input_ids)\n",
    "    all_input_mask.append(feature.input_mask)\n",
    "    all_segment_ids.append(feature.segment_ids)\n",
    "    all_label_ids.append(feature.label_id)\n",
    "\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    print(params)\n",
    "    batch_size = 500\n",
    "\n",
    "    num_examples = len(features)\n",
    "\n",
    "    d = tf.data.Dataset.from_tensor_slices({\n",
    "        \"input_ids\":\n",
    "            tf.constant(\n",
    "                all_input_ids, shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"input_mask\":\n",
    "            tf.constant(\n",
    "                all_input_mask,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"segment_ids\":\n",
    "            tf.constant(\n",
    "                all_segment_ids,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"label_ids\":\n",
    "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "    })\n",
    "\n",
    "    if is_training:\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d582882",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_examples = create_examples(test_lines, 'test')\n",
    "\n",
    "predict_features = run_classifier.convert_examples_to_features(\n",
    "    predict_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "predict_input_fn = input_fn_builder(\n",
    "    features=predict_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "preds = []\n",
    "for prediction in tqdm(result):\n",
    "      preds.append(float(prediction['probabilities'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = (np.array(preds) > 0.50).astype('uint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "print(\">> Spooky Author Experiment (2 Classes Only)\")\n",
    "print(\">> F1 Score on 4500 trained samples: \", f1_score(test_labels, PREDICTIONS))\n",
    "print(\">> ROC AUC  on 4500 trained samples: \", roc_auc_score(test_labels, preds))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
