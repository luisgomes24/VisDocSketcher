{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89e554a",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            border : #015a2c solid;\n",
    "            background-color:#ecfff5;\n",
    "           font-size:110%;\n",
    "           letter-spacing:0.5px;\n",
    "            text-align: center\">\n",
    "\n",
    "<center><h1 style=\"padding: 25px 0px; color:#015a2c; font-weight: bold; font-family: Cursive\">\n",
    "üê± Cats vs. Dogs üê∂</h1></center>\n",
    "<center><h3 style=\"padding-bottom: 25px; color:#015a2c; font-weight: bold; font-style:italic; font-family: Cursive\">\n",
    "(CNN model - Image augmentation - Transfer learning)</h3></center>     \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415648dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb4fdf",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d01dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9492cfe",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fb8e3",
   "metadata": {},
   "source": [
    "# Import & organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\", 'r')\n",
    "zip_df.extractall(\"/kaggle/working/\")\n",
    "zip_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34876d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = '/kaggle/working/train'\n",
    "base_dir = '/kaggle/working/catVsdog'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "# ------------------------------------\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# ------------------------------------\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(10000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(10000, 12500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# --------------------------------------------------------------\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(10000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(10000, 12500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32760e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4dd35",
   "metadata": {},
   "source": [
    "# 1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(learning_rate=1e-4),\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf51eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# --------------------------------------\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(150, 150),  \n",
    "        batch_size=100,\n",
    "        class_mode='binary')\n",
    "\n",
    "# --------------------------------------\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=50,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf02359",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=200,  # 20000 train images = batch_size * steps\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100  # 5000 validation images = batch_size * steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7a3da",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Cursive; font-size:16px; background-color:#ecfff5; padding: 25px 20px\">\n",
    "The plot above shows the pattern of overfitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefca60",
   "metadata": {},
   "source": [
    "# 2. Data augmentation and Dropout layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524a587",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; font-family: Cursive; border: solid 2px #015a2c;\n",
    "            font-size:15.5px;padding: 25px 10px; border-radius:8px;\">\n",
    "<p>There are several ways to prevent overfitting, two of which are:</p>\n",
    "<ol>\n",
    "    <li>Dropout layer</li>\n",
    "    <li>Data augmentation</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2ebdd",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; font-family: Cursive; border: solid 2px #015a2c;\n",
    "            font-size:15.5px;padding: 25px 10px; border-radius:8px;\">\n",
    "<h3>What is Dropout? ü§î</h3>\n",
    "<p>A single model can be used to simulate having a large number of different network architectures by randomly dropping out nodes during training. This is called dropout and offers a very computationally cheap and remarkably effective regularization method to reduce overfitting and improve generalization error in deep neural networks of all kinds. <a href =\"https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\">ref</a>\n",
    "<br><br> The following figure shows a network with dropout.\n",
    "</p>    \n",
    "<img width =90% src=\"https://miro.medium.com/max/1400/1*iWQzxhVlvadk6VAJjsgXgg.png\" alt=\"dropout\"  class=\"center\"> \n",
    "<center><a href = \"https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\">image source</a></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f0519",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; font-family: Cursive; border: solid 2px #015a2c;\n",
    "            font-size:15.5px;padding: 25px 10px; border-radius:8px;\">\n",
    "<h3>What is image data augmentation? üßê</h3>\n",
    "<p>image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.<br> Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images. <a href =\"https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\">ref</a></p>\n",
    "<p>Some image augmentation techniques include:</p>\n",
    "<ul>\n",
    "    <li>Image shifts</li>    \n",
    "    <li>Image flips</li>\n",
    "    <li>Image rotations</li>\n",
    "    <li>Image zoom</li>\n",
    "    <li>and ...</li>\n",
    "</ul>\n",
    "<p>The following figure shows the augmentation of a cat image.</p>\n",
    "<img src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2021/05/tf_data_data_aug_sequential.png?lossy=1&strip=1&webp=1\" alt=\"augmentation\"  class=\"center\" height=100%> \n",
    "<center><a href = \"https://pyimagesearch.com/2021/06/28/data-augmentation-with-tf-data-and-tensorflow/\">image source</a></center>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_augmentation = ImageDataGenerator(rescale=1./255,\n",
    "                                                rotation_range=50,\n",
    "                                                width_shift_range=0.2,\n",
    "                                                height_shift_range=0.2,\n",
    "                                                shear_range=0.25,\n",
    "                                                zoom_range=0.2,\n",
    "                                                horizontal_flip=True,\n",
    "                                                fill_mode='nearest')\n",
    "\n",
    "\n",
    "train_generator = train_datagen_augmentation.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(150, 150),  \n",
    "        batch_size=100,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baedb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_cat = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
    "\n",
    "img_path = fname_cat[20]\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "for batch in train_datagen_augmentation.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdb2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_dog = [os.path.join(train_dogs_dir, fname) for fname in os.listdir(train_dogs_dir)]\n",
    "\n",
    "img_path = fname_dog[25]\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "for batch in train_datagen_augmentation.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model_2.add(layers.MaxPooling2D(2, 2))\n",
    "model_2.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D(2,2))\n",
    "model_2.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(512, activation='relu'))\n",
    "model_2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(learning_rate=1e-4),\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_2.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=200,  # 20000 train images = batch_size * steps\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100  # 5000 validation images = batch_size * steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc807ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b43f4e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Cursive; font-size:16px; background-color:#ecfff5; padding: 25px 20px\">\n",
    "To increase accuracy, we can use transfer learning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83a245",
   "metadata": {},
   "source": [
    "# 3. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a1d4f",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; font-family: Cursive; border: solid 2px #015a2c;\n",
    "            font-size:15.5px;padding: 25px 10px; border-radius:8px;\">\n",
    "<h3>What is Transfer Learning?</h3>\n",
    "<p>Transfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task. <a href =\"https://machinelearningmastery.com/transfer-learning-for-deep-learning/\">ref</a> <br> We can use 2 below strategies  for doing transfer learning:</p>\n",
    "<ol>\n",
    "    <li>Feature extraction</li>\n",
    "    <p>Instead of using the model end-to-end as in the previous example, we can treat the pre-trained neural network as a feature extractor by discarding the last fully-connected output layer. This approach allows us to directly apply new dataset to solve an entirely different problem. <a href =\"https://towardsdatascience.com/what-is-deep-transfer-learning-and-why-is-it-becoming-so-popular-91acdcc2717a\">ref</a></p>\n",
    "    <li>Fine-tuning</li>\n",
    "    <p>Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task. <a href =\"https://www.tensorflow.org/tutorials/images/transfer_learning\">ref</a></p>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bed84b",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            background-color:#ffffff;\n",
    "            border-style: solid;\n",
    "            border-color: #015a2c;\n",
    "            letter-spacing:0.5px;\">\n",
    "\n",
    "<center><h3 style=\"padding: 5px 0px; color:#015a2c; font-weight: bold; font-family: Cursive\">\n",
    "1. Feature extraction</h3></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(base_model)\n",
    "model_3.add(layers.Flatten())\n",
    "model_3.add(layers.Dense(512, activation='relu'))\n",
    "model_3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(learning_rate=1e-4),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2bdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af684d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the base model:', len(model_3.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21297172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the base model:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_3.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=200,  # 20000 train images = batch_size * steps\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100  # 5000 validation images = batch_size * steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e9bfa",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            background-color:#ffffff;\n",
    "            border-style: solid;\n",
    "            border-color: #015a2c;\n",
    "            letter-spacing:0.5px;\">\n",
    "\n",
    "<center><h3 style=\"padding: 5px 0px; color:#015a2c; font-weight: bold; font-family: Cursive\">\n",
    "2. Fine-Tuning</h3></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d041ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in base_model.layers:\n",
    "    print(\"layer name is : \",l.name,\" ** trainable is \", l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "tmp = False\n",
    "for l in base_model.layers:\n",
    "    if l.name == \"block5_conv1\":\n",
    "        tmp = True\n",
    "    if tmp:\n",
    "        l.trainable = True\n",
    "    else:\n",
    "        l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(learning_rate=1e-4),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_3.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=200,  # 20000 train images = batch_size * steps\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=100,  # 5000 validdation images = batch_size * steps\n",
    "      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f358c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a74e8",
   "metadata": {},
   "source": [
    "# References:\n",
    "* https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "* https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "* https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "* https://machinelearningmastery.com/transfer-learning-for-deep-learning/\n",
    "* https://towardsdatascience.com/what-is-deep-transfer-learning-and-why-is-it-becoming-so-popular-91acdcc2717a\n",
    "* https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac781de9",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            background-color:#ffffff;\n",
    "            border-style: solid;\n",
    "            border-color: #015a2c;\n",
    "            letter-spacing:0.5px;\">\n",
    "\n",
    "<center><h4 style=\"padding: 5px 0px; color:#015a2c; font-weight: bold; font-family: Cursive\">\n",
    "    Thanks for your attention and for reviewing my notebook.üôå <br><br>Please write your comments for me.üìù</h4></center>\n",
    "<center><h4 style=\"padding: 5px 0px; color:#015a2c; font-weight: bold; font-family: Cursive\">\n",
    "If you liked my work and found it useful, please upvote. Thank youüôè</h4></center>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
