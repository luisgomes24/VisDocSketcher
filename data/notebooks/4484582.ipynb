{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df2208e",
   "metadata": {},
   "source": [
    "In this notebook, I \n",
    "- visualize the dataset. \n",
    "- some basic image enhancement techniques using skiimage.\n",
    "- Many images have multiple annotations. I show how to select according to value counts and visualize it \n",
    "\n",
    "\n",
    "You may find the following links useful\n",
    "- [EDA](https://www.kaggle.com/peterchang77/exploratory-data-analysis)\n",
    "\n",
    "I will keep updating the kernel as i explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940f694",
   "metadata": {},
   "source": [
    "# Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde07d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage as ndi\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "import tqdm\n",
    "import gc\n",
    "gc.enable()\n",
    "import glob\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage as ndi\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation/')\n",
    "from mask_functions import rle2mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5533899",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4727d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files = glob.glob('../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm')\n",
    "len(sample_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15504af5",
   "metadata": {},
   "source": [
    "# Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/siim-acr-pneumothorax-segmentation/sample images/train-rle-sample.csv',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78520a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "def cvshow(image, format='.png', rate=255 ):\n",
    "    decoded_bytes = cv2.imencode(format, image*rate)[1].tobytes()\n",
    "    display(Image(data=decoded_bytes))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa809538",
   "metadata": {},
   "source": [
    "# Visualizing Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "nImg = 10\n",
    "img_ar = np.empty(0)\n",
    "while img_ar.shape[0]!=nImg:\n",
    "#     dcm_file = '../input/../input/sample images/%s.dcm' % patientId\n",
    "    dcm_file = sample_files[j]\n",
    "    dcm_data = pydicom.read_file(dcm_file)\n",
    "    img = np.expand_dims(dcm_data.pixel_array,axis=0)    \n",
    "    if j==0:\n",
    "        img_ar = img\n",
    "    elif (j%100==0):\n",
    "        print(j,'images loaded')\n",
    "    else:\n",
    "        img_ar = np.concatenate([img_ar,img],axis=0)\n",
    "    j += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f289e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgtile(imgs,tile_w):\n",
    "    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n",
    "    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n",
    "    return np.hstack(np.hstack(r))\n",
    "\n",
    "#usage\n",
    "tiled = imgtile(img_ar,5)\n",
    "# cvshow(tiled)\n",
    "tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvshow(cv2.resize( tiled, (1024,512), interpolation=cv2.INTER_LINEAR ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f035ffd",
   "metadata": {},
   "source": [
    "These are some of the traditional ways to enhance an image. I used these techniques a lot but now deep learning has made them obsolete. You can find some visualization below.\n",
    "\n",
    "## Rescaling Intensity\n",
    "Using this function we can stretch/shrink its intensity levels.\n",
    "\n",
    "## Contrast Limited Adaptive Histogram Equalization (CLAHE).\n",
    "\n",
    "An algorithm for local contrast enhancement, that uses histograms computed\n",
    "over different tile regions of the image. Local details can therefore be\n",
    "enhanced even in regions that are darker or lighter than most of the image.\n",
    "\n",
    "## Logarithmic Correction\n",
    "\n",
    "This function transforms the input image pixelwise according to the\n",
    "equation $O = gain*log(1 + I)$ after scaling each pixel to the range 0 to 1.\n",
    "\n",
    "## Gamma Correction\n",
    "\n",
    "Also known as Power Law Transform.\n",
    "This function transforms the input image pixelwise according to the\n",
    "equation $O = I*gamma$ after scaling each pixel to the range 0 to 1.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68114943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple ways to enhance the image\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.subplots_adjust(bottom=0.2, top=0.7, hspace=0)  #adjust this to change vertical and horiz. spacings..\n",
    "nImg = 3  #no. of images to process\n",
    "for j in range(nImg):\n",
    "    q = j+1\n",
    "    img = np.array(pydicom.read_file(sample_files[j]).pixel_array)\n",
    "    \n",
    "#     # Contrast stretching\n",
    "    p2, p97 = np.percentile(img, (2, 97))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p97))\n",
    "    \n",
    "    # Equalization\n",
    "    img_eq = exposure.equalize_hist(img)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(img)\n",
    "    img_adjustlog = exposure.adjust_log(img)\n",
    "    img_adjustgamma = exposure.adjust_gamma(img)\n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-6)\n",
    "    plt.imshow(img, cmap=plt.cm.bone)\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-5)    \n",
    "    plt.imshow(img_rescale, cmap=plt.cm.bone)\n",
    "    plt.title('Contrast stretching')\n",
    "    \n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-4)\n",
    "    plt.imshow(img_eq, cmap=plt.cm.bone)\n",
    "    plt.title('Equalization')\n",
    "    \n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-3)\n",
    "    plt.imshow(img_adapteq, cmap=plt.cm.bone)\n",
    "    plt.title('Adaptive Equalization')\n",
    "    \n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-2)\n",
    "    plt.imshow(img_adjustgamma, cmap=plt.cm.bone)\n",
    "    plt.title('Adjust Gamma')\n",
    "    \n",
    "    plt.subplot(nImg,7,q*7-2)\n",
    "    plt.imshow(img_adjustlog, cmap=plt.cm.bone)\n",
    "    plt.title('Adjust Log')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b6f93",
   "metadata": {},
   "source": [
    "To download images you need to create an account on Google Cloud Products (GCP) and go through a series of messy process.. Providing the data on kaggle would have been so much easier!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-train/*/*/*.dcm'\n",
    "test_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-test/*/*/*.dcm'\n",
    "train_fns = sorted(glob.glob(train_glob))\n",
    "test_fns = sorted(glob.glob(test_glob))\n",
    "df_mask = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/train-rle.csv', index_col='ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57053b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mask),len(set(df_mask.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask_dist = df_mask.copy(deep=True)\n",
    "df_mask_dist.reset_index(inplace=True)\n",
    "\n",
    "df = pd.DataFrame(df_mask_dist.ImageId.value_counts()).reset_index()\n",
    "df.columns = ['ImageId','counts']\n",
    "\n",
    "df_mask_dist = pd.merge(df_mask_dist,df,on='ImageId')\n",
    "df_mask_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask_dist.counts.plot.hist()\n",
    "plt.xlabel('Number of Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea05d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(im_path,im_type,df_mask=df_mask):\n",
    "    if im_type=='train':\n",
    "        return pydicom.dcmread(im_path).pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6feafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn_id = [val.split('/')[-1][:-4] for val in train_fns]\n",
    "print(len(set(train_fn_id).intersection(set(df_mask_dist.ImageId))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_count_gt_one = set(df_mask_dist[df_mask_dist.counts>4].ImageId.values)\n",
    "print('Number of masks with annotations greater than 5:',(df_mask_dist.counts>5).sum())\n",
    "common_masks =  list(set(train_fn_id).intersection(masks_count_gt_one))\n",
    "print(len(common_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nImg = 12  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "sel_train_fns = [train_fns[train_fn_id.index(c_m)] for c_m in common_masks]\n",
    "\n",
    "_train_ids = list(sel_train_fns)\n",
    "np.random.shuffle(_train_ids)\n",
    "_train_ids = _train_ids[:nImg]\n",
    "tile_size = (256, 256)\n",
    "n = 4\n",
    "alpha = 0.25\n",
    "\n",
    "m = int(np.ceil(len(_train_ids) * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 1), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 1), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    for j in range(n):\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        if counter == len(_train_ids):\n",
    "            break\n",
    "        image_path = _train_ids[counter]; counter+=1\n",
    "        img = get_image_data(image_path, 'train')\n",
    "        \n",
    "        num_annot = len(df_mask.loc[image_path.split('/')[-1][:-4]].values)\n",
    "#         print('num_annot',num_annot)\n",
    "        for i in range(num_annot):\n",
    "            mask =  rle2mask(df_mask.loc[image_path.split('/')[-1][:-4]].iloc[i][0], 1024, 1024).T\n",
    "            \n",
    "        mask = mask.astype(np.uint8)\n",
    "        \n",
    "        img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n",
    "#         img_masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        img = cv2.resize(img, dsize=tile_size)\n",
    "        img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "        \n",
    "        img_masked = cv2.putText(img_masked, image_path.split('/')[-1][:-4], (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "        complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,None]\n",
    "        \n",
    "    if counter == len(_train_ids):\n",
    "        break    \n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image_masked[ys:ye,:,0],cmap='bone')\n",
    "    plt.title(\"Training dataset: Lighter Color depicts mask\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
