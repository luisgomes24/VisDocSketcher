{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57807838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop  displaying warning messages in output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# To  collect garbage (delete files)\n",
    "import gc\n",
    "# To save dataset as pcikle file for future use\n",
    "import pickle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# for basic math operations like sqrt\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfaa34",
   "metadata": {},
   "source": [
    "Importing master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(\"../input/rapido-rides/ct_rr.csv\")\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d3a8c",
   "metadata": {},
   "source": [
    "### Removing any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data size before removing: \",input_data.shape)\n",
    "\n",
    "# Check duplicated rows in train set\n",
    "df = input_data[input_data.duplicated()]  # checks duplicate rows considering all columns\n",
    "print(\"Number of duplicate observations: \", len(df))\n",
    "del df\n",
    "gc.collect();\n",
    "\n",
    "#Dropping duplicates and keeping first occurence only\n",
    "input_data.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "print(\"Data size after removing: \",input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d23e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d07059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique customers: \" ,input_data[\"number\"].nunique()) #number of distinct customers = 1.7 lakhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cba56",
   "metadata": {},
   "source": [
    "The number of customers are 1.7 lakhs. Therefore,it won't be practically feasible to predict forecast for each customer. So, we can drop that column.\n",
    "\n",
    "Converting timestamp to month number, year number etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "new = input_data[\"ts\"].str.split(\" \", n = 1, expand = True) \n",
    "  \n",
    "# making separate first name column from new data frame \n",
    "input_data[\"raw_date\"]= new[0] \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "input_data[\"raw_time\"]= new[1] \n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f45ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "new = input_data[\"raw_date\"].str.split(\"-\", n = 2, expand = True) \n",
    "  \n",
    "# making separate first name column from new data frame \n",
    "input_data[\"year\"]= new[0] \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "input_data[\"month\"]= new[1] \n",
    "\n",
    "# making separate last name column from new data frame \n",
    "input_data[\"date\"]= new[2] \n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94975f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "new = input_data[\"raw_time\"].str.split(\":\", n = 2, expand = True) \n",
    "  \n",
    "# making separate first name column from new data frame \n",
    "input_data[\"hour\"]= new[0]\n",
    "#24:00 time system\n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "input_data[\"minute\"]= new[1] \n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6be16a",
   "metadata": {},
   "source": [
    "Forecasting at minute level won't add much information. So we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da16bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing cols which are not reqd.\n",
    "data = input_data.copy()\n",
    "data.drop([\"ts\",\"raw_date\",\"raw_time\",\"number\",\"minute\"],axis=1, inplace=True)\n",
    "data.head()\n",
    "\n",
    "del input_data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa814ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is there any missing value? \",data.isna().sum().sum()>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd49d8",
   "metadata": {},
   "source": [
    "Creating distance variable using latitude and longitude given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pick_lat, pick_lng, drop_lat, drop_lng):\n",
    "    \n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    s_lat = pick_lat*np.pi/180.0                      \n",
    "    s_lng = np.deg2rad(pick_lng)     \n",
    "    e_lat = np.deg2rad(drop_lat)                       \n",
    "    e_lng = np.deg2rad(drop_lng)  \n",
    "    \n",
    "    d = np.sin((e_lat - s_lat)/2)**2 + np.cos(s_lat)*np.cos(e_lat) * np.sin((e_lng - s_lng)/2)**2\n",
    "    \n",
    "    return round(2 * R * np.arcsin(np.sqrt(d)),1)    #rounding off distance in km to 1 decimal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"distance\"] = data.apply(lambda x: distance(x.pick_lat, x.pick_lng, x.drop_lat, x.drop_lng), axis=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b07385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming avg. bike speed of 35km/hrs, we can calculate time in min.\n",
    "avg_speed = 35/60 #speed in km/minutes\n",
    "data[\"ride_minutes\"] = data[\"distance\"].apply(lambda x: round(x/avg_speed,0))\n",
    "\n",
    "print(\"Maximum ride distance covered in Km: \", data.distance.max())\n",
    "print(\"Minimum ride distance covered in Km: \", data.distance.min())\n",
    "print(\"Maximum ride time in mins: \",data.ride_minutes.max())\n",
    "print(\"Minimum ride time in mins: \", data.ride_minutes.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f7813",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71292c1f",
   "metadata": {},
   "source": [
    "Plotting latitudes and longitudes to see distribution based on lat and long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60508536",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=data['pick_lng'], y=data['pick_lat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=data['drop_lng'], y=data['drop_lat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50db79",
   "metadata": {},
   "source": [
    "Assuming the data given to us is for india geography only. It will also help to remove outliers \n",
    "that might lie in entering data for lat and long for India geography.\n",
    "Therefore, we can remove  invalid latitude and longitudes\n",
    "For India, longitude: (66, 90), latitude: (8, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.pick_lng <90) & (data.drop_lng <90) & (data.pick_lng >66) & (data.drop_lng >66) &\n",
    "       (data.pick_lat <40) & (data.drop_lat <40) & (data.pick_lat >8) & (data.drop_lat >8)]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85381d84",
   "metadata": {},
   "source": [
    "We can see it removed around 10K obs. Such small number as compared to data size could clearly imply outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4583075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after removing above outliers based on lat and long\n",
    "\n",
    "print(\"Maximum ride distance covered in Km: \", data.distance.max())\n",
    "print(\"Minimum ride distance covered in Km: \", data.distance.min())\n",
    "print(\"Maximum ride time in mins: \",data.ride_minutes.max())\n",
    "print(\"Minimum ride time in mins: \", data.ride_minutes.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b597f",
   "metadata": {},
   "source": [
    "Plotting latitudes and longitudes to see distribution after removing outliers based on lat and long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c548ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=data['pick_lng'], y=data['pick_lat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=data['drop_lng'], y=data['drop_lat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e8705",
   "metadata": {},
   "source": [
    "Hourly distibution of rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a67eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"hour\", data=data)  #plot counts of variabe in bars form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96ebbd",
   "metadata": {},
   "source": [
    "We can see that demand surges at 8-10am and 6-8pm, which is typical due to people asking for rides to office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot('ride_minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d23a5",
   "metadata": {},
   "source": [
    "RIDE DISTANCE: On observing the plot, we see that the distribution of distance is continuous in the sense that there does not seem\n",
    "to be an outlier. However, the ride distance of more than 2000km is spurious which needs to be confirmed with business teams.\n",
    "Similarly there are 21K obervations with ride distance <=0Km. Although we rounded off distance to 1 decimal place. So, ride for less\n",
    "than 100meters again seems spurious and can be removed.\n",
    "\n",
    "RIDE TIME: This is directly proportional to ride distance.\n",
    "Right now we can clip values to 1% and 99%tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a08750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(data):\n",
    "    data_X = data.copy()\n",
    "    for col in ['distance','ride_minutes']:\n",
    "        percentiles = data_X[col].quantile([0.01,0.99]).values\n",
    "        data_X[col][data_X[col] <= percentiles[0]] = percentiles[0]\n",
    "        data_X[col][data_X[col] >= percentiles[1]] = percentiles[1]\n",
    "    \n",
    "    return data_X\n",
    "\n",
    "data = outlier_treatment(data)\n",
    "print(\"After outlier treatment: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot('ride_minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8945896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before removing outliers: \", data.shape)\n",
    "data = data[(data.ride_minutes<16) & (data.distance<11)]\n",
    "print(\"After removing outliers: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after removing above outliers based on lat and long\n",
    "\n",
    "print(\"Maximum ride distance covered in Km: \", data.distance.max())\n",
    "print(\"Minimum ride distance covered in Km: \", data.distance.min())\n",
    "print(\"Maximum ride time in mins: \",data.ride_minutes.max())\n",
    "print(\"Minimum ride time in mins: \", data.ride_minutes.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c99648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique year present:\",data.year.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af6fd7",
   "metadata": {},
   "source": [
    "Downcasting variables to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385116a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pick_lat'] = pd.to_numeric(data['pick_lat'], downcast='float')\n",
    "data['pick_lng'] = pd.to_numeric(data['pick_lng'], downcast='float')\n",
    "data['drop_lat'] = pd.to_numeric(data['drop_lat'], downcast='float')\n",
    "data['drop_lng'] = pd.to_numeric(data['drop_lng'], downcast='float')\n",
    "data['distance'] = pd.to_numeric(data['distance'], downcast='float')\n",
    "\n",
    "data['month']= pd.to_numeric(data['month'], downcast='unsigned')\n",
    "data['year']= pd.to_numeric(data['year'], downcast='unsigned')\n",
    "data['hour']= pd.to_numeric(data['hour'], downcast='unsigned')\n",
    "\n",
    "data['ride_minutes']= pd.to_numeric(data['ride_minutes'], downcast='unsigned')\n",
    "\n",
    "data['date']= pd.to_numeric(data['date'], downcast='unsigned')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36211ef1",
   "metadata": {},
   "source": [
    "Creating new month variable to counter month number for new year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_month(row):\n",
    "    if row['year']>2018:\n",
    "        return (12 + row['month'])\n",
    "    else:\n",
    "        return row['month']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1856545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"new_month\"] = data.apply(change_month, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88851",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"new_month\", data=data)  #plot counts of variabe in bars form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f75bd2d",
   "metadata": {},
   "source": [
    "we see that we have only 13 months of data from April 2018 to April 2019. The number of rides are continously inc which means there might\n",
    "be new riders registering for the service. However, #rides for April 2019 went drastically down which might be due to unavailability of \n",
    "full data as it is last month in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating price based features using price surge\n",
    "peak_intensity = {0:1, 1 : 1.1, \t2 : 1.1, \t3 : 1.1, \t4 : 1.1, \t5 : 1, \t6 : 1, \t7 : 1.1, \t8 : 1.2, \t9 : 1.2, \t10 : 1.1, \t11 : 1, \n",
    "                  12 : 1, \t13 : 1, \t14 : 1, \t15 : 1, \t16 : 1, \t17 : 1.05, \t18 : 1.1, \t19 : 1.2, \t20 : 1.2, \t21 : 1.1, \t\n",
    "                  22 : 1, \t23 : 1}\n",
    "\n",
    "data['price_surge'] = data['hour'].map(peak_intensity)\n",
    "\n",
    "#defining ride price in rs. assuming 7rs per km\n",
    "def price_define(row):\n",
    "    ride_price = row['distance']*7*row['price_surge']\n",
    "    return ride_price\n",
    "\n",
    "data[\"ride_price\"] = data.apply(price_define, axis=1)\n",
    "data.drop(['price_surge'],axis=1,inplace=True)\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600018e",
   "metadata": {},
   "source": [
    "The workspace got full on performing above operations so, saving data till last step. It will be used in next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56356ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"rapido_v_save\"     #type name of file to be saved as\n",
    "with open(model_file,mode='wb') as model_f:\n",
    "    pickle.dump(data,model_f)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
