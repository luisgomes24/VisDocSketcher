{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "import pickle \n",
    "import os \n",
    "import numpy as np\n",
    "import cv2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385a1cf",
   "metadata": {},
   "source": [
    "<h2>Process the images and resize them to the preferred size </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5496423",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 200\n",
    "def get_training_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3052a8b",
   "metadata": {},
   "source": [
    "<h2>Preparing the training and testing data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\n",
    "test = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\n",
    "val = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d741a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnenumonia = 0 \n",
    "normal = 0 \n",
    "\n",
    "for i, j in train:\n",
    "    if j == 0:\n",
    "        pnenumonia+=1\n",
    "    else:\n",
    "        normal+=1\n",
    "        \n",
    "print('Pneumonia:', pnenumonia)\n",
    "print('Normal:', normal)\n",
    "print('Pneumonia - Normal:', pnenumonia-normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d1c403",
   "metadata": {},
   "source": [
    "<h2>Visualize training images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[1][0], cmap='gray')\n",
    "plt.axis('off')\n",
    "print(labels[train[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ad177",
   "metadata": {},
   "source": [
    "<h2 >We are incoprating the validation data into the training data because it does not contain enough examples. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a131a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for feature, label in train:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "# resize data for deep learning \n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_val = X_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca10063",
   "metadata": {},
   "source": [
    "Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good for balancing out disproportions in the dataset \n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=90, \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=True)  \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b115b1a",
   "metadata": {},
   "source": [
    "<h2 >CNN (Convolutional Neural Network) </h2>\n",
    "Image source: https://www.researchgate.net/publication/321286547/figure/download/fig6/AS:564402564472832@1511575465150/A-convolutional-neural-networks-CNN.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fad2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "early_stop = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=10), callbacks=[early_stop], validation_data=(X_val, y_val), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b802f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3c288",
   "metadata": {},
   "source": [
    "<h2>Visualizing our training progress</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['val_acc'])\n",
    "plt.title('Model Validation Accuracy')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['val_loss'])\n",
    "plt.title('Model Validation Loss')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3f0c1",
   "metadata": {},
   "source": [
    "<h2>Prepare data for precision vs. recall and ROC</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, pred)\n",
    "fpr, tpr, thresholds2 = roc_curve(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-')\n",
    "    plt.title('Precision vs. Recall')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.legend(['Precision', 'Recall'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title('FPR (False Positive rate) vs TPR (True Positive Rate)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.show()\n",
    "    \n",
    "plot_precision_recall(precisions, recalls, thresholds)\n",
    "plot_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112be77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889daf6b",
   "metadata": {},
   "source": [
    "<h2>Set thresholds for our model, we want the results to be precise while not sacraficing too much recall </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04547ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = []\n",
    "threshold = thresholds[np.argmax(precisions >= 0.80)]\n",
    "for i in predictions:\n",
    "    if i >= threshold:\n",
    "        binary_predictions.append(1)\n",
    "    else:\n",
    "        binary_predictions.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c13101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\n",
    "print('Precision on testing set:', precision_score(binary_predictions, y_test))\n",
    "print('Recall on testing set:', recall_score(binary_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff3735",
   "metadata": {},
   "source": [
    "<h2>Plotting the confusion matrix. Here is how we interpet one. </h2>\n",
    "\n",
    "Image source: https://silvrback.s3.amazonaws.com/uploads/4ab81a17-4a77-4e9e-b092-de5fac2afa07/confusionmatrix_large.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84393190",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(binary_predictions, y_test)\n",
    "plt.figure(figsize=(16, 9))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix, annot=True, ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted Labels', size=20)\n",
    "ax.set_ylabel('True Labels', size=20)\n",
    "ax.set_title('Confusion Matrix', size=20) \n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5fdd4",
   "metadata": {},
   "source": [
    "<h2>View some results from a sample of 25 images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e311184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train.reshape(-1, img_size, img_size)[i], cmap='gray')\n",
    "    if(binary_predictions[i]==y_test[i]):\n",
    "        plt.xlabel(labels[binary_predictions[i]], color='blue')\n",
    "    else:\n",
    "        plt.xlabel(labels[binary_predictions[i]], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df00444",
   "metadata": {},
   "source": [
    "<h2>Download the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save('pneumonia_detection_ai_version_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843d0a0",
   "metadata": {},
   "source": [
    "<h2>Reflection: </h2>\n",
    "<h3> There are a lot of rooms to improve. If you have any questions or suggestions, please leave a comment below.</h3>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
