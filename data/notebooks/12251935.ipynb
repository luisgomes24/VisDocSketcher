{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c655584b",
   "metadata": {},
   "source": [
    "# Words analysis for selected web pages\n",
    "Started on 11 October 2020\n",
    "\n",
    "The urls where the text were scraped from are as follow:\n",
    "\n",
    "- Url 1: [Amazon search for Skin care : Face : Creams & Moisturizers : Night Creams](https://www.amazon.com/s?i=beauty-intl-ship&bbn=16225006011&rh=n%3A11060451%2Cn%3A11060711%2Cn%3A11061301%2Cn%3A7792275011%2Cp_72%3A1248873011%2Cp_36%3A1253952011&dc&qid=1599459689&rnid=386662011&ref=sr_nr_p_36_3)\n",
    "\n",
    "- Url 2: [Amazon search for Skin care : Face : Creams & Moisturizers : Night Creams](https://www.amazon.com/s?i=beauty-intl-ship&bbn=16225006011&rh=n%3A11060451%2Cn%3A11060711%2Cn%3A11061301%2Cn%3A7792275011%2Cp_72%3A1248873011&dc&qid=1599459692&ref=sr_ex_p_36_0)\n",
    "\n",
    "- Url 3: [Amazon search for Beauty & Personal Care : Skin Care : Eyes : Serums](https://www.amazon.com/s?k=dark+circles&i=beauty&rh=n%3A3760911%2Cn%3A11060451%2Cn%3A11061941%2Cn%3A7730098011&dc&qid=1599459662&rnid=11055981&ref=sr_nr_n_3)\n",
    "\n",
    "This was done over several days in Sep and Oct 2020.\n",
    "\n",
    "### _Steps:_\n",
    "_Pre-processing_\n",
    "* Read text file as a string of raw text.\n",
    "* Lower case all words.\n",
    "* Tokenize the raw text string into a list of words where each entry contains a word.\n",
    "* Remove numbers, punctuations and other characters like @#%^_&*, etc.\n",
    "* Remove stop words and other words of no interest e.g. ml, oz, ounce etc.\n",
    "\n",
    "_Process text into bigrams (two words)_\n",
    "* Use NLTK Bigram Collocation finder to determine the frequency of each bigram.\n",
    "* Create a Python dictionary with the bigram and bigram measure of raw frequency score.\n",
    "\n",
    "_Visualization_\n",
    "* Create some visualisations to facilitate any insights.\n",
    "\n",
    "Reference: https://avidml.wordpress.com/2017/07/29/word-clouds-with-frequently-occurring-and-salient-unigrams/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325bf68",
   "metadata": {},
   "source": [
    "# Words analysis for selected web pages\n",
    "Started on 11 October 2020\n",
    "\n",
    "The urls where the text were scraped from are as follow:\n",
    "\n",
    "- Url 1: [Amazon search for Skin care : Face : Creams & Moisturizers : Night Creams](https://www.amazon.com/s?i=beauty-intl-ship&bbn=16225006011&rh=n%3A11060451%2Cn%3A11060711%2Cn%3A11061301%2Cn%3A7792275011%2Cp_72%3A1248873011%2Cp_36%3A1253952011&dc&qid=1599459689&rnid=386662011&ref=sr_nr_p_36_3)\n",
    "\n",
    "- Url 2: [Amazon search for Skin care : Face : Creams & Moisturizers : Night Creams](https://www.amazon.com/s?i=beauty-intl-ship&bbn=16225006011&rh=n%3A11060451%2Cn%3A11060711%2Cn%3A11061301%2Cn%3A7792275011%2Cp_72%3A1248873011&dc&qid=1599459692&ref=sr_ex_p_36_0)\n",
    "\n",
    "- Url 3: [Amazon search for Beauty & Personal Care : Skin Care : Eyes : Serums](https://www.amazon.com/s?k=dark+circles&i=beauty&rh=n%3A3760911%2Cn%3A11060451%2Cn%3A11061941%2Cn%3A7730098011&dc&qid=1599459662&rnid=11055981&ref=sr_nr_n_3)\n",
    "\n",
    "This was done over several days in Sep and Oct 2020.\n",
    "\n",
    "### _Steps:_\n",
    "_Pre-processing_\n",
    "* Read text file as a string of raw text.\n",
    "* Lower case all words.\n",
    "* Tokenize the raw text string into a list of words where each entry contains a word.\n",
    "* Remove numbers, punctuations and other characters like @#%^_&*, etc.\n",
    "* Remove stop words and other words of no interest e.g. ml, oz, ounce etc.\n",
    "\n",
    "_Process text into bigrams (two words)_\n",
    "* Use NLTK Bigram Collocation finder to determine the frequency of each bigram.\n",
    "* Create a Python dictionary with the bigram and bigram measure of raw frequency score.\n",
    "\n",
    "_Visualization_\n",
    "* Create some visualisations to facilitate any insights.\n",
    "\n",
    "Reference: https://avidml.wordpress.com/2017/07/29/word-clouds-with-frequently-occurring-and-salient-unigrams/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ab95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3167b7f",
   "metadata": {},
   "source": [
    "## Pre-process the text files into word lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf5973",
   "metadata": {},
   "source": [
    "## Pre-process the text files into word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c10343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_stop_words():\n",
    "    stopwordsList = []\n",
    "    # Load default stop words and add a few more specific to the text.\n",
    "    stop_words_list = stopwords.words('english')\n",
    "    stop_words_list.append('ounce')\n",
    "    stop_words_list.append('oz')\n",
    "    stop_words_list.append('ml')\n",
    "    stop_words_list.append('ii')\n",
    "    return stop_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_stop_words():\n",
    "    stopwordsList = []\n",
    "    # Load default stop words and add a few more specific to the text.\n",
    "    stop_words_list = stopwords.words('english')\n",
    "    stop_words_list.append('ounce')\n",
    "    stop_words_list.append('oz')\n",
    "    stop_words_list.append('ml')\n",
    "    stop_words_list.append('ii')\n",
    "    return stop_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1150bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(file):\n",
    "    input_file = file\n",
    "    FILEHEADER = 0\n",
    "    with open(input_file, 'r') as f:\n",
    "        if FILEHEADER:\n",
    "            next(f)\n",
    "        raw_text = f.read()\n",
    "    # Lowercase and tokenize\n",
    "    raw_text = raw_text.lower()\n",
    "    tokens = nltk.word_tokenize(raw_text)\n",
    "    text = nltk.Text(tokens)\n",
    "    # Remove unwanted characters, numbers and stop words\n",
    "    text_content = [''.join(re.split(\"[ .,;:!?'`|~@#$%^_*()&{}\\n\\t\\-']\", word)) for word in text]\n",
    "    text_content = [word for word in text_content if not re.search(r'\\d', word)]\n",
    "    text_content = [word for word in text_content if word not in stop_words]\n",
    "    text_content = [word for word in text_content if len(word) !=0]\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(file):\n",
    "    input_file = file\n",
    "    FILEHEADER = 0\n",
    "    with open(input_file, 'r') as f:\n",
    "        if FILEHEADER:\n",
    "            next(f)\n",
    "        raw_text = f.read()\n",
    "    # Lowercase and tokenize\n",
    "    raw_text = raw_text.lower()\n",
    "    tokens = nltk.word_tokenize(raw_text)\n",
    "    text = nltk.Text(tokens)\n",
    "    # Remove unwanted characters, numbers and stop words\n",
    "    text_content = [''.join(re.split(\"[ .,;:!?'`|~@#$%^_*()&{}\\n\\t\\-']\", word)) for word in text]\n",
    "    text_content = [word for word in text_content if not re.search(r'\\d', word)]\n",
    "    text_content = [word for word in text_content if word not in stop_words]\n",
    "    text_content = [word for word in text_content if len(word) !=0]\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = prepare_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = prepare_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url1-combined.txt')\n",
    "url2_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url2-combined.txt')\n",
    "url3_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url3-combined.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2467e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url1-combined.txt')\n",
    "url2_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url2-combined.txt')\n",
    "url3_unigrams = process_text('../input/text-scrapped-from-amazon-search-pages/url3-combined.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of words in Url1 is', len(url1_unigrams), '\\n',\n",
    "      'Number of words in Url2 is', len(url2_unigrams), '\\n',\n",
    "      'Number of words in Url2 is', len(url3_unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of words in Url1 is', len(url1_unigrams), '\\n',\n",
    "      'Number of words in Url2 is', len(url2_unigrams), '\\n',\n",
    "      'Number of words in Url2 is', len(url3_unigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e02d6",
   "metadata": {},
   "source": [
    "## Setup and score the bigrams - create two-word frequency list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85109fba",
   "metadata": {},
   "source": [
    "## Setup and score the bigrams - create two-word frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_scored_list(text_content):\n",
    "    # setup and score the bigrams using raw frequency\n",
    "    finder = BigramCollocationFinder.from_words(text_content)\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    scored_list = sorted(scored, key = itemgetter(1), reverse=True)\n",
    "    # Create dictionary of bigrams and weightage\n",
    "    bigram_dict = {}\n",
    "    list_length = len(scored_list)\n",
    "    for i in range(list_length):\n",
    "        bigram_dict['_'.join(scored_list[i][0])] = int(scored_list[i][1]*len(text_content))\n",
    "    return bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_scored_list(text_content):\n",
    "    # setup and score the bigrams using raw frequency\n",
    "    finder = BigramCollocationFinder.from_words(text_content)\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    scored_list = sorted(scored, key = itemgetter(1), reverse=True)\n",
    "    # Create dictionary of bigrams and weightage\n",
    "    bigram_dict = {}\n",
    "    list_length = len(scored_list)\n",
    "    for i in range(list_length):\n",
    "        bigram_dict['_'.join(scored_list[i][0])] = int(scored_list[i][1]*len(text_content))\n",
    "    return bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1_bigrams = create_bigram_scored_list(url1_unigrams)\n",
    "url2_bigrams = create_bigram_scored_list(url2_unigrams)\n",
    "url3_bigrams = create_bigram_scored_list(url3_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475758f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1_bigrams = create_bigram_scored_list(url1_unigrams)\n",
    "url2_bigrams = create_bigram_scored_list(url2_unigrams)\n",
    "url3_bigrams = create_bigram_scored_list(url3_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf4525",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4360e7",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b12e4d",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec627c2",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddf1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set word cloud params and instantiate the word cloud.\n",
    "wc_max_words = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set word cloud params and instantiate the word cloud.\n",
    "wc_max_words = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words)\n",
    "wordCloud.generate_from_frequencies(url1_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 1', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f226976",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words)\n",
    "wordCloud.generate_from_frequencies(url1_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 1', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words, colormap='plasma')\n",
    "wordCloud.generate_from_frequencies(url2_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 2', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words, colormap='plasma')\n",
    "wordCloud.generate_from_frequencies(url2_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 2', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f716df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words, colormap='cividis')\n",
    "wordCloud.generate_from_frequencies(url3_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 3', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud = WordCloud(max_words=wc_max_words, colormap='cividis')\n",
    "wordCloud.generate_from_frequencies(url3_bigrams)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.title('Most frequently occurring bigrams for Url 3', fontsize=30)\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a629e4d4",
   "metadata": {},
   "source": [
    "### Graphs of Top 20 Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bbbfa",
   "metadata": {},
   "source": [
    "### Graphs of Top 20 Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_n_dataframe(bigrams, n=20):\n",
    "    df = pd.DataFrame(bigrams.items(), columns=['words', 'freq'])\n",
    "    df_n = df[:n]\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_n_dataframe(bigrams, n=20):\n",
    "    df = pd.DataFrame(bigrams.items(), columns=['words', 'freq'])\n",
    "    df_n = df[:n]\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137294e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url1 = create_top_n_dataframe(url1_bigrams)\n",
    "df_url2 = create_top_n_dataframe(url2_bigrams)\n",
    "df_url3 = create_top_n_dataframe(url3_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28aaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url1 = create_top_n_dataframe(url1_bigrams)\n",
    "df_url2 = create_top_n_dataframe(url2_bigrams)\n",
    "df_url3 = create_top_n_dataframe(url3_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b36266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url1', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url1', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec17e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url2', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dff2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url2', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url3', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7279bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Top 20 Words from Url3', fontsize=30)\n",
    "sns.barplot(x='freq', y='words', data=df_url3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265e0cb",
   "metadata": {},
   "source": [
    "### Tables of Top 20 Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14f00c",
   "metadata": {},
   "source": [
    "### Tables of Top 20 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed64545",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
