{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1c59c4",
   "metadata": {},
   "source": [
    "# Credits\n",
    "Forked and edited from [the original source](https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu)\n",
    "\n",
    "# Intro\n",
    "Kaggle provides free access to NVidia K80 GPUs in kernels. This benchmark shows that **enabling a GPU to your Kernel results in a 12.5X speedup during training of a deep learning model.** \n",
    "\n",
    "This kernel was run with a GPU. I compare run-times to a kernel training the same model on a CPU [here](https://www.kaggle.com/dansbecker/benchmarking-model-training-with-a-cpu).\n",
    "\n",
    "The total run-time with a GPU is 994 seconds. The total run-time for the kernel with only a CPU is 13,419 seconds. This is a 12.5X speedup (total run-time with only a CPU is 13.5X as long).\n",
    "\n",
    "Limiting the comparison only to model training, we see a reduction from 13,378 seconds on CPU to 950 seconds with a GPU.  So the model training speed-up is a little over 13X.\n",
    "\n",
    "The exact speed-up varies based on a number of factors including model architecture, batch-size, input pipeline complexity, etc. That said, the GPU opens up much great possibilities in Kaggle kernels. \n",
    "\n",
    "If you want to use these GPU's for deep learning projects, you'll likely find our [Deep Learning Course](kaggle.com/learn/deep-learning) the fastest path around to get up to speed so you can run your own projects.  We're also adding new image processing datasets to our [Datasets platform](kaggle.com/datasets) and we always have many [Competitions](kaggle.com/competitions) for you to try out new ideas using these free GPU's.  \n",
    "\n",
    "The following text shows how to enable a GPU and gives details on the benchmark.\n",
    "\n",
    "\n",
    "# Adding a GPU\n",
    "We set up this kernel to run on a GPU by first opening the kernel controls.\n",
    "\n",
    "![Imgur](https://i.imgur.com/WY2p6bH.png)\n",
    "___\n",
    "Select the **Settings** tab. Then select the checkbox for **Enable GPU**. Verify the GPU is attached to your kernel in the console bar, where it should show **GPU ON** next to your resource usage metrics.\n",
    "\n",
    "![Imgur](https://i.imgur.com/F9Hd3DN.png)\n",
    "___\n",
    "*GPU backed instances have less CPU power and RAM. Moreover, many data science libraries cannot take advantage of a GPU.  So, GPU's will be valuable for some tasks (especially when using deep learning libraries like TensorFlow, Keras and PyTorch).  But you are better off without a GPU for most other tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b3996",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "The dataset contains images with 29 different signs in American Sign Language. These are the 26 letters (A through Z) plus the signs for *space*, *delete* and *nothing*. Our model will view these images and learn to classify what sign is made in each image.\n",
    "\n",
    "Sample images below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea07d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Deep Learning\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ensure consistency across runs\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "# Imports to view data\n",
    "import cv2\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import floor\n",
    "import random\n",
    "\n",
    "def plot_three_samples(letter):\n",
    "    print(\"Samples images for letter \" + letter)\n",
    "    base_path = '../input/asl_alphabet_train/asl_alphabet_train/'\n",
    "    img_path = base_path + letter + '/**'\n",
    "    path_contents = glob(img_path)\n",
    "    \n",
    "    plt.figure(figsize=(16,16))\n",
    "    imgs = random.sample(path_contents, 3)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(cv2.imread(imgs[0]))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(cv2.imread(imgs[1]))\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(cv2.imread(imgs[2]))\n",
    "    return\n",
    "\n",
    "plot_three_samples('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce422a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_three_samples('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623be62",
   "metadata": {},
   "source": [
    "# Data Processing Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca89b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input/asl_alphabet_train/asl_alphabet_train\"\n",
    "target_size = (64, 64)\n",
    "target_dims = (64, 64, 3) # add channel for RGB\n",
    "n_classes = 29\n",
    "val_frac = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "data_augmentor = ImageDataGenerator(samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True, \n",
    "                                    validation_split=val_frac)\n",
    "\n",
    "train_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\n",
    "print(len(train_generator))\n",
    "val_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")\n",
    "print(len(val_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3c6f2",
   "metadata": {},
   "source": [
    "# Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims))\n",
    "my_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\n",
    "my_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\n",
    "my_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Dense(512, activation='relu'))\n",
    "my_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608efcd2",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a44a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(val_generator)\n",
    "my_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, epochs=5, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
