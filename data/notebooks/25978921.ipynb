{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0451bd",
   "metadata": {},
   "source": [
    "# Imports and data batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b056c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1978ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8defe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../input/pistachio-image-dataset/Pistachio_Image_Dataset/Pistachio_Image_Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For replicable results\n",
    "SEED = 0\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b53b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the images is (600,600). This is the default input size for EfficientNetB7 \n",
    "IMAGE_SIZE = (600, 600)\n",
    "# Default batch size\n",
    "BATCH_SIZE = 32\n",
    "# Images are grayscale\n",
    "COLOR_MODE = \"rgb\"\n",
    "# 20% test split\n",
    "VAL_SPLIT = 0.2\n",
    "# Number of batches for a smaller train dataset\n",
    "SMALL_DATASET_BATCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a38ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    label_mode='categorical',\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    color_mode=COLOR_MODE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    label_mode='categorical',\n",
    "    seed=SEED,\n",
    "    color_mode=COLOR_MODE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small train dataset with BATCH_SIZE*SMALL_DATASET_BATCHES images\n",
    "train_data_small = train_data_all.take(SMALL_DATASET_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data_all.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c7346",
   "metadata": {},
   "source": [
    "# Explore Random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6455a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "    target_folder = target_dir + target_class\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\");\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97baf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = view_random_image(dataset_dir, class_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc829133",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = view_random_image(dataset_dir, class_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0389f",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE + (3,)), name=\"input_layer\")\n",
    "# Efficient net model has the normalizing layer builtin\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46eb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history_0 = model_0.fit(train_data_small,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_data=test_data,\n",
    "                      validation_steps=int(0.1 * len(test_data)),\n",
    "                      verbose=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af6a9b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f573c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_0.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dae303",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_0, acc_0 = model_0.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9645da7",
   "metadata": {},
   "source": [
    "# Tentative model #1: Introducing data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd451472",
   "metadata": {},
   "source": [
    "In this test model we'll add a data augmentation layer before feeding the model with training images, this wi'll provide the model with more and more varied data to learn from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f044ca",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "                                         preprocessing.RandomFlip(\"horizontal_and_vertical\"),  \n",
    "                                         preprocessing.RandomRotation(1),\n",
    "                                         preprocessing.RandomZoom(0.1),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de645789",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE + (3,)), name=\"input_layer\")\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55410195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44767e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_data_small,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_data=test_data,\n",
    "                      validation_steps=int(0.1 * len(test_data)),\n",
    "                      verbose=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c34d0",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2aaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1, acc_1 = model_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245a8d9",
   "metadata": {},
   "source": [
    "Model 1 verdict: The accuracy is only slightly better than without data augmentation, but giving the nature of the images there's no harm in keeping it as the model will be exposed to perfectly valid example images. this will vastly increase the number of training images and will help the model to learn what patterns make each class unique, instead of learning the training images. The loss and validation loss keep going down after the first epoches, meaning there's still margin to improve accuracy when giving the model more training time.\n",
    "\n",
    " * Image augmentation pros:\n",
    "  * Virtually infinite images to train with\n",
    "  * Avoids overfitting\n",
    "\n",
    " * Image augmentation cons:\n",
    "  * Increased processing time\n",
    "  * Slower learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eae2e4",
   "metadata": {},
   "source": [
    "# Tentative model #2: Adjusting the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bcf2e2",
   "metadata": {},
   "source": [
    "To find a good learning rate we're going to fit the baseline model scheduling an increasingly bigger learning rate from 0.0001 to 0.1.\n",
    "Analyzing the losses for each learning rate we can pick the optimal learning rate to minimize the maximum loss per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab36687",
   "metadata": {},
   "source": [
    "## Ideal learning rate estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same model as model_0\n",
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE + (3,)), name=\"input_layer\")\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_test = tf.keras.Model(inputs, outputs)\n",
    "model_lr_test.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79346d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lr_test = model_lr_test.fit(train_data_small,\n",
    "                                    epochs=100, \n",
    "                                    callbacks=[lr_scheduler], \n",
    "                                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe18d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning rate versus the loss\n",
    "lrs = 1e-4 * (10 ** (np.arange(100)/20))\n",
    "loss = history_lr_test.history[\"loss\"]\n",
    "low_loss = min(loss)\n",
    "low_lr_loss_index = loss.index(low_loss)\n",
    "low_lr = 1e-4 * (10 ** (low_lr_loss_index/20))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.semilogx(lrs, loss)\n",
    "plt.scatter(low_lr, low_loss, alpha=0.9, c='r', s=50)\n",
    "plt.scatter(low_lr/10, low_loss, alpha=0.9, c='g', s=50)\n",
    "plt.annotate(f\"LR FOR LOWEST LOSS = {round(low_lr, 4)}\", (low_loss/10 , low_lr+2))\n",
    "\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.title(\"Learning rate vs. loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c729274",
   "metadata": {},
   "source": [
    "The estimated optimal learning rate is between 0.0398 and 0.00398. We're picking 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4311067",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same model as model_0\n",
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE + (3,)), name=\"input_layer\")\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01316e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.025\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(train_data_small,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=test_data,\n",
    "                          validation_steps=int(0.1 * len(test_data)),\n",
    "                          verbose=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ec447",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_2.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192949ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_2, acc_2 = model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f9492",
   "metadata": {},
   "source": [
    "Model 2 verdict: Good improvement on accuracy after a careful learning rate choice\n",
    "\n",
    " * Learning rate adjustment pros:\n",
    "  * Better results after fewer epoches, and thus, processing time\n",
    "\n",
    " * Learning rate adjustment cons:\n",
    "  * Being higher than the default (0.001) the loss can lose control and start rising in fewer epoches too. A early stop might be necessary in the final design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92624b13",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e02ae1",
   "metadata": {},
   "source": [
    "Based on the previous tests, the final model features include:\n",
    " * Training with the whole dataset\n",
    " * A data augmentation layer\n",
    " * Training for the same amount of epochs\n",
    " * A starting learning rate of 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97384e65",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1621a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE + (3,)), name=\"input_layer\")\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c866718",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.025\n",
    "model_final = tf.keras.Model(inputs, outputs)\n",
    "model_final.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history_final = model_final.fit(train_data_all,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=int(0.1 * len(test_data)),\n",
    "                                  verbose=True,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6d5fa",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d88975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_final.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_final, acc_final = model_final.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6823734",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c46b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Base model\", \"Using data augmentation\", \"Higher learning rate\", \"All of above\"]\n",
    "m0 = [\"10%\", 10, loss_0, round(acc_0 * 100, 3)]\n",
    "m1 = [\"10%\", 10, loss_1, round(acc_1 * 100, 3)]\n",
    "m2 = [\"10%\", 10, loss_2, round(acc_2 * 100, 3)]\n",
    "m3 = [\"100%\", 10, loss_final, round(acc_final * 100, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1117dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([m0, m1, m2, m3], index=names, columns=[\"Used dataset\", \"Epochs\", \"Loss\", \"Accuracy %\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bceea2",
   "metadata": {},
   "source": [
    "With the power of a pre-trained model, a custom classifier can deliver good results with no changes at all, but further improvement is in the fine details. By testing on a small dataset and changing hyperparameters or adding layers of complexity we can save processing time, those improvements _should_ carry to the full dataset training, ending with a very accurate model."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
