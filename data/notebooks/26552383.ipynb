{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random,os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython\n",
    "\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import display\n",
    "\n",
    "#Deep learning from pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac90d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_open = open('/kaggle/input/birdclef-2022/scored_birds.json', 'r')\n",
    "bird_target = json.load(json_open)\n",
    "bird_target\n",
    "\n",
    "train = pd.read_csv(\"../input/fulllabeldataset/train.csv\",index_col=0)\n",
    "#train = train[train.num <= 3].reset_index(drop=True)\n",
    "train[\"filepath\"] = \"../input/fulllabeldataset/image_128/\" + train[\"path\"]\n",
    "train[\"sort_index\"] = train.filename_id.apply(lambda x: int(x.split(\"_\")[-1])//5)\n",
    "train[\"file_id\"] = train.filename_id.apply(lambda x: x.split(\"_\")[0])\n",
    "train['secondary_labels_array'] =  train.secondary_labels.apply(eval)\n",
    "train[\"sleng\"] = train.secondary_labels_array.apply(lambda x: len(x))\n",
    "unique_key = sorted(bird_target)\n",
    "LABEL_IDS = {label: label_id for label_id, label in enumerate(unique_key)}\n",
    "INV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}\n",
    "print(LABEL_IDS)\n",
    "train[\"label_id\"] = -1\n",
    "train.loc[train.primary_label.isin(bird_target),\"label_id\"] = train.loc[train.primary_label.isin(bird_target),\"primary_label\"].map(LABEL_IDS)\n",
    "df_nolabel = train[train.sleng == 0]\n",
    "df_nolabel['label_array'] =  df_nolabel.label_id.apply(lambda x: np.array([x]))\n",
    "df_nolabel['num'] = 0\n",
    "df_nolabel[\"sec1\"] = -1\n",
    "df_nolabel[\"sec2\"] = -1\n",
    "df_nolabel[\"sec3\"] = -1\n",
    "\n",
    "df_label = train[train.sleng > 0]\n",
    "df_label['labels_id'] = df_label.secondary_labels_array.apply(lambda x: np.vectorize(lambda s: LABEL_IDS[s] if s in unique_key else -1)(x))\n",
    "df_label.labels_id = df_label.labels_id.apply(lambda x: x[x != -1])\n",
    "df_label['num'] = df_label.labels_id.apply(lambda x: len(x))\n",
    "df_label[\"sec1\"] = df_label.labels_id.apply(lambda x: x[0] if len(x) > 0 else -1)\n",
    "df_label[\"sec2\"] = df_label.labels_id.apply(lambda x: x[1] if len(x) > 1 else -1)\n",
    "df_label[\"sec3\"] = df_label.labels_id.apply(lambda x: x[2] if len(x) > 2 else -1)\n",
    "\n",
    "train = pd.concat([df_label,df_nolabel]).sort_values([\"file_id\",\"sort_index\"]).reset_index(drop=True)\n",
    "\n",
    "train.loc[train.label_id == train.sec1,\"sec1\"] = -1\n",
    "train.loc[train.label_id == train.sec2,\"sec2\"] = -1\n",
    "train.loc[train.label_id == train.sec3,\"sec3\"] = -1\n",
    "\n",
    "#train[\"label\"] = train[[\"sec1\",\"sec2\",\"sec3\"]].apply(lambda x: np.array([x.sec1,x.sec2,x.sec3],dtype=np.int32),axis=1)\n",
    "#train[\"label\"] = train.label.apply(lambda x: x[x != -1])\n",
    "#train[\"num\"] = train.labels_id.apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "train = train[~((train.label_id == -1)&(train.num==0))].reset_index(drop=True)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "furudf = pd.read_csv(\"../input/annotationdataset-furu/results.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_hand\"})\n",
    "furudfnum1 = pd.read_csv(\"../input/annotationdataset-furu/results_num1_primary.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_hand\"})\n",
    "ishiidf = pd.read_csv(\"../input/annotationdataset-ishii/results.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_hand\"})\n",
    "tadokorodf = pd.read_csv(\"../input/annotationdataset-tadokoro/results.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_hand\"})\n",
    "takemidf = pd.read_csv(\"../input/annotationdataset-takemi/results.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_hand\"})\n",
    "handlabeldf = pd.concat([furudf,furudfnum1,ishiidf,tadokorodf,takemidf]).drop_duplicates(\"filename_id\")\n",
    "train = pd.merge(train,handlabeldf,on=[\"filename_id\"],how=\"left\").fillna(0)\n",
    "\n",
    "furudf_sec = pd.read_csv(\"../input/annotationdataset-furusec/results_sec1.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec1\"})\n",
    "ishiidf1_sec = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec1.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec1\"})\n",
    "ishiidf2_sec = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec2.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec1\"})\n",
    "ishiidf3_sec = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec3_1.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec1\"})\n",
    "takemidf_sec = pd.read_csv(\"../input/annotationdataset-takemisec/results_sec1.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec1\"})\n",
    "handlabeldf_sec1 = pd.concat([furudf_sec,ishiidf1_sec,ishiidf2_sec,ishiidf3_sec,takemidf_sec]).drop_duplicates(\"filename_id\")\n",
    "train = pd.merge(train,handlabeldf_sec1,on=[\"filename_id\"],how=\"left\").fillna(0)\n",
    "\n",
    "ishiidf1_sec2 = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec2.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec2\"})\n",
    "ishiidf2_sec2 = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec3_2.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec2\"})\n",
    "handlabeldf_sec2 = pd.concat([ishiidf1_sec2,ishiidf2_sec2]).drop_duplicates(\"filename_id\")\n",
    "train = pd.merge(train,handlabeldf_sec2,on=[\"filename_id\"],how=\"left\").fillna(0)\n",
    "\n",
    "ishiidf_sec3 = pd.read_csv(\"../input/annotationdatasetishiisec/results_sec3_3.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec3\"})\n",
    "takemidf_sec3 = pd.read_csv(\"../input/annotationdataset-takemisec2/results_sec3.txt\",header=None).rename(columns={0:\"filename_id\",1:\"primary_label_sec3\"})\n",
    "handlabeldf_sec3 = pd.concat([ishiidf_sec3,takemidf_sec3]).drop_duplicates(\"filename_id\")\n",
    "train = pd.merge(train,handlabeldf_sec3,on=[\"filename_id\"],how=\"left\").fillna(0)\n",
    "\n",
    "#skylar houfinに関しては、確率低いもののみハンドラベリング済みなので、高いものは全てTrueにする\n",
    "train.loc[(train.primary_label.isin([\"skylar\"]))&(train.num==0),\"primary_label_hand\"] = \"skylar\"\n",
    "train.loc[(train.primary_label.isin([\"houfin\"]))&(train.num==0),\"primary_label_hand\"] = \"houfin\"\n",
    "train.loc[train.primary_label_hand==0,\"primary_label_hand\"] = \"nolabel\"\n",
    "train.loc[(train.primary_label_sec1==0)&(train.sec1 == -1),\"primary_label_sec1\"] = \"nocall\"\n",
    "train.loc[train.primary_label_sec1==0,\"primary_label_sec1\"] = \"nolabel\"\n",
    "train.loc[(train.primary_label_sec2==0)&(train.sec2 == -1),\"primary_label_sec2\"] = \"nocall\"\n",
    "train.loc[train.primary_label_sec2==0,\"primary_label_sec2\"] = \"nolabel\"\n",
    "train.loc[(train.primary_label_sec3==0)&(train.sec3 == -1),\"primary_label_sec3\"] = \"nocall\"\n",
    "train.loc[train.primary_label_sec3==0,\"primary_label_sec3\"] = \"nolabel\"\n",
    "\n",
    "train.to_csv(\"handlabeltrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc52d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15febcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
