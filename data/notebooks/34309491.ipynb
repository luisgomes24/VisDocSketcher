{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414b28f4",
   "metadata": {},
   "source": [
    "# Opening\n",
    "This is my exercise to explore a dataset based on courses I've learned for few months. I'm beginner on Data Science and I have strong passionate to learn it! Your suggestions and advices is important for me!\n",
    "\n",
    "I'm only work in dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97919a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff6358",
   "metadata": {},
   "source": [
    "# Objective\n",
    "From this dataset, I would like to figure out the kind of house type which has high price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f61a625",
   "metadata": {},
   "source": [
    "# Dataset Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71184528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b24637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2203ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff4a47",
   "metadata": {},
   "source": [
    "Dataset df which is dataset train has total 1460 rows and 81 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(exclude = ['object'])\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d763c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numeric_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad758ff",
   "metadata": {},
   "source": [
    "Dataset has 38 numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns = df.select_dtypes(include = ['object'])\n",
    "categoric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categoric_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f7cca",
   "metadata": {},
   "source": [
    "Dataset df has 43 categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f212b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aea744",
   "metadata": {},
   "source": [
    "Dataset df has a lot of missing values in its various columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a62c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299eae3e",
   "metadata": {},
   "source": [
    "There are several columns which have too much missing values with total amount most likely 50% even 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1878063",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d474e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_columns.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b024193",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(df.corr(),\n",
    "\t\t\tcmap = 'BrBG',\n",
    "\t\t\tfmt = '.2f',\n",
    "\t\t\tlinewidths = 2,\n",
    "\t\t\tannot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd088c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a22ab",
   "metadata": {},
   "source": [
    "Delete columns where have too much unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f347f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55881d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numeric = df_clean.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "list_of_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_categoric = df_clean.select_dtypes(include = ['object']).columns.tolist()\n",
    "list_of_categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_columns = df_clean.select_dtypes(exclude = ['object'])\n",
    "#categoric_columns = df_clean.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136365d",
   "metadata": {},
   "source": [
    "Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_numeric].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c48028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_numeric].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_of_numeric:\n",
    "    if df_clean[i].isna().any() == True:\n",
    "        df_clean[i] = df_clean[i].fillna(df_clean[i].mean())\n",
    "        print('Is {} has missing value? {}'.format(i, df_clean[i].isna().any()))\n",
    "        \n",
    "df_clean[list_of_numeric].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb98ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['LotFrontage'] = df_clean['LotFrontage'].fillna(df_clean['LotFrontage'].mean())\n",
    "#df_clean['MasVnrArea'] = df_clean['MasVnrArea'].fillna(df_clean['MasVnrArea'].mean())\n",
    "#df_clean['GarageYrBlt'] = df_clean['GarageYrBlt'].fillna(df_clean['GarageYrBlt'].mean())\n",
    "\n",
    "#df_clean[list_of_numeric].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_categoric].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_categoric].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daa652",
   "metadata": {},
   "source": [
    "Remove columns which have too many missing values (likely 50% to above) and fill missing values on other columns with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_of_categoric:\n",
    "    if df_clean[i].isna().sum() > 600:\n",
    "        del df_clean[i]\n",
    "    else:\n",
    "        df_clean[i] = df_clean[i].fillna(df_clean[i].mode()[0])\n",
    "        print('Is {} has missing value? {}'.format(i, df_clean[i].isna().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d41426",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_categoric = df_clean.select_dtypes(include = 'object').columns.tolist()\n",
    "list_of_categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_categoric].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f715d0",
   "metadata": {},
   "source": [
    "Normalization numeric columns in dataset df_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ece15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[list_of_numeric] = scaler.fit_transform(df_clean[list_of_numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3ad5c",
   "metadata": {},
   "source": [
    "Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf726658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.get_dummies(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(list_of_categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in list_of_categoric:\n",
    "#    df_clean[col] = LabelEncoder().fit_transform(df_clean[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84dfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean[list_of_categoric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d6f0b",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean.drop(['SalePrice'], axis=1)\n",
    "y = df_clean['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset train contains:\", X_train.shape[0], \"rows and \", X_train.shape[1], \"columns\")\n",
    "print(\"Dataset test contains:\", X_test.shape[0], \"rows and \", X_test.shape[1], \"columns\")\n",
    "\n",
    "print(\"Variable target to train contains:\", y_train.shape[0], \"rows\")\n",
    "print(\"Variable target to test contains:\", y_test.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020ee3e",
   "metadata": {},
   "source": [
    "# Modeling with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I decompose each row into 10 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_dec(data, n):\n",
    "  pca = PCA(n)\n",
    "  X_dec = pca.fit_transform(data)\n",
    "  return X_dec, pca\n",
    "\n",
    "#Decomposing the train set:\n",
    "pca_train_results, pca_train = pca_dec(X_train, 10)\n",
    "\n",
    "#Decomposing the test set:\n",
    "pca_test_results, pca_test = pca_dec(X_test, 10)\n",
    "\n",
    "#Creating a table with the explained variance ratio\n",
    "names_pcas = [f\"PCA Component {i}\" for i in range(1, 11, 1)]\n",
    "scree = pd.DataFrame(list(zip(names_pcas, pca_train.explained_variance_ratio_)), columns=[\"Component\", \"Explained Variance Ratio\"])\n",
    "print(scree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b30b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the values of the first principal component by how large each one is\n",
    "df2 = pd.DataFrame({'PCA':pca_train.components_[0], 'Variable Names':list(X_train.columns)})\n",
    "df2 = df2.sort_values('PCA', ascending=False)\n",
    "\n",
    "#Sorting the absolute values of the first principal component by magnitude\n",
    "df3 = pd.DataFrame(df2)\n",
    "df3['PCA']=df3['PCA'].apply(np.absolute)\n",
    "df3 = df3.sort_values('PCA', ascending=False)\n",
    "#print(df2['Variable Names'][0:11])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec7331",
   "metadata": {},
   "source": [
    "What is conclusion? I dunno and I'll learn it more to know the answer!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
