{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3747366",
   "metadata": {},
   "source": [
    "# HR DATA ANALYSIS\n",
    "\n",
    "In this notebook we will be looking at the dataset to see if we can glean useful insights by means Data Analysis and Data Visualization. Roughly, we will be following the below structure: \n",
    "\n",
    "* Load the data.\n",
    "* Display useful statistics.\n",
    "* Build generic functions to detect nulls and missing values.\n",
    "* Handle missing values.\n",
    "* Make Visualizations to understand data better.\n",
    "\n",
    "The problem comes under classification as we are predicting a binary value of either promoted (1) or not (0). After going through the above listed steps one can efficiently build ML models like Naive Bayes, Logistic Regression, Random Forests to name a few. This notebook will cover EDA concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdb4dc",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2cf45",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3de5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/hranalysis/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/hranalysis/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Display rows\n",
    "print(df_train.head(5))\n",
    "print('======================')\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3aa69",
   "metadata": {},
   "source": [
    "# Display summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the column names\n",
    "print(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4420496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef891e39",
   "metadata": {},
   "source": [
    "It seems like much of the data has discrete values (0 or 1) in terms of numerical columns. Columns like KPIs_met ranges in terms of percent values between 0 - 1. Let's look into the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "print(df_train.select_dtypes(include = ['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba2abb",
   "metadata": {},
   "source": [
    "At this point looking at rhe categorical columns, *Region* can be removed (unless we find something that refutes this decision), *department*, *education* and *recruitment_channel* can be encoded either via LabelEncoding or OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cdca1",
   "metadata": {},
   "source": [
    "# Investigating Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function to calculate missing values, zero values\n",
    "def calcMissingValues(df):\n",
    "    '''    \n",
    "        This function is used to calculate : zero values, missing values, NA and returns a dataframe with the above calculated\n",
    "        values. \n",
    "        \n",
    "        Input: Dataframe\n",
    "        Output: Returns a dataframe\n",
    "    '''\n",
    "    \n",
    "    # Calc zero vals\n",
    "    zero_vals = (df == 0.0).astype(int).sum(axis = 0)\n",
    "    \n",
    "    # Calc missing vals\n",
    "    missing_vals = df.isnull().sum()\n",
    "    \n",
    "    # Calc missing value percent\n",
    "    missing_val_percent = round((missing_vals / len(df)) * 100.0, 2)\n",
    "    \n",
    "    df_missing_stat = pd.concat([zero_vals , missing_vals , missing_val_percent] , axis = 1)\n",
    "    \n",
    "    df_missing_stat = df_missing_stat.rename(columns = {0: 'zero_vals', 1: 'missing_vals', 2: '%_missing_vals'})\n",
    "    \n",
    "    df_missing_stat['data_types'] = df.dtypes\n",
    "    \n",
    "    print(df_missing_stat)\n",
    "    \n",
    "    return df_missing_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_stat = calcMissingValues(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584d56c",
   "metadata": {},
   "source": [
    "# Visualize Missing values\n",
    "\n",
    "We will use the ***missingno*** library to visualize the missing values in our dataset. Visualization provides some intuition and a possible pattern that can be useful to interpret the data in a better way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a missing value matrix\n",
    "msno.matrix(df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996a394",
   "metadata": {},
   "source": [
    "*previous_year_rating* has missing values and would be interesting to see if the values were not recorded or they did not exist which may happen in cases where *length_of_service* is less than 1 (The employee either is trainee or has joined relatively new). Both these columns must be observed before handling the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a bar graph\n",
    "msno.bar(df_train , figsize = (10 , 8) , color = 'orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdee90",
   "metadata": {},
   "source": [
    "The values to the right side gives the row numbers, and the left gives the proportion of rows to the total. The values at the top of the bar gives the actual number of non-missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3662074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe null records to see if there is any corresponding pattern in other columns\n",
    "train_copy = df_train.copy()\n",
    "print(train_copy[train_copy['previous_year_rating'].isnull()]['length_of_service'])\n",
    "\n",
    "print()\n",
    "\n",
    "print(train_copy[train_copy.filter(items = ['previous_year_rating']).isnull().any(axis = 1)]['length_of_service'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73057c",
   "metadata": {},
   "source": [
    "Both lines of code give the same result and our initial guess was correct whenever there is a null value in *previous_year_rating* the *length_of_service* column has a value of 1. This rules out deleting the rows having nulls. Let's again look at the info statistics to see if we can impute reasonably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e842e8",
   "metadata": {},
   "source": [
    "Since the mean value of *previous_year_rating* is 3.3, we can impute the missing values with the mean as it makes sense to give an average rating to employees than a ratin of 1 which is not realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values for previous_year_rating with mean\n",
    "df_train['previous_year_rating'].fillna(df_train['previous_year_rating'].mean() , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['education'].value_counts())\n",
    "\n",
    "# Get the mode of the feature education\n",
    "print()\n",
    "print('Mode: ' , df_train['education'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c230d",
   "metadata": {},
   "source": [
    "For education, we see Bachelors and Masters being the most common value and we can impute with Bachelors for the missing value as it makes a reasonable estimate and it also is the mode (statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values for education with mode\n",
    "df_train['education'].fillna(df_train['education'].mode()[0] , inplace = True)\n",
    "\n",
    "# Check for missing values\n",
    "df_missing_stat = calcMissingValues(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c01733",
   "metadata": {},
   "source": [
    "# EDA and Data Visualization\n",
    "\n",
    "We will now look into data analysis and visualize some of the relationships between features to get more insights about the data.\n",
    "\n",
    "We will do a pairplot analysis to see what are the reltionships between different variables and how it influences the target variable. In datasets having more features, pairplots are quite useful in revealing patterns that help in subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258efe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a93dc",
   "metadata": {},
   "source": [
    "The employee_id column can be safely dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the train dataset\n",
    "df_x = df_train.copy()\n",
    "\n",
    "df_x.drop('employee_id' , inplace = True , axis = 1)\n",
    "\n",
    "# Let's make a pairplot with employee_id being dropped\n",
    "\n",
    "# Lets visualize from the perspective of education degree\n",
    "plt.figure(figsize = (12 , 8))\n",
    "sns.pairplot(df_x , hue = 'education')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b70843",
   "metadata": {},
   "source": [
    "Some observations from the pairplot\n",
    "(Stacked bar graphs do not serve any purpose when you are analysing a numerical value against another numerical value!! They are useful when there is a categorical variable. Otherwise the analysis can be misleading)\n",
    "\n",
    "* Lesser no_of_trainings has more promotions (Does quality over quanity matter here?)\n",
    "* Promotions are provided irrespective of the employee age\n",
    "* All types of previous_year_ratings have received promotions, so there is no explicit pattern or strong relationship to discern here. Higher ratings have more number of promotions.\n",
    "* Similarly age too does not play a role in promotions as in any company people receive promotions across different age groups.\n",
    "* Length_of_service has a positive linear relationship with age which is obviously true!.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70915285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare some of the features against the target variable\n",
    "prev_yr_rating = df_x.groupby(['previous_year_rating'] , as_index = False)['is_promoted'].sum()\n",
    "\n",
    "prev_yr_rating['previous_year_rating'] = prev_yr_rating['previous_year_rating'].round().astype(int)\n",
    "\n",
    "print(prev_yr_rating)\n",
    "\n",
    "'''\n",
    "\n",
    "VALID LEGEND LOCATIONS\n",
    "\n",
    "best\n",
    "upper right\n",
    "upper left\n",
    "lower left\n",
    "lower right\n",
    "right\n",
    "center left\n",
    "center right\n",
    "lower center\n",
    "upper center\n",
    "center\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "prev_yr_rating.plot(kind = 'bar', x = 'previous_year_rating' , y = 'is_promoted', color = 'yellow' , alpha = 0.6, figsize = (10 , 8) , rot = 0)\n",
    "plt.xlabel('Previous Year Ratings')\n",
    "plt.ylabel('Total Promotions')\n",
    "plt.title('Previous Year Ratings - Promotions')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79510111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare education and total promotions\n",
    "education_promotions = df_x.groupby(['education'], as_index = False)['is_promoted'].sum()\n",
    "\n",
    "print(education_promotions)\n",
    "\n",
    "education_promotions.plot(kind = 'bar', x = 'education' , y = 'is_promoted', color = 'yellow' , alpha = 0.6, figsize = (10 , 8) , rot = 0)\n",
    "plt.xlabel('Education Degree')\n",
    "plt.ylabel('Total Promotions')\n",
    "plt.title('Education Degree - Promotions')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160b0a4",
   "metadata": {},
   "source": [
    "In general, a Bachelors degree is a necessary to be considered for a promotion and the count is also boosted by the handling of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a545e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall proportion of different degrees\n",
    "\n",
    "# Pie Chart ref: https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f\n",
    "print(df_x.groupby(['education']).size())\n",
    "\n",
    "sizes = list(df_x.groupby(['education']).size())\n",
    "\n",
    "print(sizes)\n",
    "\n",
    "labels = ['Bachelors' , 'Below Secondary', 'Masters']\n",
    "colors = ['#ff9999','#1f70f0','#99ff99']\n",
    "pie_explode = [0 , 0 , 0.3]\n",
    "\n",
    "plt.figure(figsize = (10 , 8))\n",
    "plt.pie(sizes , labels = labels , explode = pie_explode , colors = colors , shadow = True, startangle = 90 , textprops={'fontsize': 14} , autopct = '%.1f%%')\n",
    "plt.ylabel('')\n",
    "plt.title('Degree distribution in the data' , fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c927bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recruitment channel - employment\n",
    "# Pie Chart ref: https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f\n",
    "\n",
    "# Unique values for the type of recruitment followed\n",
    "print(df_x['recruitment_channel'].unique())\n",
    "\n",
    "print(df_x['recruitment_channel'].value_counts())\n",
    "recruitment_categories = list(df_x['recruitment_channel'].value_counts())\n",
    "\n",
    "print(recruitment_categories)\n",
    "\n",
    "labels = ['other' , 'sourcing', 'referred']\n",
    "colors = ['#3f4857','#a5a8ad','#687d9e']\n",
    "pie_explode = [0 , 0.3 , 0]\n",
    "\n",
    "plt.figure(figsize = (10 , 8))\n",
    "plt.pie(recruitment_categories , labels = labels , explode = pie_explode , colors = colors , shadow = True, startangle = 90 , textprops = {'fontsize': 14} , autopct = '%.1f%%')\n",
    "plt.ylabel('')\n",
    "plt.title('Recruitment Categories' , fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88a4b9",
   "metadata": {},
   "source": [
    "In a similar vein, the other features could be visualized either as a donut chart or bar graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7f8e8",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook includes Data Analysis, EDA (as offered by the dataset) and Data Visualization. Building models on top this dataset given the detailed analysis and handling of missing values should be fairly simple. This notebook primarily serves as an exercise for analysis and visualizations"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
