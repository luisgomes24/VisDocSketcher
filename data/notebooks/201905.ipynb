{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import sklearn\n",
    "from ggplot import *\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "df = pd.read_csv('../input/rdany_conversations_2016-03-01.csv')\n",
    "## Check whether dataset is loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleansing(corpus):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", corpus) \n",
    "    words = letters_only.lower().split()                            \n",
    "    return( \" \".join( words ))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x:data_cleansing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b11920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['source','text']]\n",
    "##Check the data cleansing\n",
    "for i in range(5):\n",
    "    print(df['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceae14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(aes(x='len'), data=df) + geom_histogram(binwidth=2)+ theme_bw() + ggtitle('Histogram of length of conversation')+ facet_wrap('source')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce177d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(source):\n",
    "    tmp = df[df['source']==source]\n",
    "    clean_text=[]\n",
    "    for each in tmp['text']:\n",
    "        clean_text.append(each)\n",
    "    clean_text = ' '.join(clean_text)\n",
    "    if source == 'robot' :\n",
    "        color='black'\n",
    "    else:\n",
    "        color='white'\n",
    "    wordcloud = WordCloud(background_color=color,\n",
    "                      width=3000,\n",
    "                      height=2500\n",
    "                     ).generate(clean_text)\n",
    "    print('==='*30)\n",
    "    print('word cloud of '+source+' is plotted below')\n",
    "    plt.figure(1,figsize=(8,8))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud('robot')\n",
    "wordcloud('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split train/test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(df,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tfidf variables\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "for each in train['text']:\n",
    "    train_corpus.append(each)\n",
    "for each in test['text']:\n",
    "    test_corpus.append(each)\n",
    "## Start creating them\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "train_features = v.fit_transform(train_corpus)\n",
    "test_features=v.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call ML models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed089b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = {'lg':LogisticRegression(random_state=42,C=5,max_iter=200),'dt':DecisionTreeClassifier(random_state=42,min_samples_leaf=1),'rf':RandomForestClassifier(random_state=42,n_estimators=100,n_jobs=-1),'gb':GradientBoostingClassifier(random_state=42,n_estimators=100,learning_rate=0.3)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Pipeline(clf_name):\n",
    "    clf = Classifiers[clf_name]\n",
    "    fit = clf.fit(train_features,train['source'])\n",
    "    pred = clf.predict(test_features)\n",
    "    Accuracy = accuracy_score(test['source'],pred)\n",
    "    Confusion_matrix = confusion_matrix(test['source'],pred)\n",
    "    print('==='*35)\n",
    "    print('Accuracy of '+ clf_name +' is '+str(Accuracy))\n",
    "    print('==='*35)\n",
    "    print(Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08214d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_Pipeline('lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_Pipeline('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_Pipeline('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_Pipeline('gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2922a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42,n_estimators=100,n_jobs=-1)\n",
    "fit = clf.fit(train_features,train['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c855a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = v.get_feature_names()\n",
    "importance = clf.feature_importances_\n",
    "impordf = pd.DataFrame({'Word' : words,'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bfc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
