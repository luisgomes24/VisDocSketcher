{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0818dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401fff52",
   "metadata": {},
   "source": [
    "## Installing Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a686ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../input/titanic/train.csv')\n",
    "test  = pd.read_csv('../input/titanic/test.csv')\n",
    "sub   = pd.read_csv('../input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0817e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f900de",
   "metadata": {},
   "source": [
    "### we won’t dive into data preparation for Machine Learning because Pycaret takes care of some data prep (one-hot encoding, feature scaling, train/test split…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38060389",
   "metadata": {},
   "source": [
    "### We drop some unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['PassengerId','Name'],inplace=True,axis=1)\n",
    "test.drop(['PassengerId','Name'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4c262",
   "metadata": {},
   "source": [
    "## The column we want to predict is 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ecd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(titanic,target='Survived', silent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad1eb5",
   "metadata": {},
   "source": [
    "### It will automatically assign data types — if everything looks good, you can just hit enter. It will also keep 30% of the dataset so as to test it at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf28c4",
   "metadata": {},
   "source": [
    "### Comparion of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9339fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c71e26",
   "metadata": {},
   "source": [
    "### This will train several models (using k-fold cross-validation) and rank them. The models are ranked by accuracy by default, but you can change that using the “sort” argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93161162",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b528a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = create_model(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f98e7",
   "metadata": {},
   "source": [
    "### This will create a new classifier based on the result given by the compare_models method (the best model). The output here are the scores achieved using k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2738d3a",
   "metadata": {},
   "source": [
    "## Hyperparametric tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97763eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = tune_model(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a24434",
   "metadata": {},
   "source": [
    "## Model Finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea830b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = finalize_model(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee2fa0",
   "metadata": {},
   "source": [
    "## Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bcd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(mymodel,'mymodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990683f4",
   "metadata": {},
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2392c7",
   "metadata": {},
   "source": [
    "##  Loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import load_model, predict_model\n",
    "load_model('mymodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f86e95",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a02de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(mymodel, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac56f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddfca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Survived'] = predictions['Label'].astype(int)\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8680f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
