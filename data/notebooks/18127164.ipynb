{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d700e14",
   "metadata": {},
   "source": [
    "# Please predict and score using youâ€™re the best model to testbase.csv data as final submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa1c03",
   "metadata": {},
   "source": [
    "### In this notebook , I'm going to predictions customers are eligible for the credit and check whether what are the missing criteria to know why user ineligible in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f46182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/creditscroring/trainbase.csv')\n",
    "df_test = pd.read_csv('../input/creditscroring/testbase.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the id column is not useful for us and building a model then we must drop it\n",
    "\n",
    "df_train.drop(columns='id', inplace = True)\n",
    "df_test.drop(columns='id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed025ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['branchcode'].unique()\n",
    "df_test['branchcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['branchcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.bar(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd739b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace value \n",
    "df_train.branchcode = df_train.branchcode.replace({\"A\": 1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6, \"G\" : 7, \"H\" : 8, \"I\" : 9,\"K\": 11, \"J\": 10})\n",
    "df_test.branchcode = df_test.branchcode.replace({\"A\": 1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6, \"G\" : 7, \"H\" : 8, \"I\" : 9,\"K\": 11, \"J\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223d035",
   "metadata": {},
   "source": [
    "### Remove naull value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ed964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['branchcode']=df_train['branchcode'].fillna(df_train['branchcode'].mode()[0])\n",
    "df_test['branchcode']=df_test['branchcode'].fillna(df_test['branchcode'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97df1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid')\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(x = 'n_cards' , data = df_train)\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(x = 'branchcode', data= df_train)\n",
    "plt.subplot(2,2,3)\n",
    "sns.countplot(x = 'n_cards', hue= 'good_bad_flag', data = df_train)\n",
    "plt.subplot(2,2,4)\n",
    "sns.countplot(x = 'loan_tenure',hue = 'good_bad_flag' , data= df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(figsize=(18, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.title(\"Relation Between credit Limit vs Os Balance \")\n",
    "\n",
    "plt.grid()\n",
    "plt.scatter(df_train['creditlimit'] , df_train['os_balance'], c='k', marker='x')\n",
    "plt.xlabel(\"Credit Limit\")\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f536cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_train['good_bad_flag'], df_train['branchcode'])\n",
    "plt.title(\"Relation Beteween branchcode and Eligiblity Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train.corr()\n",
    "plt.figure(figsize=(28,12))\n",
    "sns.heatmap(corr , annot = True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599fa83",
   "metadata": {},
   "source": [
    "In this heatmap, we can clearly seen the relation between two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0a58c",
   "metadata": {},
   "source": [
    "### Choose ML Model\n",
    "In this step, We have a lots of Machine Learning Model from sklearn package, and we need to decide which model is give us the better performance. then we use that model in final stage and send to the production level.\n",
    "\n",
    "We will use logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import classification_report,plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a4871",
   "metadata": {},
   "source": [
    "First of all, we are use LogisticRegression from sklearn.linear_model package. Here is the little information about LogisticRegression.\n",
    "\n",
    "Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, and True / False) given a set of independent variables. To represent binary / categorical outcome, we use dummy variables. You can also think of logistic regression as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670475d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=['n_cards','os_balance','os_billing','tot_cash_advance_trx','tot_retail_trx','remaining_unpaid_balance','branchcode','overlimit_pct','deliquncy_score','loan_tenure','total_trx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcea7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[train_features].values\n",
    "y_train = df_train['good_bad_flag'].values\n",
    "\n",
    "x_test = df_test[train_features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6cadb",
   "metadata": {},
   "source": [
    "### Predict Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ae09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of model :', logistic_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept of model',logistic_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logistic_model.score(x_train, y_train)\n",
    "print('accuracy_score overall :', score)\n",
    "print('accuracy_score percent :', round(score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the target on the test dataset\n",
    "predict_test = logistic_model.predict(x_test)\n",
    "print('Target on test data',predict_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff99ae",
   "metadata": {},
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dde3e8",
   "metadata": {},
   "source": [
    "Finally, we are done so far. The last step is to deploy our model in production map. Suppose we need to export our model and bind with web application API.\n",
    "Using pickle we can export our model and store in to logistic_model.pkl file, so we can ealy access this file and calculate customize prediction using Web App API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aebb69",
   "metadata": {},
   "source": [
    "A little bit information about pickle:\n",
    "Pickle is the standard way of serializing objects in Python. You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file. Later you can load this file to deserialize your model and use it to make new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'logistic_model.pkl'\n",
    "pkl.dump(logistic_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cfbad",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "For huge data this modle might get slow, in that case we can use XgBoos Classifer Light GBM model. Boosting algorithom will be best for this sceniro ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53924b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
