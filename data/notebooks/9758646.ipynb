{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d4736",
   "metadata": {},
   "source": [
    "# Acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ae391",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/titanic/train.csv')\n",
    "test_df = pd.read_csv('../input/titanic/test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45063bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a538d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#  passing by reference is convenient, because we can clean both datasets at once\n",
    "combine = [train_df,test_df]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b6319",
   "metadata": {},
   "source": [
    "Description of dataset:\n",
    "\n",
    "survival:    Survival \n",
    "PassengerId: Unique Id of a passenger. \n",
    "pclass:    Ticket class     \n",
    "sex:    Sex     \n",
    "Age:    Age in years     \n",
    "sibsp:    # of siblings / spouses aboard the Titanic     \n",
    "parch:    # of parents / children aboard the Titanic     \n",
    "ticket:    Ticket number     \n",
    "fare:    Passenger fare     \n",
    "cabin:    Cabin number     \n",
    "embarked:    Port of Embarkation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6cccb",
   "metadata": {},
   "source": [
    "# Analysing data by Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Pclass',\"Survived\"]].groupby(['Pclass']).mean().sort_values(by = 'Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f95e49",
   "metadata": {},
   "source": [
    "from the above table we can see that passengers on Pclass1 had highest survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f944e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Sex','Survived']].groupby('Sex').mean().sort_values('Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7d653",
   "metadata": {},
   "source": [
    "from the above table we can see that Female passengers had highest survival rate****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['SibSp','Survived']].groupby('SibSp').mean().sort_values('Survived',ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ff82a",
   "metadata": {},
   "source": [
    "# Analyzing by Visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118ac69",
   "metadata": {},
   "source": [
    "## Correlating numerical features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced51758",
   "metadata": {},
   "source": [
    "Let us start by understanding correlations between numerical features and our solution goal (Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ab2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df,col='Survived')\n",
    "g.map(plt.hist, 'Age',bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15950ef",
   "metadata": {},
   "source": [
    "Observations :\n",
    "\n",
    "\n",
    "* Infants (Age <=4) had high survival rate.\n",
    "* Oldest passengers (Age = 80) survived.\n",
    "* Large number of 15-25 year olds did not survive.\n",
    "* Most passengers are in 15-35 age range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da7922",
   "metadata": {},
   "source": [
    "Decisions:\n",
    "\n",
    "* We should consider Age (our assumption classifying #2) in our model training.\n",
    "* Complete the Age feature for null values (completing #1).\n",
    "* We should band age groups (creating #3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da067b",
   "metadata": {},
   "source": [
    "## Correlating numerical and ordinal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14022b3",
   "metadata": {},
   "source": [
    "We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', height=2.2, aspect =1.6)\n",
    "grid.map(plt.hist, 'Age', alpha = 0.5, bins=20 )\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d4a4d",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n",
    "* Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n",
    "* Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n",
    "* Pclass varies in terms of Age distribution of passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a81b",
   "metadata": {},
   "source": [
    "Decision:\n",
    "* Consider Pclass for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ccc8f",
   "metadata": {},
   "source": [
    "\n",
    "## Correlating categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178031bd",
   "metadata": {},
   "source": [
    "Now we can correlate categorical features with our solution goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the x category is the Pclass and the hue category is the Sex. Hence you need to add\n",
    "# order = [1,2,3], hue_order=[\"male\", \"female\"]\n",
    "\n",
    "grid = sns.FacetGrid(train_df, row = 'Embarked', height = 2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass','Survived','Sex', order = [1,2,3], hue_order=[\"female\",\"male\"],palette = 'deep')\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e27741",
   "metadata": {},
   "source": [
    "\n",
    "Obsevations:\n",
    "\n",
    "* female passengers has more survival rate than men.\n",
    "* Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f319e2d",
   "metadata": {},
   "source": [
    "Decisions: \n",
    "\n",
    "* Add Sex feature to model training.\n",
    "* Complete and add Embarked feature to model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22999c",
   "metadata": {},
   "source": [
    "### Correlating categorical and numerical feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840c8ae",
   "metadata": {},
   "source": [
    "We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', height =2.2, aspect=1.6 )\n",
    "grid.map(sns.barplot, 'Sex','Fare', alpha=0.5, ci=None, order = ['male',\"female\"])\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c34f3",
   "metadata": {},
   "source": [
    "observation:\n",
    "* Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n",
    "* Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a1911",
   "metadata": {},
   "source": [
    "Decisions:\n",
    "* Consider banding decision feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f54f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n",
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0a438",
   "metadata": {},
   "source": [
    "# Creating new feature extracting from existing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fd692",
   "metadata": {},
   "source": [
    "### Creating new feature extracting from existing\n",
    "\n",
    "We want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n",
    "\n",
    "In the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adcb2d8",
   "metadata": {},
   "source": [
    "We can replace many titles with a more common name or classify them as `Rare`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95959c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train_df[['Title', 'Survived']].groupby('Title').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a354f38",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.\n",
    "* Survival among Title Age bands varies slightly.\n",
    "* Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\n",
    "\n",
    "Decision.\n",
    "\n",
    "* We decide to retain the new Title feature for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69e39a",
   "metadata": {},
   "source": [
    "We can convert the categorical titles to ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f663b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {'Mr':1,'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5}\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12dd21",
   "metadata": {},
   "source": [
    "Now we can easily drop the Name feature from train ,test dataset. we also do not need Passenger_ID column from train\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"PassengerId\",\"Name\"],axis= 1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0706f",
   "metadata": {},
   "source": [
    "# Converting a categorical feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d2881",
   "metadata": {},
   "source": [
    "Now we can convert features which contain strings to numerical values. This is required by most model algorithms. Doing so will also help us in achieving the feature completing goal.\n",
    "\n",
    "Let us start by converting Sex feature to a new feature called Gender where female=1 and male=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5db299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb54095",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPLETING or replacing the NAN values with relevant values\n",
    "\n",
    "for dataset in combine:\n",
    "    \n",
    "    #complete missing age with median\n",
    "    dataset['Age'].fillna(dataset['Age'].median(),inplace=True)\n",
    "    \n",
    "    #complete embarked with mode\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0],inplace=True)\n",
    "    \n",
    "    #complete missing fare with median\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Training data with null values per column: \\n\",train_df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"testing data with null values per column: \\n\", test_df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c942e26",
   "metadata": {},
   "source": [
    "Let us create Age bands and determine correlations with Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'] = train_df['Age'].astype(int)\n",
    "train_df['Age'] = train_df['Age'].astype(int)\n",
    "train_df['AgeBand'] = pd.cut(train_df['Age'],5 )\n",
    "train_df[['AgeBand','Survived']].groupby('AgeBand',as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039f533",
   "metadata": {},
   "source": [
    "Let us replace Age with ordinals based on these bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Age'] <=16, 'Age'] =0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e60d7",
   "metadata": {},
   "source": [
    "We can now remove the AgeBand feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f664445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =train_df.drop(['AgeBand'],axis = 1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111fad7",
   "metadata": {},
   "source": [
    "# Create new feature combining existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c211cac",
   "metadata": {},
   "source": [
    "We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] +1\n",
    "    \n",
    "train_df[[\"FamilySize\",\"Survived\"]].groupby([\"FamilySize\"],as_index=False).mean().sort_values(by='Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8770fe",
   "metadata": {},
   "source": [
    "Using this we can now create new feature called IsAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize']==1, 'IsAlone']=1\n",
    "\n",
    "train_df[[\"IsAlone\", \"Survived\"]].groupby([\"IsAlone\"], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e666fcb",
   "metadata": {},
   "source": [
    "Let us drop Parch, Sibsp and FamilySize in favour of IaAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"Parch\",\"SibSp\", \"FamilySize\"],axis=1)\n",
    "test_df = test_df.drop([\"Parch\",\"SibSp\", \"FamilySize\"],axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b36044",
   "metadata": {},
   "source": [
    "1. We can also create an artificial feature combining Pclass and Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d07218",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Age*Class\"] = dataset.Age * dataset.Pclass\n",
    "    \n",
    "train_df[[\"Age*Class\", \"Age\",\"Pclass\"]].head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0374fa",
   "metadata": {},
   "source": [
    "# Converting Categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset.Embarked.map({'S': 0, 'C': 1, 'Q': 2}) .astype(int)\n",
    "    \n",
    "train_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7dfa6",
   "metadata": {},
   "source": [
    "# # Creating a new feature using Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"FareBand\"] = pd.qcut(train_df['Fare'],4)\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).count().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbac347",
   "metadata": {},
   "source": [
    "converting the Fare feature to ordinal values based on FareBand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1947b",
   "metadata": {},
   "source": [
    "# Model, predict, Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Logistic regression\n",
    "X_train = train_df.drop('Survived',axis=1)\n",
    "Y_train = train_df['Survived']\n",
    "X_test = test_df.drop('PassengerId',axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,Y_train)\n",
    "y_predict = logreg.predict(X_test)\n",
    "logistics_regression_acc_log = round(logreg.score(X_train,Y_train)*100,2)\n",
    "logistics_regression_acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac8264",
   "metadata": {},
   "source": [
    "We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n",
    "\n",
    "Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n",
    "\n",
    "* Sex is highest positivie coefficient, implying as the Sex value increases (male: 0 to female: 1), the probability of Survived=1 increases the most.\n",
    "* Inversely as Pclass increases, probability of Survived=1 decreases the most.\n",
    "* This way Age*Class is a good artificial feature to model as it has second highest negative correlation with Survived.\n",
    "* So is Title as second highest positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65428d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"PassengerId\": test_df[\"PassengerId\"],\n",
    "                           \"Survived\":y_predict })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1378ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
