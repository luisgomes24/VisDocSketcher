{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01371df",
   "metadata": {},
   "source": [
    "<div width=\"100%\">\n",
    "    <img width=\"100%\" src=\"https://storage.googleapis.com/kaggle-datasets-images/228/482/a520351269b547c89afe790820a1087e/dataset-cover.jpeg\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ce832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4ee8a",
   "metadata": {},
   "source": [
    "<h1 id=\"dataset\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n",
    "    <center>Dataset\n",
    "        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/pima-indians-diabetes-database/diabetes.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in features:\n",
    "    df[feat] /= df[feat].max()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(14,8))\n",
    "_ = sns.heatmap(df.corr(), \n",
    "        xticklabels=df.corr().columns,\n",
    "        yticklabels=df.corr().columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03772c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Outcome', axis=1)\n",
    "labels = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        features, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6494c35",
   "metadata": {},
   "source": [
    "<h1 id=\"ann\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n",
    "    <center>Artificial neural network\n",
    "        <a class=\"anchor-link\" href=\"#ann\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c59877",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid', input_shape=(8, )),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ebdd3",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(\n",
    "                    from_logits=False, label_smoothing=0, \n",
    "                    name='binary_crossentropy'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bcd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y, training):\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f27fbf",
   "metadata": {},
   "source": [
    "## Gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256aa77f",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01, rho=0.1, \n",
    "                                        momentum=0.1, epsilon=1e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2204a3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1761791",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = y_train.values\n",
    "X, y = X_train.values, y_temp.reshape(y_temp.shape[0], 1)\n",
    "\n",
    "y_temp = y_test.values\n",
    "X_val, y_val = X_test.values, y_temp.reshape(y_temp.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6128eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3001\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "test_loss_results = []\n",
    "test_accuracy_results = []\n",
    "\n",
    "loss_fn = tf.keras.metrics.Mean()\n",
    "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    batches = np.array_split(np.arange(len(X)), len(X) // 8)\n",
    "    batches = [b.tolist() for b in batches]\n",
    "\n",
    "    for batch in batches:\n",
    "        X_b, y_b = X[batch], y[batch]\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, X_b, y_b)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_accuracy.update_state(y_b, model(X_b, training=True))\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "        \n",
    "    test_loss_results.append(loss_fn(y_val, model(X_val)).numpy())\n",
    "    test_accuracy_results.append(acc_fn(y_val, model(X_val)).numpy())\n",
    "\n",
    "    if epoch % 300 == 0:\n",
    "        print(\"Epoch {:3d}: Train_Loss:{:3.3f}, Train_Accuracy:{:3.3f}, Test_Loss:{:3.3f}, Test_Accuracy:{:3.3f}\"\n",
    "              .format(epoch, epoch_loss_avg.result(), epoch_accuracy.result(),\n",
    "                      test_loss_results[-1], test_accuracy_results[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02181f73",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b893fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(14, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(14, 8))\n",
    "fig.suptitle('Testing Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(test_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(test_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e035d",
   "metadata": {},
   "source": [
    "<h1 id=\"boosted\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n",
    "    <center>Boosted Trees\n",
    "        <a class=\"anchor-link\" href=\"#boosted\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad5f3f",
   "metadata": {},
   "source": [
    "## Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = tf.feature_column\n",
    "NUMERIC_COLUMNS = list(df.drop('Outcome', axis=1).columns)\n",
    "\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "    return fc.indicator_column(\n",
    "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
    "                                                 vocab))\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(fc.numeric_column(feature_name,\n",
    "                                           dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebad24",
   "metadata": {},
   "source": [
    "## Boosted Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 4\n",
    "\n",
    "est = tf.estimator.BoostedTreesClassifier(feature_columns,\n",
    "                                          n_batches_per_layer=n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c87cb",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = len(y_train)\n",
    "\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
    "    def input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(NUM_EXAMPLES)\n",
    "        # For training, cycle thru dataset as many times as need (n_epochs=None).\n",
    "        dataset = dataset.repeat(n_epochs)\n",
    "        # In memory training doesn't use batching.\n",
    "        dataset = dataset.batch(NUM_EXAMPLES)\n",
    "        return dataset\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b76b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(X_train, y_train)\n",
    "eval_input_fn = make_input_fn(X_test, y_test, shuffle=False, n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522477d",
   "metadata": {},
   "source": [
    "## Train Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1be84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = len(y_train)\n",
    "\n",
    "est.train(train_input_fn, max_steps=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df08fd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = est.evaluate(eval_input_fn)\n",
    "clear_output()\n",
    "\n",
    "print(pd.Series(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117247b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dicts = list(est.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
