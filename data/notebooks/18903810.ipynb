{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a30b9b2",
   "metadata": {},
   "source": [
    "# Titanic-Machine Learning from Disaster - Ishan Saksena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ec86f",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "Aim: Predicting the survival status of the passengers in test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d387bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb # Python debugger\n",
    "from IPython.display import Image, display\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, train_test_split, GridSearchCV\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' # Increase the figures' resolution in jupyter notebook\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a400341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/titanic/train.csv')\n",
    "df_test = pd.read_csv('../input/titanic/test.csv')\n",
    "df_data = df_train.append(df_test).reset_index(drop=True)\n",
    "df_submission = pd.read_csv('../input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028583fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead51732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training null values\\n')\n",
    "print(df_train.isnull().sum()) \n",
    "print('-'*30)\n",
    "print('Testing null values\\n')\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a19769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training info\\n')\n",
    "print(df_train.info())\n",
    "print('-'*30)\n",
    "print('Testing info\\n')\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6578400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4bba8",
   "metadata": {},
   "source": [
    "## Some Observations from the Data\n",
    "\n",
    "### Features\n",
    "    PassengerId\n",
    "    Survived\n",
    "    Pclass (Ticket class)\n",
    "    Name\n",
    "    Sex\n",
    "    Age\n",
    "    SibSp (# of siblings / spouses aboard the Titanic)\n",
    "    Parch (# of parents / children aboard the Titanic)\n",
    "    Ticket\n",
    "    Fare\n",
    "    Cabin\n",
    "    Embarked (Port of Embarkation)\n",
    "    \n",
    "### Missing Values\n",
    "    Age and Cabin have a number of missing values, Embarked has some\n",
    "\n",
    "### Type\n",
    "    Categorical features: Survived, Sex, Embarked, and Pclass(ordinal).\n",
    "    Numercial features: Age, Fare. Discrete: SibSp, Parch.\n",
    "    \n",
    "### Distribution\n",
    "    Only Name has 100% unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f6eed",
   "metadata": {},
   "source": [
    "## Assumtions based on data analysis\n",
    "\n",
    "\n",
    "### Correlating.\n",
    "\n",
    " - Will use heatmaps and other visual methods to figure out which data correlates to survival the most.\n",
    "\n",
    "### Completing.\n",
    "\n",
    "- Fill Age value - A vital component \n",
    "- Embarked value \n",
    "- Cabin value - Has a lot of missing values and might not have high correlation. Potential Drop.\n",
    "\n",
    "### Correcting.\n",
    "\n",
    "- Name and ID have no correlation with survival and can be dropped for the model. \n",
    "- Some duplicates in the Ticket value is an interesting discovery. We can use this piece of information later on with a simple assumption - Passengers with same ticket values may be acquainted with each other.\n",
    "- Cabin can be dropped since we cannot assume that people with missing cabin entry were any different. \n",
    "\n",
    "### Creating.\n",
    "\n",
    "- We could build a feature known as Family - Using the columns Sibsp and Parch. \n",
    "- We could extract the title from Name \n",
    "- Turning the Age and Fair features into ordinal categorical features with Age Bands and Fair Bins\n",
    "\n",
    "### Classifying.\n",
    "\n",
    "- Some Assumptions: \n",
    "- Women (Sex=female) and Children (Age<16) had higher survival rate.\n",
    "- The upper-class passengers (Pclass=1) had higher survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f981c",
   "metadata": {},
   "source": [
    "## Exporatory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\n",
    "display(df_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "display(df_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean())\n",
    "display(df_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean())\n",
    "display(df_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6750d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_data['Embarked'], hue=df_data['Survived'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_data['Sex'], hue=df_data['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72350d8b",
   "metadata": {},
   "source": [
    "## Feature Engineering and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bfc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the sex feature\n",
    "df_data['Sex#'] = df_data['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e664d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature for Family\n",
    "df_data['Fsize'] = df_data['Parch'] + df_data['SibSp'] + 1 #Family = Self + Sib + Parents/Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c458c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature for IsAlone\n",
    "df_data['IsAlone']  = 0\n",
    "df_data.loc[df_data.Fsize == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Plot\n",
    "sns.countplot(x=df_data['IsAlone'], hue=df_data['Survived'])\n",
    "plt.show()\n",
    "\n",
    "#This looks like important data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making bins\n",
    "df_data['Fare'].fillna(80.0, inplace = True)\n",
    "df_data.isna().sum()\n",
    "\n",
    "df_data['FareBin'] = pd.qcut(df_data['Fare'], 6)\n",
    "\n",
    "\n",
    "\n",
    "# Mapping the bins\n",
    "label_encoder = LabelEncoder()\n",
    "df_data['FareBin'] = label_encoder.fit_transform(df_data['FareBin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c412d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits again beacuse we just engineered new feature\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "\n",
    "# Training set and labels\n",
    "x_train = df_train.drop(labels=['Survived','PassengerId'], axis=1)\n",
    "y_train = df_train['Survived']\n",
    "\n",
    "# show columns\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e074b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Family name by Regex - might help later\n",
    "df_data['Fname'] = df_data['Name'].str.extract('([A-Za-z]+.[A-Za-z]+)\\,', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the cause of duplicate tickets is because the passengers knew each other. \n",
    "\n",
    "duplicates = []\n",
    "\n",
    "for uniq in df_data['Ticket'].unique():\n",
    "    temp = df_data.loc[df_data['Ticket'] == uniq, 'Name']\n",
    "    if temp.count() > 1:\n",
    "        duplicates.append(df_data.loc[df_data['Ticket'] == uniq, ['Name', 'Ticket', 'Fare', 'FareBin', 'Fsize', 'Survived']])\n",
    "duplicates = pd.concat(duplicates)\n",
    "duplicates.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_friend = duplicates.loc[(duplicates.Fsize == 1) & (duplicates.Survived.notnull())]\n",
    "df_family = duplicates.loc[(duplicates.Fsize > 1) & (duplicates.Survived.notnull())]\n",
    "display(df_friend.head(), df_family.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020044b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Duplicates: ', duplicates['Name'].count())\n",
    "print('Family: ', df_family['Name'].count())\n",
    "print('Friend: ', df_friend['Name'].count())\n",
    "print('Other: ', duplicates['Name'].count() - df_family['Name'].count() - df_friend['Name'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33608f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a column for just Connected Survival\n",
    "df_data['Connected_Survival'] = 0.5\n",
    "\n",
    "for ticket_num, df_grp in df_data.groupby('Ticket'):\n",
    "    if len(df_grp) > 1: # Duplicates in Ticket\n",
    "            for index, row in df_grp.iterrows():\n",
    "                smax = df_grp.drop(index).Survived.max()\n",
    "                smin = df_grp.drop(index).Survived.min()\n",
    "                pid = row.PassengerId\n",
    "                if smax == 1.0:\n",
    "                    df_data.loc[df_data['PassengerId'] == pid, 'Connected_Survival'] = 1\n",
    "                elif smin == 0.0:\n",
    "                    df_data.loc[df_data['PassengerId'] == pid, 'Connected_Survival'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked Filling by checking Fare\n",
    "df_data[df_data['Embarked'].isnull()][['Embarked', 'Pclass', 'Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check their relation in groups\n",
    "df_data.groupby(['Embarked', 'Pclass'])[['Fare']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80 is closest to C1 - Assigning C and mapping\n",
    "\n",
    "# Filling missing values with the value that has greatest frequency\n",
    "df_data['Embarked'] = df_data['Embarked'].fillna('C')\n",
    "\n",
    "# Mapping\n",
    "df_data['Embarked#'] = df_data['Embarked'].map({'S': 1, 'C': 2, 'Q': 3})\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting Titles from Name - might help in filling Age\n",
    "df_data['Title'] = df_data['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "df_data['Title'] = df_data['Title'].replace(['Capt', 'Col', 'Rev', 'Don', 'Countess', 'Jonkheer', 'Dona', 'Sir', 'Dr', 'Major', 'Dr'], 'Rare')\n",
    "df_data['Title'] = df_data['Title'].replace(['Mlle', 'Mme', 'Ms'], 'Miss')\n",
    "df_data['Title'] = df_data['Title'].replace(['Lady'], 'Mrs')\n",
    "df_data['Title'] = df_data['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d63048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30c5cd",
   "metadata": {},
   "source": [
    "#### Filling Values of Age\n",
    "1. Linear Regression/XGBRegressor\n",
    "2. Using Title\n",
    "3. Using Pclass and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_data.Age.describe())\n",
    "display(df_train['Age'].isna().sum())\n",
    "display(df_test['Age'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc540a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Title - \"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 \n",
    "df_data.groupby('Title')['Age'].median().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a735ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_age = df_data.groupby('Title')['Age'].median().values\n",
    "df_data['Age_pred1'] = df_data['Age']\n",
    "for i in range(5):\n",
    "    df_data.loc[(df_data['Title'] == i) & (df_data['Age'].isnull()), 'Age_pred1'] = title_age[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acccb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Linear Regression\n",
    "x_train = df_data[df_data.Age.notnull()]\n",
    "y_train = df_data[df_data.Age.notnull()]['Age']\n",
    "x_test = df_data[df_data.Age.isnull()]\n",
    "\n",
    "#select_feature = ['Sex#', 'Pclass', 'Title', 'FareBin','Embarked#', 'IsAlone']\n",
    "select_feature = ['Sex#', 'Pclass', 'Title', 'FareBin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train[select_feature], y_train)\n",
    "reg.score(x_train[select_feature], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Age_pred3'] = df_data['Age']\n",
    "df_data.loc[df_data['Age'].isnull(), 'Age_pred2'] = reg.predict(x_test[select_feature]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(x_train[select_feature], y_train)\n",
    "xgb.score(x_train[select_feature], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Age_pred3'] = df_data['Age']\n",
    "df_data.loc[df_data['Age'].isnull(), 'Age_pred3'] = xgb.predict(x_test[select_feature]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Higher survival rate for age <16, we put filter for predicting minors\n",
    "\n",
    "df_data['Minor_pred1'] = ((df_data['Age_pred1']) < 16)*1\n",
    "df_data['Minor_pred2'] = ((df_data['Age_pred2']) < 16)*1\n",
    "df_data['Minor_pred3'] = ((df_data['Age_pred3']) < 16)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing Age like Fare\n",
    "\n",
    "\n",
    "df_data['AgeBin_pred1'] = pd.qcut(df_data['Age_pred1'], 5)\n",
    "#df_data['AgeBin_pred2'] = pd.qcut(df_data['Age_pred2'], 5)\n",
    "df_data['AgeBin_pred3'] = pd.qcut(df_data['Age_pred3'], 5)\n",
    "\n",
    "df_data['AgeBin_pred1'] = label_encoder.fit_transform(df_data['AgeBin_pred1'])\n",
    "#df_data['AgeBin_pred2'] = label_encoder.fit_transform(df_data['AgeBin_pred2'])\n",
    "df_data['AgeBin_pred3'] = label_encoder.fit_transform(df_data['AgeBin_pred3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217747ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assumption - What if a missing cabin value means that the passenger was not assigned a premium cabin?\n",
    "\n",
    "df_data['Cabin'] = df_data['Cabin'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin(x):\n",
    "    try:\n",
    "        if x != 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Cabin'] = df_data['Cabin'].apply(cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61cc36",
   "metadata": {},
   "source": [
    "## Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f81d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['PassengerId', 'Pclass', 'Sex#']] = df_data[['PassengerId', 'Pclass', 'Sex#']].astype('int32')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ee7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = ['Survived', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Sex#', 'Fsize', 'IsAlone', 'FareBin', 'Connected_Survival', 'Embarked#', 'Age_pred1', 'Age_pred3', 'Minor_pred1', 'Minor_pred3', 'AgeBin_pred1', 'AgeBin_pred3', 'Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c79eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df_train[train_features].astype(float).corr()\n",
    "corr_mat_fil = corr_mat.loc[:, 'Survived'].sort_values(ascending=False)\n",
    "corr_mat_fil = pd.DataFrame(data=corr_mat_fil[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "bar = sns.barplot(x=corr_mat_fil.Survived.abs(), y=corr_mat_fil.index, data=corr_mat_fil, palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = ['Survived', 'Sex#', 'Connected_Survival', 'FareBin', 'Minor_pred3', 'Embarked#', 'AgeBin_pred3', 'Parch', 'Age_pred3','IsAlone', 'Pclass', 'Cabin']\n",
    "corr_mat = df_train[train_features].astype(float).corr()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr_mat.abs(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d620cb2",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea46713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features = ['Sex#', 'Pclass', 'FareBin', 'Connected_Survival', 'Minor_pred3', 'Embarked#', 'Cabin']\n",
    "#selected_features = ['Sex#', 'Pclass', 'FareBin', 'Connected_Survival', 'Cabin']\n",
    "selected_features = ['Sex#', 'Pclass', 'FareBin', 'Connected_Survival', 'Minor_pred3', 'Embarked#', 'IsAlone']\n",
    "\n",
    "\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "\n",
    "x_train = df_train[selected_features]\n",
    "y_train = df_train['Survived']\n",
    "x_test = df_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=2)\n",
    "\n",
    "grid_parameters = {'n_estimators': [i for i in range(300, 601, 50)], 'min_samples_split' : [10, 20, 30, 40]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=grid_parameters)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print('Best: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29422a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = grid_result.best_params_['n_estimators']\n",
    "min_samples_split = grid_result.best_params_['min_samples_split']\n",
    "\n",
    "RFC = RandomForestClassifier(random_state=2, n_estimators=300, min_samples_split=40)\n",
    "RFC.fit(x_train, y_train)\n",
    "y_pred = RFC.predict(x_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': y_pred})\n",
    "output = output.astype('int')\n",
    "output.to_csv('predictionnocwisalone1.csv', index=False)\n",
    "#print('Your file was successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49496d50",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed07e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Sex#', 'Pclass', 'FareBin', 'Connected_Survival', 'Minor_pred3', 'Embarked#', 'Cabin']\n",
    "\n",
    "\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "\n",
    "x_train = df_train[selected_features]\n",
    "y_train = df_train['Survived']\n",
    "x_test = df_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39273adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc = XGBClassifier(random_state=2)\n",
    "\n",
    "#xgbc.fit(x_train, y_train)\n",
    "#y_pred = xgbc.predict(x_test)\n",
    "\n",
    "#output = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': y_pred})\n",
    "#output = output.astype('int')\n",
    "##print('Your file was successfully saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
