{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07601a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "# import pydot\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from colorama import Fore\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "%config Completer.use_jedi = False\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All modules have been imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "feature_dictionary = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.YlOrRd):\n",
    "    plt.figure(figsize = (6,6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    cm = np.round(cm,2)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76be3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example, feature_dictionary=feature_dictionary):\n",
    "    parsed_example = tf.io.parse_example(example, feature_dictionary)\n",
    "    return parsed_example\n",
    "\n",
    "def read_data(filename):\n",
    "    full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    full_dataset = full_dataset.cache()\n",
    "    print(\"Size of Training Dataset: \", len(list(full_dataset)))\n",
    "    \n",
    "    feature_dictionary = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }   \n",
    "\n",
    "    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    print(full_dataset)\n",
    "    for image_features in full_dataset:\n",
    "        image = image_features['image'].numpy()\n",
    "        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n",
    "        image = tf.reshape(image, [299, 299])        \n",
    "        image=image.numpy()\n",
    "        image=cv2.resize(image,(100,100))\n",
    "        image=cv2.merge([image,image,image])\n",
    "        image\n",
    "        images.append(image)\n",
    "        labels.append(image_features['label_normal'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=['../input/ddsm-mammography/training10_0/training10_0.tfrecords',\n",
    "          '../input/ddsm-mammography/training10_1/training10_1.tfrecords',\n",
    "          '../input/ddsm-mammography/training10_2/training10_2.tfrecords',\n",
    "          '../input/ddsm-mammography/training10_3/training10_3.tfrecords',\n",
    "          '../input/ddsm-mammography/training10_4/training10_4.tfrecords'\n",
    "          ]\n",
    "\n",
    "for file in filenames:\n",
    "    read_data(file)\n",
    "    \n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ea5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(images)\n",
    "y=np.array(labels)\n",
    "\n",
    "\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.3, random_state=42,\n",
    "                                                      shuffle=True,stratify=y)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42,\n",
    "                                                shuffle=True,stratify=y_test1)\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c07817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our ANN Model\n",
    "ann_model=Sequential()\n",
    "ann_model.add(Dense(16, input_dim=128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\n",
    "ann_model.add(BatchNormalization())\n",
    "ann_model.add(Dropout( 0.2))\n",
    "ann_model.add(Dense(1,activation='sigmoid'))\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "names = [\n",
    "        \"K Nearest Neighbour Classifier\",\n",
    "        'SVM',\n",
    "        \"Random Forest Classifier\",\n",
    "        \"AdaBoost Classifier\", \n",
    "        \"XGB Classifier\",\n",
    "         ]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "        ]\n",
    "zipped_clf = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train= sentiment_fit.predict(X_train)\n",
    "    y_pred_val = sentiment_fit.predict(X_val)\n",
    "    y_pred_test = sentiment_fit.predict(X_test)\n",
    "    \n",
    "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
    "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
    "    \n",
    "    \n",
    "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
    "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
    "   \n",
    "    \n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
    "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n",
    "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n",
    "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n",
    "  \n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Train Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"Accuracy core : {}%\".format(train_accuracy))\n",
    "    cm=confusion_matrix(y_train,y_pred_train)\n",
    "    cm_plot=plot_confusion_matrix(cm,classes=['0','1'])\n",
    "    \n",
    "    print('------------------------ Validation Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"Accuracy score : {}%\".format(val_accuracy))\n",
    "    cm=confusion_matrix(y_val,y_pred_val)\n",
    "    cm_plot=plot_confusion_matrix(cm,classes=['0','1'])\n",
    "    \n",
    "    print('------------------------ Test Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"Accuracy score : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall score: {}\".format(test_recall))\n",
    "    print(\"Precision score : {}\".format(test_precision))\n",
    "    cm=confusion_matrix(y_test,y_pred_test)\n",
    "    cm_plot=plot_confusion_matrix(cm,classes=['0','1'])\n",
    "    \n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([('Classifier', c)])\n",
    "        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n",
    "        #print(c)\n",
    "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model= ResNet101(input_shape=(100,100,3), weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dense(16,kernel_initializer='he_uniform')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "predictions = Dense(128, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(x_train)\n",
    "val_features=model_feat.predict(x_val)\n",
    "test_features=model_feat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=y_train\n",
    "val_y=y_val\n",
    "test_y=y_test\n",
    "ann_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10,class_weight={0:0.6,1:1})\n",
    "loss_value , accuracy = ann_model.evaluate(train_features, train_y)\n",
    "print('Train_accuracy is:' + str(accuracy))\n",
    "loss_value , accuracy = ann_model.evaluate(val_features, val_y)\n",
    "print('Validation_accuracy is := ' + str(accuracy))\n",
    "loss_value , accuracy = ann_model.evaluate(test_features, test_y)\n",
    "print('test_accuracy is : = ' + str(accuracy))\n",
    "print(\"Performance Report:\")\n",
    "y_pred1=ann_model.predict_classes(test_features)\n",
    "\n",
    "target=[\"0\",\"1\"]\n",
    "from sklearn import metrics\n",
    "print('Accuracy score is :', np.round(metrics.accuracy_score(test_y, y_pred1),4))\n",
    "print('Precision score is :', np.round(metrics.precision_score(test_y, y_pred1, average='weighted'),4))\n",
    "print('Recall score is :', np.round(metrics.recall_score(test_y,y_pred1, average='weighted'),4))\n",
    "print('F1 Score is :', np.round(metrics.f1_score(test_y, y_pred1, average='weighted'),4))\n",
    "print('ROC AUC Score is :', np.round(metrics.roc_auc_score(test_y, y_pred1,multi_class='ovo', average='weighted'),4))\n",
    "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(test_y, y_pred1),4))\n",
    "print('\\t\\tClassification Report:\\n', metrics.classification_report(test_y, y_pred1,target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab72a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
