{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c084be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,cv2,glob\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6359bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path=Path.cwd()/'fm1/nomask'\n",
    "if not path.exists():\n",
    "    path.mkdir(parents=True)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder='/kaggle/input/aasaniface/nomask'  \n",
    "folderLen= len(inputFolder)\n",
    "#os.mkdir('./fm/mask')\n",
    "for img in glob.glob(inputFolder +\"/*.*\"):\n",
    "    #print(img)\n",
    "    image=cv2.imread(img)\n",
    "    imgResized=cv2.resize(image,(150,150))\n",
    "    cv2.imwrite(\"fm1/nomask\"+img[folderLen:],imgResized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99face99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path.cwd()/'fm/nomask'\n",
    "if not path.exists():\n",
    "    path.mkdir(parents=True)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee74edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder='../input/aasaniface/nomask'\n",
    "folderLen= len(inputFolder)\n",
    "#os.mkdir('./fm/nomask')\n",
    "for img in glob.glob(inputFolder +\"/*.*\"):\n",
    "    image=cv2.imread(img)\n",
    "    imgResized=cv2.resize(image,(150,150))\n",
    "    cv2.imwrite(\"fm/nomask\"+img[folderLen:],imgResized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7163a",
   "metadata": {},
   "source": [
    "# checking rezised pictures with the defined pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8cc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder='./fm1/nomask'\n",
    "folderLen= len(inputFolder)\n",
    "#os.mkdir('fm')\n",
    "for img in glob.glob(inputFolder +\"/*.*\"):\n",
    "    image=cv2.imread(img)\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e607d57",
   "metadata": {},
   "source": [
    "# these some image qritten to curr dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder='../input/aasaniface/nomask'\n",
    "folderLen= len(inputFolder)\n",
    "\n",
    "for img in glob.glob(inputFolder +\"/*.*\"):\n",
    "    image=cv2.imread(img)\n",
    "    imgResized=cv2.resize(image,(150,150))\n",
    "    cv2.imwrite(\"./\"+img[folderLen:],imgResized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84faa8",
   "metadata": {},
   "source": [
    "# importing necessary librraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa811f",
   "metadata": {},
   "source": [
    "# training the model and putting it into fm1 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\n",
    "train_data = ImageDataGenerator(rescale = 1./255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\n",
    "training_set = train_data.flow_from_directory('./fm1', batch_size = 5, target_size = (150,150), class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8280e33",
   "metadata": {},
   "source": [
    "# defining convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the CNN as a sequence of layers.\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15eec7",
   "metadata": {},
   "source": [
    "# Adding first convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44925597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 1st Convolutional layer\n",
    "#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [150,150,3],activation = 'relu'))\n",
    "#activation function relu is applied to decrease any linearity that might have arrised while applying filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a597acd",
   "metadata": {},
   "source": [
    "# Applying maxpooling at first convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying max pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18a645",
   "metadata": {},
   "source": [
    "# Adding second convolutional network and applying max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5887e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 2nd Convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba6774",
   "metadata": {},
   "source": [
    "# Adding third convolutional network and applying max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 3rd Convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20c6e9",
   "metadata": {},
   "source": [
    "# applying flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f759699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the input of step 4 is an flattened array,\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d7c5e",
   "metadata": {},
   "source": [
    "# creating input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming an ann with 128 input neurons\n",
    "cnn.add(tf.keras.layers.Dense(units = 300, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e012e10",
   "metadata": {},
   "source": [
    "# Adding output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding ouput layer of the ann\n",
    "cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be92ef",
   "metadata": {},
   "source": [
    "# Compiling CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d2ee5",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(x = training_set,  epochs = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec18853",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('facemask_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081f74d",
   "metadata": {},
   "source": [
    "# Again loading the model to predict the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29049a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "classifier = load_model('facemask_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image as imgproc\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e46978",
   "metadata": {},
   "source": [
    "## Predicting the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = '/kaggle/input/aasaniface/nomask/IMG20210714190031_00.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing images\n",
    "test_img = imgproc.load_img(testimage,target_size = (150,150))\n",
    "#converting image to array\n",
    "test_img = image.img_to_array(test_img)\n",
    "test_img = np.expand_dims(test_img,axis = 0)\n",
    "result = classifier.predict(test_img)\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = ' Picture without mask'\n",
    "else:\n",
    "    prediction = 'Picture with mask'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db11d27",
   "metadata": {},
   "source": [
    "# predicting another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm=imgproc.load_img('./fm1/nomask/IMG20210714190031_00.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = imgproc.load_img('./fm1/nomask/IMG20210714190031_00.jpg',target_size = (150,150))\n",
    "#converting image to array\n",
    "test_img = imgproc.img_to_array(test_img)\n",
    "test_img = np.expand_dims(test_img,axis = 0)\n",
    "result = classifier.predict(test_img)\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = ' Picture without mask'\n",
    "else:\n",
    "    prediction = 'Picture with mask'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
