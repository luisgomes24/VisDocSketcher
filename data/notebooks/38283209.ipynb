{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6760136",
   "metadata": {},
   "source": [
    "# What is about ? \n",
    "\n",
    "Simple Baseline to start with : Covert MultiLabel to MultiTarge  + Embeddings + Ridge \n",
    "\n",
    "    Features - precalculated embeddings for protein sequences. Thanks to Grandmaster Sergei Fironov for sharing protein emebedding calculated by T5 protein language model from the Rost Lab. \n",
    "    \n",
    "    Targets - multi-label is converted to mult-target (binary classification) task - i.e. for each sample we are preciting the probability that this label is assigned to that sample. In total there can be 40 000 labels - that is too much, so we choose only N the most frequent ones. \n",
    "    \n",
    "    After that - use any ML-model you like to make predictions. Start with Ridge as the he most simple and fast one. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f023ab0",
   "metadata": {},
   "source": [
    "Thanks to all  authors of the public notebooks and datasets which are quite helpful (please upvote them) and especially those ones:\n",
    "\n",
    "LEONID KULYK: https://www.kaggle.com/code/leonidkulyk/eda-cafa5-pfp-interactive-dags-plotly\n",
    "\n",
    "MARÍLIA PRATA: https://www.kaggle.com/code/mpwolke/cafa-5-protein-prediction\n",
    "\n",
    "DAREK KŁECZEK:  https://www.kaggle.com/code/thedrcat/cafa-eda\n",
    "\n",
    "D_KHATRI:  https://www.kaggle.com/code/dhruvkhatri/naive-submission-afa\n",
    "\n",
    "* Pretrained T5 protein embeddings: \n",
    "    * https://www.kaggle.com/datasets/danofer/uniprotkbswiss-prot-protein-embeddings\n",
    "\n",
    "Grandmaster Sergei Fironov shared protein emebedding calculated by T5 protein language model from the Rost Lab:  https://www.kaggle.com/datasets/sergeifironov/t5embeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6dc8a",
   "metadata": {},
   "source": [
    "# Key param(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels_to_consider = 1499 # We will choose only top frequent labels (in train) and predict only them. \n",
    "n_max_preds = 1499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0start = time.time() \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e475d7e6",
   "metadata": {},
   "source": [
    "# Prepare multi-target Y  ( transition from multi-label task to multi target task - binary classifiction ). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a2854",
   "metadata": {},
   "source": [
    "## Load train labels and select the most frequent ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainTerms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\",sep=\"\\t\")\n",
    "print(trainTerms.shape)\n",
    "display(trainTerms.head(2))\n",
    "vec_freqCount = (trainTerms['term'].value_counts())\n",
    "print(vec_freqCount )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop very rares\n",
    "vec_freqCount = vec_freqCount[vec_freqCount>=30]\n",
    "print(vec_freqCount.shape[0])\n",
    "vec_freqCount.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_freqCount[vec_freqCount>200].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "labels_to_consider = list(vec_freqCount.index[:n_labels_to_consider] )\n",
    "print('n_labels_to_consider:', len(labels_to_consider), 'First 10:', labels_to_consider[:10] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366cc3e",
   "metadata": {},
   "source": [
    "## Load protein Ids in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fn = '/kaggle/input/t5embeds/train_ids.npy'\n",
    "vec_train_protein_ids = np.load(fn)\n",
    "print(vec_train_protein_ids.shape)\n",
    "vec_train_protein_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574a24f",
   "metadata": {},
   "source": [
    "## Prepare Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "train_size = 142246 # len(X)\n",
    "Y = np.zeros( (train_size ,n_labels_to_consider) )\n",
    "print(Y.shape)\n",
    "\n",
    "series_train_protein_ids = pd.Series(vec_train_protein_ids ) # \n",
    "\n",
    "trainTerms_smaller = trainTerms[ trainTerms['term'].isin( labels_to_consider ) ] # to speed-up the next step \n",
    "print( trainTerms_smaller.shape)\n",
    "\n",
    "for i in range(Y.shape[1]):\n",
    "    m = trainTerms_smaller['term'] ==  labels_to_consider[i]\n",
    "#     m.sum()\n",
    "    Y[:,i] =  series_train_protein_ids.isin(  set(trainTerms_smaller[m]['EntryID'] ) ).astype(float )\n",
    "    if (i % 10) == 0: \n",
    "        print(i, m.sum())\n",
    "Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# save for possible future reuse \n",
    "fn4saveY = 'Y_'+str(Y.shape[1])\n",
    "print(fn4saveY)\n",
    "np.save( fn4saveY , Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fn4save_labels = 'Y_'+str(Y.shape[1]) + '_labels'\n",
    "np.save(fn4save_labels, labels_to_consider )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( list(np.load(fn4save_labels +'.npy' ))[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ded15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Someone may prefer  Y as dataframe \n",
    "if 1:\n",
    "    df_Y = pd.DataFrame(data = Y, columns = labels_to_consider)\n",
    "    display(df_Y.head(2))\n",
    "#     print( df.info().sum() )\n",
    "    print('memory_usage:', df_Y.memory_usage(index=True).sum() )\n",
    "    display(df_Y.describe() )    \n",
    "    fn4save =  'df_Y_'+str(Y.shape[1]) + '.csv'\n",
    "    df_Y.to_csv(fn4save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201486",
   "metadata": {},
   "source": [
    "# Load train features - precalculated embeddings for the proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fn = '/kaggle/input/protein-embeddings-1/reduced_embeddings_file.npy'\n",
    "# fn = '/kaggle/input/protein-embeddings-1/embed_protbert_train_clip_1200_first_70000_prot.csv'\n",
    "fn = '/kaggle/input/t5embeds/train_embeds.npy'\n",
    "# fn = '/kaggle/input/t5embeds/test_embeds.npy'\n",
    "\n",
    "print(fn)\n",
    "if '.csv' in fn:\n",
    "    df = pd.read_csv(fn, index_col = 0)\n",
    "    X = df.values\n",
    "elif '.npy' in fn:\n",
    "    X = np.load(fn)\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8668c",
   "metadata": {},
   "source": [
    "## Load protein Ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a89589",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fn = '/kaggle/input/t5embeds/train_ids.npy'\n",
    "vec_train_protein_ids = np.load(fn)\n",
    "print(vec_train_protein_ids.shape)\n",
    "vec_train_protein_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef9fb6",
   "metadata": {},
   "source": [
    "## Sanity check \n",
    "\n",
    "Ids from the train data are the same as from the train labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(vec_train_protein_ids) &set (trainTerms['EntryID'] )\n",
    "print( len(s), len( X ) )  # get same numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c7607",
   "metadata": {},
   "source": [
    "# Prepare Train-Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "IX = np.arange(len(X))\n",
    "IX_train, IX_test, _,_ = train_test_split( IX, IX, train_size=0.1, random_state=42)\n",
    "print(len(IX_train), len(IX_test),  IX_train[:10], IX_test[:10] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba499c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = Ridge(alpha=1.0) # 0.805\n",
    "model = RidgeCV() # 0.8127 auc, with 15% train\n",
    "# model = RandomForestClassifier(n_estimators=200,  max_depth=14, min_samples_split=3, min_samples_leaf=1,n_jobs=-1) ## much slower... \n",
    "# model =MLPClassifier(hidden_layer_sizes=(512,256), early_stopping=True,\n",
    "#                      validation_fraction=0.05,learning_rate=\"adaptive\",learning_rate_init=0.005) # 0.59 rocauc , and slower\n",
    "str_model_id = 'Ridge1'\n",
    "\n",
    "df_models_stat = pd.DataFrame()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(X[IX_train,:],Y[IX_train,:])\n",
    "Y_pred_test = model.predict(X[IX_test,:])\n",
    "tt = time.time() - t0\n",
    "print(str_model_id, tt)\n",
    "l = []\n",
    "for i in range(Y.shape[1]):\n",
    "    if len(np.unique(Y[IX_test,i]) ) > 1:\n",
    "        s = roc_auc_score(Y[IX_test,i], Y_pred_test[:,i]);\n",
    "    else:\n",
    "        s = 0.5\n",
    "    l.append(s)        \n",
    "    if i %10 == 0:\n",
    "        print(i, s)\n",
    "df_models_stat.loc[str_model_id,'RocAuc Mean Test'] = np.mean(l)\n",
    "df_models_stat.loc[str_model_id,'Time'] = np.round(tt,1)\n",
    "df_models_stat.loc[str_model_id,'Test Size'] = len(IX_test)\n",
    "df_models_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f65c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae65a5",
   "metadata": {},
   "source": [
    "## Scores statistics over targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78877891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(l)\n",
    "plt.show()\n",
    "pd.Series(l).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1176662",
   "metadata": {},
   "source": [
    "# Retrain model on the the full sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30668af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81762eb",
   "metadata": {},
   "source": [
    "# Submission preparations Step 1 - load features and calculate predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e136dd",
   "metadata": {},
   "source": [
    "## Load features for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fn = '/kaggle/input/protein-embeddings-1/reduced_embeddings_file.npy'\n",
    "# fn = '/kaggle/input/protein-embeddings-1/embed_protbert_train_clip_1200_first_70000_prot.csv'\n",
    "# fn = '/kaggle/input/t5embeds/train_embeds.npy'\n",
    "fn = '/kaggle/input/t5embeds/test_embeds.npy'\n",
    "print(fn)\n",
    "X_submit = np.load(fn)\n",
    "print(X_submit.shape)\n",
    "# X_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35934614",
   "metadata": {},
   "source": [
    "## Calculate prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d149a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Y_submit =  model.predict(X_submit)\n",
    "print(Y_submit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c759e",
   "metadata": {},
   "source": [
    "# Submission preparations Step 2 - prepare submision in desired format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_finalSubmission = pd.DataFrame(columns = ['Protein Id', 'GO Term Id','Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07832da7",
   "metadata": {},
   "source": [
    "## Load protein ids for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fn = '/kaggle/input/t5embeds/test_ids.npy'\n",
    "vec_test_protein_ids = np.load(fn)\n",
    "print(vec_test_protein_ids.shape)\n",
    "vec_test_protein_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09276a0",
   "metadata": {},
   "source": [
    "## \"Melt\" protein ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "l = []\n",
    "for k in list(vec_test_protein_ids):\n",
    "    l += [ k] * Y_submit.shape[1]\n",
    "print(len(l), l[:20])    \n",
    "\n",
    "df_finalSubmission['Protein Id'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11958e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# df_finalSubmission.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b72775",
   "metadata": {},
   "source": [
    "## \"Melt\" Labels (Gene ontology terms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721582ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission['GO Term Id'] = labels_to_consider * Y_submit.shape[0]\n",
    "# df_finalSubmission.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77040d",
   "metadata": {},
   "source": [
    "## Assign predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58871018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission['Prediction'] = Y_submit.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_finalSubmission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee9a17",
   "metadata": {},
   "source": [
    "### drop 0 preds and negatives\n",
    "* opt: sort by score, keep top K per Protein\n",
    "* warning : will be slooow with this many rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd96b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_finalSubmission['Prediction'] = df_finalSubmission['Prediction'].round(3)\n",
    "df_finalSubmission = df_finalSubmission[df_finalSubmission['Prediction']>0]\n",
    "df_finalSubmission.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bc505",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_finalSubmission.to_csv(\"submission.tsv\",header=False, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba6a0a",
   "metadata": {},
   "source": [
    "## Show some info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76be755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# df_finalSubmission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_finalSubmission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize = (15,4))\n",
    "plt.hist(df_finalSubmission['Prediction'].values, bins = 300 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52edd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission.iloc[:,0:2].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7404a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission.shape[0]/141864 ## num proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalSubmission.shape[0]/n_labels_to_consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
