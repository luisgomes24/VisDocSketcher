{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/complex1/complex1.jfif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/complex2/complex2.jfif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82348672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/computer/computer.PNG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(plt.imread(\"../input/picture/picture_comp.PNG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a400f6",
   "metadata": {},
   "source": [
    "PART 1: INTRODUCTION TO NEURAL NETWORKS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2c1ad",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983cb01",
   "metadata": {},
   "source": [
    "Just like your brain oftentimes mistakenly categorizes objects at first sight, convolutional neural networks are prone to the same indecision when presented with an object or an image from an angle that can easily place it under more than one category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce62b1d",
   "metadata": {},
   "source": [
    "Why Convolutional Neural Networks Are So Important\n",
    "To understand this, you can ask yourself a couple of simple questions:\n",
    "\n",
    "How do self-driving cars recognize other cars as well as pedestrians and street objects?\n",
    "How did Facebook go from making you tag people in images yourself, to being able to identify your friends and automatically tag them as it does now?\n",
    "\n",
    "And the answer to both questions would be: through the magic of convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/general-description/general_view.PNG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bbb109",
   "metadata": {},
   "source": [
    "PART 1: DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38932db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#Generate batches of tensor image data with real-time data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce184aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        '../input/cat-and-dog/training_set/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5509e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        '../input/cat-and-dog/test_set/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a8963",
   "metadata": {},
   "source": [
    "PART 2:BUILDING CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/feature/feature.PNG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92378ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb90dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120b870",
   "metadata": {},
   "source": [
    "1.Step: Creating CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1116dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d731a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\",input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ccca2a",
   "metadata": {},
   "source": [
    "2.Step: Pooling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27c11c",
   "metadata": {},
   "source": [
    "Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. his is to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd96e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b36eb",
   "metadata": {},
   "source": [
    "Max Pooling returns the maximum value from the portion of the image covered by the Kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ff645",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(plt.imread(\"../input/max-pooling/max_pooling.PNG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09304b6",
   "metadata": {},
   "source": [
    "3.Step: Adding Second Convolutional Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "from tensorflow.keras.layers import MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbbafa",
   "metadata": {},
   "source": [
    "4.Step: Flattening: Transformin all these Copnvolutional Layers into 1D vector in order to use ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1eb90",
   "metadata": {},
   "source": [
    "5. Step: Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e884ad",
   "metadata": {},
   "source": [
    "Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the Softmax Classification technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9069959",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98503949",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894826f4",
   "metadata": {},
   "source": [
    "Compiling the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ec94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc6140",
   "metadata": {},
   "source": [
    "PART 3: MAKING PREDICTIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acade22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832d379",
   "metadata": {},
   "source": [
    "image.load_img() loads image into pil format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45caef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(location):\n",
    "    test_image=image.load_img(location,target_size=(64,64))\n",
    "    test_image=image.img_to_array(test_image)\n",
    "    test_image=np.expand_dims(test_image, axis=0)\n",
    "    result=cnn.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    if result[0][0] == 1:\n",
    "        \n",
    "        prediction = \"It is a dog\"\n",
    "    else:\n",
    "        prediction = \"It is a cat\"\n",
    "    print(result[0][0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866768e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= \"../input/single-cat/cat_or_dog_2.jpg\"\n",
    "predictor(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066215e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= \"../input/singledog/cat_or_dog_1.jpg\"\n",
    "predictor(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38146f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= \"../input/single-cat2/cat.jpg\"\n",
    "predictor(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ace0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= \"../input/single-dog2/dog.jpg\"\n",
    "predictor(location)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
