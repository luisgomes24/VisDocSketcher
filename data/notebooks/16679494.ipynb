{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5154af",
   "metadata": {},
   "source": [
    "# Data Augmentationについて\n",
    "> Data augmentation can be viewed as an injection of prior knowledge about the invariant properties of the data against certain transformations. Augmented data can cover unexplored input space, prevent overfitting, and improve the generalization ability of a DL model.\n",
    "\n",
    "[https://arxiv.org/pdf/1706.00527.pdf](https://arxiv.org/pdf/1706.00527.pdf)より引用\n",
    "\n",
    "Data Augmentationとは画像でお馴染みの操作で、Deep Learning大流行の昨今、皆さんもイヌネコの画像分類で左右にフリップしたり微小な平行移動や回転を加えてデータ数を水増しするというのを見たことがあるでしょう。この画像の例からData Augmentationはデータの水増しという印象になりがちですが、ではこの操作による精度のゲインはどこから来ているのでしょうか？無から有は生まれませんから、それに相当する情報をどこからか得ていることになります。実はこれは本質的には「とある変換操作がターゲットラベルを変化させない」というPrior Informationをモデルに注入することに相当していると言えます。他にも正則化の一種とみる見方もあり、いずれも同じことですが、この説明はデータと向き合い、どのようなaugmentationがあり得るのかを考える上でとても参考になると思っています。この考え方に立つと、画像以外の様々なデータタイプに対しても適用可能になるでしょう。これは、「何がどうなったらラベルがTrueになるか」などを考えるFeature Engineeringとスタンスは異なりますが近いものがあるようにも感じられますね。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリimportしておきます\n",
    "import os\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ一覧をDataFrameとして読み込みます\n",
    "df_train = pd.read_csv('/kaggle/input/data-science-spring-osaka-2021/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/data-science-spring-osaka-2021/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの先頭部分をチラッと見ておきましょう\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7541746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df89f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# センサーデータの方も1個目を見てみましょう\n",
    "df_sensor = pd.read_csv('/kaggle/input/data-science-spring-osaka-2021/train/train_0000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356df6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# センサーデータは数百行程度の可変長データです。\n",
    "# これを高さがHピクセル、幅が1ピクセル、チャネル数20の画像として読み込むことを考えます。\n",
    "# 今回のデータは1dなのですがあえて幅1ピクセルの2dとして扱うことによってOpenCVなどの画像関連のライブラリや機能を活用することができます。\n",
    "def create_image(df, H):\n",
    "    X = []\n",
    "    for path in df.file_path:\n",
    "        arr = pd.read_csv('/kaggle/input/data-science-spring-osaka-2021' + path, index_col=0).values.reshape(1,-1,20)\n",
    "        arr = cv2.resize(arr.astype(float), (H, 1))\n",
    "        arr = arr.reshape(-1, H, 1, 20)\n",
    "        X.append(arr)\n",
    "    X = np.concatenate(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換を実行します。\n",
    "X_train = create_image(df_train, 512)\n",
    "X_test = create_image(df_test, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今回はData Augmentationだけのご紹介ですが、一応ターゲットも変換しておきます。\n",
    "y_train = df_train.action_seq.values\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(le.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのshapeを確認しておきましょう。\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# さて、データに種々の変換操作を施した上でランダムにミニバッチを吐き出してくれるGeneratorを定義しておきます。\n",
    "# Credit: https://github.com/yu4u/mixup-generator\n",
    "class EskinGenerator(Sequence):\n",
    "        'Generates data for Keras'\n",
    "        def __init__(self, X_train, y_train, batch_size=32, shuffle=True, alpha=.2, datagen=None):\n",
    "            'Initialization'\n",
    "            self.batch_size = batch_size\n",
    "            self.X_train = X_train\n",
    "            self.y_train = y_train\n",
    "            self.shuffle = shuffle\n",
    "            self.on_epoch_end()\n",
    "            self.alpha= alpha\n",
    "            self.datagen=datagen\n",
    "    \n",
    "        def __len__(self):\n",
    "            'Denotes the number of batches per epoch'\n",
    "            return int(np.floor(len(self.X_train) / self.batch_size))\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "            'Generate one batch of data'\n",
    "            # Generate indexes of the batch\n",
    "            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            # Generate data\n",
    "            X, y = self.__data_generation(indexes)\n",
    "    \n",
    "            return X, y\n",
    "    \n",
    "        def on_epoch_end(self):\n",
    "            'Updates indexes after each epoch'\n",
    "            self.indexes = np.arange(len(self.X_train))\n",
    "            if self.shuffle == True:\n",
    "                np.random.shuffle(self.indexes)\n",
    "        \n",
    "        def __data_generation(self, batch_ids):\n",
    "            if self.alpha>0:\n",
    "                _, h, w, c = self.X_train.shape\n",
    "                l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "                X_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "                y_l = l.reshape(self.batch_size, 1)\n",
    "\n",
    "                X1 = self.X_train[batch_ids]\n",
    "                X2 = self.X_train[np.flip(batch_ids)] #replaced this with flip\n",
    "                X = X1 * X_l + X2 * (1 - X_l)\n",
    "                y1 = self.y_train[batch_ids]\n",
    "                y2 = self.y_train[np.flip(batch_ids)]\n",
    "                y = y1 * y_l + y2 * (1 - y_l) \n",
    "            else:\n",
    "                X = self.X_train[batch_ids]\n",
    "                y = self.y_train[batch_ids]\n",
    "        \n",
    "            if self.datagen:\n",
    "                for i in range(self.batch_size):\n",
    "                    X[i] = self.datagen.random_transform(X[i])\n",
    "                    X[i] = self.datagen.standardize(X[i])\n",
    "        \n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c575656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EskinGeneratorに今回のデータをセットします。\n",
    "# ここで、タイムオフセットはそのタイミングがarbiterary decisionであり、本質的にターゲットの値を変えない（パンチを打つタイミングが少々ずれても、同じコンビネーションという事実を変えない）ことから、height_shiftを入れてみます。\n",
    "# 他にも色々考えられるでしょう。\n",
    "datagen = image.ImageDataGenerator(\n",
    "    height_shift_range=0.1,  \n",
    ")\n",
    "\n",
    "training_generator = EskinGenerator(X_train, y_train, alpha=0, batch_size=1, datagen=datagen, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先頭データの右肘部のセンサー値について、augmentationの結果として出力がどのようになるか見てみましょう。\n",
    "# よくみると、ランダムな時間方向のシフトが適用されているのがわかりますね。\n",
    "col = 'ELBOW_R'\n",
    "col_ix = np.where(df_sensor.columns=='ELBOW_R')[0][0]-1\n",
    "\n",
    "plt.figure(figsize=[30,10])\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    X, y = training_generator.__getitem__(0)\n",
    "    plt.title('output %d'%i)\n",
    "    plt.plot(X[0,:,:,col_ix], label=col)\n",
    "    plt.xlabel('relative time position')\n",
    "    plt.ylabel('sensor_output')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3c273",
   "metadata": {},
   "source": [
    "# それでは引き続きデータとコンペをお楽しみください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd714ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
