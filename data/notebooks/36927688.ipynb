{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4478c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16906786",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e42e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/kaggle/input/intel-image-classification'\n",
    "\n",
    "files_name =os.listdir(data_dir)\n",
    "class_name =os.listdir(os.path.join(data_dir,files_name[0],files_name[0]))\n",
    "class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116eb99",
   "metadata": {},
   "source": [
    "**load training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join(data_dir,files_name[0],files_name[0])\n",
    "data=tf.keras.utils.image_dataset_from_directory(train_dir,image_size=(100, 100),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc6bf8",
   "metadata": {},
   "source": [
    "**show your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f19bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, aix =plt.subplots(ncols=5,figsize=(20,20))\n",
    "for ind,img in enumerate(batch[0][:5]):\n",
    "    aix[ind].imshow(img.astype(int))\n",
    "    aix[ind].title.set_text(batch[1][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65565479",
   "metadata": {},
   "source": [
    "**load test and predict dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=os.path.join(data_dir,files_name[2],files_name[2])\n",
    "test_data=tf.keras.utils.image_dataset_from_directory(test_dir,image_size=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fadd1f",
   "metadata": {},
   "source": [
    "**split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(len(data)*.8)\n",
    "val_size =int(len(data)*.2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9294ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.take(train_size)\n",
    "val_data=data.skip(train_size).take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c33b33",
   "metadata": {},
   "source": [
    "**scale data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =train_data.map(lambda x,y:(x/255,y) )\n",
    "val_data=val_data.map(lambda x,y:(x/255,y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb595c3a",
   "metadata": {},
   "source": [
    "**Build a deep learing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial learning rate\n",
    "#can using this in training \n",
    "initial_lr = 0.01\n",
    "\n",
    "# Define the learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    lr = initial_lr * (0.1 ** (epoch // 10))\n",
    "    return lr\n",
    "\n",
    "# Create the LearningRateScheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Define the optimizer with the initial learning rate and decay\n",
    "optimizer = SGD(lr=initial_lr, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc734c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the convolutional layers\n",
    "#Here's an implementation of the AlexNet architecture\n",
    "\n",
    "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu',kernel_regularizer=regularizers.l2(0.01), padding='valid', input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (5, 5), strides=(1, 1), activation='relu',kernel_regularizer=regularizers.l2(0.01), padding='same'))\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(124, (3, 3), strides=(1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.01),padding='same'))\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "#this model accuracy is 83%\n",
    "#another architecture to  this a problem \n",
    "\n",
    "model.add(Conv2D(100,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01),input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(80,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(50,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(40,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e80c0d",
   "metadata": {},
   "source": [
    "**now to compile the model , using adam optimizer , & sparse categorical crossentropy loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7fd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(train_data,epochs=20,validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(hist.history['loss'],label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "fig.suptitle('loss',fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure()\n",
    "plt.plot(hist.history['accuracy'],label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "fig.suptitle('accuracy',fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36eb2a",
   "metadata": {},
   "source": [
    "**increasing number of epochs number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549988f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(train_data,epochs=30,validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efcab2",
   "metadata": {},
   "source": [
    "**that is enough so overfitting problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7839ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "for batch in test_data.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    y_one_hot = to_categorical(y, num_classes=6)\n",
    "    pre.update_state(y_one_hot, yhat)\n",
    "    re.update_state(y_one_hot, yhat)\n",
    "    acc.update_state(y_one_hot, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision= {pre.result().numpy()}, Recall= {re.result().numpy()}, Accuracy= {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83041c93",
   "metadata": {},
   "source": [
    "**nice Accuracy 81%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6062bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11129faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
