{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a46c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas_bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# import tensorflow.keras.applications.ResNet101 as resnet101\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import pandas_bokeh\n",
    "# from bokeh.models.widgets import DataTable, TableColumn\n",
    "# from bokeh.models import ColumnDataSource\n",
    "\n",
    "from plotly.offline import iplot\n",
    "import plotly as py\n",
    "import plotly.tools as tls\n",
    "import cufflinks as cf\n",
    "\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "cf.go_offline()\n",
    "cf.set_config_file(theme = 'solar')\n",
    "\n",
    "# pd.set_option('plotting.backend', 'pandas_bokeh')\n",
    "# pandas_bokeh.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 512\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv',na_values=['unknown'])\n",
    "test = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\n",
    "submission = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9275c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f30b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../input/siim-isic-melanoma-classification/jpeg/train/'\n",
    "img = []\n",
    "labels = []\n",
    "jpg = '.jpg'\n",
    "\n",
    "for i in train['image_name']:\n",
    "    img.append(os.path.join(DIR,i)+jpg)\n",
    "    \n",
    "for i in train['target']:\n",
    "    labels.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90982ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = train_test_split(img,labels,test_size = 0.2,random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c19a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                         rescale=1.255,\n",
    "                                        rotation_range=40,\n",
    "                                         horizontal_flip=True,\n",
    "                                         vertical_flip= True,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        \n",
    ")\n",
    "\n",
    "val_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                            rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = pd.DataFrame(x_train,columns=['image'])\n",
    "train_labels = pd.DataFrame(y_train,columns=['target'])\n",
    "train_data = pd.concat([train_img,train_labels],axis = 1)\n",
    "\n",
    "val_img = pd.DataFrame(x_val,columns=['image'])\n",
    "val_labels = pd.DataFrame(y_val,columns=['target'])\n",
    "val_data = pd.concat([val_img,val_labels],axis = 1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36873356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen = train_data_generator.flow_from_dataframe(train_data,\n",
    "    x_col='image',\n",
    "    y_col='target',\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='raw')\n",
    "\n",
    "val_img_gen = val_data_generator.flow_from_dataframe(val_data,\n",
    "                                                    x_col = 'image',\n",
    "                                                    y_col = 'target',\n",
    "                                                    target_size= (IMG_SIZE,IMG_SIZE),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='raw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ded3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # , because of class imbalance it's better to use focal loss rather than normal binary_crossentropy.You can read more about it here\n",
    "\n",
    "# def focal_loss(alpha=0.25,gamma=2.0):\n",
    "#     def focal_crossentropy(y_true, y_pred):\n",
    "#         bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "#         y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n",
    "#         p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n",
    "        \n",
    "#         alpha_factor = 1\n",
    "#         modulating_factor = 1\n",
    "\n",
    "#         alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n",
    "#         modulating_factor = K.pow((1-p_t), gamma)\n",
    "\n",
    "#         # compute the final loss and return\n",
    "#         return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n",
    "#     return focal_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "def focal_loss(alpha=0.25,gamma=2.0):\n",
    "    def focal_crossentropy(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n",
    "        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n",
    "        \n",
    "        alpha_factor = 1\n",
    "        modulating_factor = 1\n",
    "\n",
    "        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n",
    "        modulating_factor = K.pow((1-p_t), gamma)\n",
    "\n",
    "        # compute the final loss and return\n",
    "        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n",
    "    return focal_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(tf.keras.applications.ResNet101(weights='imagenet',\n",
    "                                        include_top=False,\n",
    "                                        input_shape=(IMG_SIZE,IMG_SIZE,3)\n",
    "                                       ))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(1024,activation= 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dense(70000,activation= 'relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dense(20000,activation= 'relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dense(1000,activation= 'relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(256,activation= 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(1,activation='softmax'))\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.compile(loss=focal_loss(),metrics=[tf.keras.metrics.AUC()],optimizer='adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.callbacks import ModelCheckpoint\n",
    "filepath = \"../working/saved_models-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,monitor = 'val_loss',verbose = 1,save_best_only = True,mode = 'max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c199a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_data.target),\n",
    "                                                 train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86605e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight ={\n",
    "    0:0.50893029,\n",
    "    1:28.49462366\n",
    "}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1babae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "History = model.fit_generator(train_img_gen,\n",
    "                             steps_per_epoch=train_data.shape[0]//BATCH_SIZE,\n",
    "                             epochs=EPOCH,\n",
    "                             validation_data=val_img_gen,\n",
    "                             validation_steps=val_data.shape[0]//BATCH_SIZE,\n",
    "                             class_weight=class_weight,\n",
    "                            callbacks=callbacks_list\n",
    "                             )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf18d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
