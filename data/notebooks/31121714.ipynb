{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45eebf48",
   "metadata": {},
   "source": [
    "# NESP: train data wildtypes AlphaFold predictions exploration\n",
    "Here I show how to open and use the files in [this](https://www.kaggle.com/datasets/shlomoron/train-wildtypes-af) data set. The data set contains 1186 AlphaFold predictions for 73 out of 78 wildtypes in train data (several tens of predictions for each wildtype). The predictions are for exact matches. The data set is based on the work of @roberthatch (see [here](https://www.kaggle.com/code/roberthatch/novo-train-data-contains-wildtype-groups/notebook)) and @vslaykovsky (see [here](https://www.kaggle.com/code/vslaykovsky/nesp-alphafold-v2-exact-match-data) and [here](https://www.kaggle.com/code/vslaykovsky/nesp-alphafold2-all-close-matches))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "!pip install biopandas -q\n",
    "from biopandas.pdb import PandasPdb\n",
    "from biopandas.mmcif import PandasMmcif\n",
    "!pip install py3Dmol -q\n",
    "import py3Dmol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38afcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_fold_df = pd.read_csv(\"../input/train-wildtypes-af/alpha_fold_df.csv\")\n",
    "alpha_fold_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0c83d",
   "metadata": {},
   "source": [
    "## We will explore the matches to the first wildtype. There are 84 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wildtypes = list(alpha_fold_df[\"af2_sequence\"].drop_duplicates())\n",
    "wildtype = wildtypes[0]\n",
    "print(\"wildtype:\")\n",
    "print(wildtype)\n",
    "AF_keys = alpha_fold_df.loc[alpha_fold_df[\"af2_sequence\"] == wildtype][\"af2id\"]\n",
    "print(\"Number of matches to wildtype: \" + str(len(AF_keys)))\n",
    "print(\"AF key: \" + AF_keys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefad623",
   "metadata": {},
   "source": [
    "## Confidence file exploration i.e. pLDDT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67541a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidense_df = pd.read_json(\"../input/train-wildtypes-af/confidence/\" + AF_keys[0][5:] + \"-confidence_v3.json\")\n",
    "confidense_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16543c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(confidense_df[\"confidenceScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidense_df_list = [pd.read_json(\"../input/train-wildtypes-af/confidence/\" + AF_keys.iloc[i][5:] + \"-confidence_v3.json\") for i in range(len(AF_keys))]\n",
    "for confidense_df in confidense_df_list:\n",
    "    plt.plot(confidense_df[\"confidenceScore\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca770d90",
   "metadata": {},
   "source": [
    "### We note that the length of all the scores is the same, so probably all the matches are exact matches. We will make sure that the residues are the same later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412cb98b",
   "metadata": {},
   "source": [
    "### We will look at the minimum and maximum pLDDT score across all matches at each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fbc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = list(confidense_df_list[0][\"confidenceScore\"])\n",
    "max_score = list(confidense_df_list[0][\"confidenceScore\"])\n",
    "\n",
    "for confidense_df in confidense_df_list:\n",
    "    for point_idx in range(len(confidense_df)):\n",
    "        if confidense_df.iloc[point_idx][\"confidenceScore\"] < min_score[point_idx]:\n",
    "            min_score[point_idx] = confidense_df.iloc[point_idx][\"confidenceScore\"]\n",
    "        if confidense_df.iloc[point_idx][\"confidenceScore\"] > max_score[point_idx]:\n",
    "            max_score[point_idx] = confidense_df.iloc[point_idx][\"confidenceScore\"]\n",
    "\n",
    "plt.plot(min_score)\n",
    "plt.plot(max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbe9d9",
   "metadata": {},
   "source": [
    "### So we can see quite a bit of variation...This raise the question, how to deside which prediction is the best one to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbfbb6",
   "metadata": {},
   "source": [
    "## Now we will explore the cif file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcea036",
   "metadata": {},
   "source": [
    "Snippets for reading and displaying are thanks to @cdeotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200dcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cif_path_list = [\"../input/train-wildtypes-af/cif/\" + AF_keys.iloc[i][5:] + \"-model_v3.cif\" for i in range(len(AF_keys))]\n",
    "atom_df_list = []\n",
    "for cif_path in cif_path_list:\n",
    "    atom_df = PandasMmcif().read_mmcif(cif_path)\n",
    "    atom_df = atom_df.df['ATOM']\n",
    "    atom_df_list.append(atom_df)\n",
    "atom_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c69592",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cif_path_list[0]) as ifile:\n",
    "    protein = \"\".join([x for x in ifile])\n",
    "view = py3Dmol.view(width=800, height=600) \n",
    "view.addModelsAsFrames(protein)\n",
    "style = {'cartoon': {'color': 'spectrum'},'stick':{}}\n",
    "view.setStyle({'model': -1},style) \n",
    "view.zoom(0.12)\n",
    "view.rotate(235, {'x':0,'y':1,'z':1})\n",
    "#view.spin({'x':-0.2,'y':0.5,'z':1},1)\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2943a9",
   "metadata": {},
   "source": [
    "### And now we will just make sure that the residues are the same for all matches for the explored wildtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wildtype_set = set()\n",
    "for cif_df in atom_df_list:\n",
    "    wildtype_set.add(\"\".join(list(cif_df[\"label_comp_id\"])))\n",
    "print(len(wildtype_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1691a8",
   "metadata": {},
   "source": [
    "### So indeed, they are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b05a21",
   "metadata": {},
   "source": [
    "## Lastly, we will get the mutations in the train data for this wildtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152585e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wildtype_groups = pd.read_csv(\"../input/train-wildtypes-af/train_wildtype_groups.csv\")\n",
    "print(len(train_wildtype_groups))\n",
    "train_wildtype_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = train_wildtype_groups.loc[train_wildtype_groups[\"wildtype\"] == wildtype]\n",
    "print(len(mutations))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
