{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.metrics import roc_curve,auc,classification_report,precision_score,recall_score,f1_score,plot_confusion_matrix,confusion_matrix,make_scorer\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer,LabelEncoder,OneHotEncoder,StandardScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.utils import shuffle,resample\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "import  numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id'],axis=1)\n",
    "\n",
    "df=df.drop([df[df.gender=='Other'].index][0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stroke.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77214945",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b366e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=df[df.bmi.isna()==True]\n",
    "missing_no_con=missing.drop(['age','bmi','avg_glucose_level'],axis=1)\n",
    "\n",
    "\n",
    "no_missing=df[df.bmi.isna()==False]\n",
    "no_missing_no_con=no_missing.drop(['age','bmi','avg_glucose_level'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9db174",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=[]\n",
    "\n",
    "groups={}\n",
    "\n",
    "for f in missing_no_con.columns:\n",
    "  comb.append(tuple(np.unique(df[f])))\n",
    "\n",
    "comb=list(itertools.product(comb[0],comb[1],comb[2],comb[3],comb[4],comb[5],comb[6],comb[7]))\n",
    "\n",
    "\n",
    "for idx,c in enumerate(comb):\n",
    "  get=missing_no_con[(missing_no_con[missing_no_con.columns[0]]==c[0])&\n",
    "               (missing_no_con[missing_no_con.columns[1]]==c[1])&\n",
    "               (missing_no_con[missing_no_con.columns[2]]==c[2])&\n",
    "               (missing_no_con[missing_no_con.columns[3]]==c[3])&\n",
    "               (missing_no_con[missing_no_con.columns[4]]==c[4])&\n",
    "               (missing_no_con[missing_no_con.columns[5]]==c[5])&\n",
    "               (missing_no_con[missing_no_con.columns[6]]==c[6])&\n",
    "               (missing_no_con[missing_no_con.columns[7]]==c[7])]\n",
    "  \n",
    "  if len(get.index)!=0:\n",
    "    groups[c]=list(get.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "std=StandardScaler()\n",
    "nn=NearestNeighbors(n_neighbors=1)\n",
    "for k,v in groups.items():\n",
    "  get=no_missing_no_con[(no_missing_no_con[no_missing_no_con.columns[0]]==k[0])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[1]]==k[1])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[2]]==k[2])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[3]]==k[3])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[4]]==k[4])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[5]]==k[5])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[6]]==k[6])&\n",
    "               (no_missing_no_con[no_missing_no_con.columns[7]]==k[7])]\n",
    "  index=list(get.index)  \n",
    "  if len(index)!=0: \n",
    "    neighbors=df.loc[index][['age','avg_glucose_level']]\n",
    "    neighbors=pd.DataFrame(std.fit_transform(neighbors),columns=neighbors.columns,index=neighbors.index)\n",
    "    nn.fit(neighbors)\n",
    "    for idx in v:\n",
    "      target=missing.loc[[idx]]\n",
    "      target=target[['age','avg_glucose_level']] \n",
    "      nbrs_idx=nn.kneighbors(std.fit_transform(target),1,return_distance=False)\n",
    "      nbrs_idx=neighbors.index[nbrs_idx[0][0]]\n",
    "      df.at[idx,'bmi']=np.array(df.bmi.loc[[nbrs_idx]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbceecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi']=df.bmi.fillna(df.bmi.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648dd02",
   "metadata": {},
   "source": [
    "### Visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d227fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=3,figsize=(40,10))\n",
    "\n",
    "for i,f in enumerate(df[['age','avg_glucose_level','bmi']].columns):\n",
    "  sns.histplot(data=df,x=f,hue='stroke',ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=3,figsize=(40,10))\n",
    "df_=deepcopy(df)\n",
    "\n",
    "df_=np.log(df_[['age','avg_glucose_level','bmi']])\n",
    "\n",
    "df_['stroke']=df.stroke\n",
    "for i,f in enumerate(df[['age','avg_glucose_level','bmi']].columns):\n",
    "  sns.histplot(data=df_,x=f,hue='stroke',ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7110998",
   "metadata": {},
   "source": [
    "* BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ff433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(ncols=len(df.columns)-4,figsize=(40,10))\n",
    "for i,f in enumerate(df.drop(['stroke','bmi','age','avg_glucose_level'],axis=1).columns):\n",
    "  sns.boxplot(data=df,x=f,y='bmi',hue='stroke',ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d094f",
   "metadata": {},
   "source": [
    "* glucose level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a57940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=len(df.columns)-4,figsize=(40,10))\n",
    "for i,f in enumerate(df.drop(['stroke','bmi','age','avg_glucose_level'],axis=1).columns):\n",
    "  sns.boxplot(data=df,x=f,y='avg_glucose_level',hue='stroke',ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba9cab",
   "metadata": {},
   "source": [
    "### Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a52f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency,f,ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a30ac",
   "metadata": {},
   "source": [
    "* Chi-squared independence test\n",
    "  * Test whether categorical variable indepent to whether stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals=[]\n",
    "for f in df.drop(['age','bmi','avg_glucose_level','stroke'],axis=1).columns:\n",
    "  obs=pd.crosstab(df[f],df.stroke)\n",
    "  chi2, p, dof, ex=chi2_contingency(obs)\n",
    "  if p<=0.05:\n",
    "    print(f'({f} and Stroke)--- Reject--- independence Assumption , p-val :{p}')\n",
    "  else:\n",
    "    print(f'({f} and Stroke)---Accept--- independence Assumption , p-val :{p}')\n",
    "\n",
    "  p_vals.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(df.drop(['age','bmi','avg_glucose_level','stroke'],axis=1).columns,-np.log(p_vals))\n",
    "plt.title('-log(p value)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c3aca",
   "metadata": {},
   "source": [
    "* two sample t-test\n",
    "  * Test whether stroke guy's bmi or glucose level higher than the no stroke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=deepcopy(df)\n",
    "\n",
    "df_=np.log(df_[['age','avg_glucose_level','bmi']])\n",
    "\n",
    "df_['stroke']=df.stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6cfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg glucose level\n",
    "\n",
    "\n",
    "stroke=df_[df_.stroke==1]['avg_glucose_level']\n",
    "\n",
    "no_stroke=df_[df_.stroke==0]['avg_glucose_level']\n",
    "\n",
    "\n",
    "\n",
    "F=np.var(stroke)/np.var(no_stroke)\n",
    "\n",
    "df1=len(stroke)\n",
    "df2=len(no_stroke)\n",
    "\n",
    "\n",
    "alpha = 0.05 \n",
    "p_value = scipy.stats.f.sf(F, df1, df2)\n",
    "print('p:',p_value)\n",
    "if p_value > alpha:\n",
    "\n",
    "  print('accept VarX=VarY')\n",
    "  t,p=ttest_ind(stroke,no_stroke,equal_var=True)\n",
    "else:\n",
    "  print('reject VarX=VarY')\n",
    "  t,p=ttest_ind(stroke,no_stroke,equal_var=False)\n",
    "\n",
    "\n",
    "if p/2<alpha:\n",
    "    print(f't-test p :{p/2} , Reject H0')\n",
    "else:\n",
    "    print(f't-test p :{p/2} , Accept H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bmi\n",
    "\n",
    "\n",
    "stroke=df_[df_.stroke==1]['bmi']\n",
    "\n",
    "no_stroke=df_[df_.stroke==0]['bmi']\n",
    "\n",
    "\n",
    "F=np.var(stroke)/np.var(no_stroke)\n",
    "\n",
    "df1=len(stroke)\n",
    "df2=len(no_stroke)\n",
    "\n",
    "\n",
    "alpha = 0.05 \n",
    "p_value = scipy.stats.f.sf(F, df1, df2)\n",
    "print('p:',p_value)\n",
    "if p_value > alpha:\n",
    "\n",
    "  print('accept VarX=VarY')\n",
    "  t,p=ttest_ind(stroke,no_stroke,equal_var=True)\n",
    "else:\n",
    "  print('reject VarX=VarY')\n",
    "  t,p=ttest_ind(stroke,no_stroke,equal_var=False)\n",
    "    \n",
    "\n",
    "if p/2<alpha:\n",
    "    print(f't-test p :{p/2} , Reject H0')\n",
    "else:\n",
    "    print(f't-test p :{p/2} , Accept H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756cb39",
   "metadata": {},
   "source": [
    "### Augment Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2536b1",
   "metadata": {},
   "source": [
    "* Encode Categorical \n",
    " * If more than 2 categorical then use one-hot encoding\n",
    " * else use label encoding\n",
    "\n",
    "* Continuous\n",
    " * Polynomial Feature with only interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentor:\n",
    "  def __init__(self,degree=2,\n",
    "        interaction_only=False,\n",
    "        use_ohe=True,\n",
    "        assign_drop=None):\n",
    "    self.Label_Enc={}\n",
    "    self.OneHot_Enc={}\n",
    "    self.Poly=None\n",
    "    self.degree=degree\n",
    "    self.interaction_only=interaction_only\n",
    "    self.use_ohe=use_ohe\n",
    "    self.assign_drop=assign_drop\n",
    "    self.continuous=['age','avg_glucose_level','bmi']\n",
    "\n",
    "    try:\n",
    "      for x in self.continuous:\n",
    "        if x in self.assign_drop:\n",
    "          self.continuous.remove(x)\n",
    "    except:\n",
    "      None\n",
    "\n",
    "  def __call__(self,X,y=None):\n",
    "    X_=deepcopy(X) \n",
    "\n",
    "    if self.use_ohe:\n",
    "      X_=self.one_hot_encoder(X_)\n",
    "\n",
    "    #call by address, no return \n",
    "    self.label_encoder(X_)\n",
    "    if self.degree>1:\n",
    "      X_=self.polynomial(X_)\n",
    "\n",
    "    if self.assign_drop!=None:\n",
    "      X_=X_.drop(self.assign_drop,axis=1)\n",
    "    return X_\n",
    "\n",
    "  def one_hot_encoder(self,X):\n",
    "    for f in X.columns:\n",
    "      if f in ['work_type','smoking_status']:\n",
    "        try:\n",
    "          col_names=self.OneHot_Enc[f].get_feature_names()\n",
    "        except:\n",
    "          self.OneHot_Enc[f]=OneHotEncoder()\n",
    "          self.OneHot_Enc[f].fit(X[f].values.reshape(-1,1))\n",
    "          col_names=self.OneHot_Enc[f].get_feature_names()\n",
    "        X[col_names]=self.OneHot_Enc[f].transform(X[f].values.reshape(-1,1)).toarray()\n",
    "\n",
    "    try:\n",
    "      X=X.drop(['work_type','smoking_status'],axis=1)\n",
    "    except:\n",
    "      pass\n",
    "    return X\n",
    "    \n",
    "\n",
    "  def label_encoder(self,X):\n",
    "    '''\n",
    "    input : Dataframe\n",
    "    '''\n",
    "    for f in X.columns:\n",
    "      if f not in self.continuous:\n",
    "        try:\n",
    "          self.Label_Enc[f].classes_\n",
    "          X[f]=self.Label_Enc[f].transform(X[f])\n",
    "        except:\n",
    "          self.Label_Enc[f]=LabelEncoder()\n",
    "          X[f]=self.Label_Enc[f].fit_transform(X[f])\n",
    "\n",
    "\n",
    "  def polynomial(self,X):\n",
    "    if self.Poly==None:\n",
    "      self.Poly=PolynomialFeatures(degree=self.degree,interaction_only=self.interaction_only,include_bias=False)\n",
    "      self.Poly.fit(X[self.continuous])\n",
    "    col_names=self.Poly.get_feature_names()\n",
    "    X[col_names]=self.Poly.transform(X[self.continuous])\n",
    "    try:\n",
    "      for x in self.continuous:\n",
    "        X=X.drop([x],axis=1)\n",
    "    except:\n",
    "      pass\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381caff8",
   "metadata": {},
   "source": [
    "* Custom Scorer\n",
    "\n",
    "* Since data is imbalance , we need to measure by percentage rather than sample number\n",
    "\n",
    "  * How much percentage Negative I predict correstly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61355998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_f1(y_true,y_pred):\n",
    "    C=confusion_matrix(y_true,y_pred).astype('float32')\n",
    "    C[0,:]=C[0,:]/C[0,:].sum()\n",
    "    C[1,:]=C[1,:]/C[1,:].sum()\n",
    "    TP=C[1][1]\n",
    "    FP=C[0][1]\n",
    "    TN=C[0][0]\n",
    "    FN=C[1][0]\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    f1=2*precision*recall/(precision+recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2305e9e",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04661c3d",
   "metadata": {},
   "source": [
    "* 70% Training , 30% Testing\n",
    "\n",
    "* Don't use resampling before because the evaluation has no interpretation \n",
    "  * 95% precision recall is fake because model has seen these \"copied\" data in training set \n",
    "  \n",
    "  \n",
    " * Regularzation\n",
    " \n",
    "   * elastic net for model selection purpose\n",
    "     * L1+L2 term : since I use polynomial feature and expand categorical by one hot encoding , feature number is large , so I use L1 term for feature selection and L2 term for feature weighting\n",
    "     \n",
    "   \n",
    "   * class weight for imbalance data \n",
    "   \n",
    "   \n",
    "* Tuning \n",
    "\n",
    "  * $\\alpha$ : streghth of regularzation term\n",
    "  \n",
    "  * l1-ratio $\\lambda$ : $\\frac{(1-\\lambda)}{2}*L2+\\frac{\\lambda}{2}*L1$ \n",
    "    * If $\\lambda$=0 , only L2 term\n",
    "    \n",
    "    * If $\\lambda$=1 , only L1 term\n",
    "    \n",
    "  * class weight\n",
    "  \n",
    "  * 30-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34aa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.drop(['stroke'],axis=1),df.stroke,test_size=0.3,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b075d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=make_pipeline(FunctionTransformer(Augmentor(degree=3,interaction_only=True)),\n",
    "                 StandardScaler(),SGDClassifier(loss='log',average=True,\n",
    "                 max_iter=200,\n",
    "                 early_stopping=True,random_state=0))\n",
    "\n",
    "\n",
    "params={'sgdclassifier__alpha':[1e-4,1e-3,0.01],\n",
    "    'sgdclassifier__class_weight':[{0:1,1:10},{0:1,1:15}],\n",
    "     'sgdclassifier__penalty':['elasticnet'],\n",
    "      'sgdclassifier__l1_ratio':[0,0.15,0.5,1]}\n",
    "\n",
    "scorer=make_scorer(scaled_f1)\n",
    "\n",
    "clf=GridSearchCV(lr,params,scoring=scorer,n_jobs=-1,cv=30,verbose=0)\n",
    "\n",
    "clf=clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dde450",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b4d05",
   "metadata": {},
   "source": [
    "* Training Set score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7cfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6327fc5",
   "metadata": {},
   "source": [
    "* Testing Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc3f41",
   "metadata": {},
   "source": [
    "* Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,X_test,y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e4bed",
   "metadata": {},
   "source": [
    "* score\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa94ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=confusion_matrix(y_test,y_pred).astype('float32')\n",
    "\n",
    "C[0,:]=C[0,:]/C[0,:].sum()\n",
    "C[1,:]=C[1,:]/C[1,:].sum()\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53384ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=C[1][1]\n",
    "FP=C[0][1]\n",
    "\n",
    "TN=C[0][0]\n",
    "\n",
    "FN=C[1][0]\n",
    "\n",
    "precision=TP/(TP+FP)\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "\n",
    "print('test precision:',precision)\n",
    "print('test recall',recall)\n",
    "print('test f1-score :' ,f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1c445",
   "metadata": {},
   "source": [
    "* Model interpretation (fix other variable)\n",
    "\n",
    "* For Logistic Regression\n",
    "\n",
    "  * if age +1 , log odds ratio +13\n",
    "  \n",
    "  * if childen +1 , log odss ratio -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.barh(clf.best_estimator_.steps[0][1].transform(df.drop(['stroke'],axis=1)).columns,\n",
    "         clf.best_estimator_.steps[2][1].coef_[0])\n",
    "plt.title('Regression Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
