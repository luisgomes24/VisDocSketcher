{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5e2875",
   "metadata": {},
   "source": [
    "Reading classics [Deep Learning Models](https://github.com/rasbt/deeplearning-models)\n",
    "## Basic Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd,pylab as pl\n",
    "import h5py,torch\n",
    "from torchvision.datasets import MNIST as tmnist\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader as tdl\n",
    "from torch.utils.data import Dataset as tds\n",
    "import torch.nn.functional as tnnf\n",
    "from sklearn.datasets import make_classification\n",
    "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                 else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0aabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial data\n",
    "N=500; n=int(.2*N)\n",
    "X,y=make_classification(n_samples=N,n_features=2,\n",
    "                        n_redundant=0,n_informative=2)\n",
    "mu,std=np.mean(X,axis=0),np.std(X,axis=0)\n",
    "X=(X-mu)/std\n",
    "X,y=X.astype('float32'),y.astype('int32')\n",
    "pl.figure(figsize=(11,3)); pl.grid()\n",
    "pl.scatter(X[:,0],X[:,1],marker='o',\n",
    "           s=10,c=y,cmap='cool');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20facd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling & splitting\n",
    "shuffle_ids=np.arange(N)\n",
    "np.random.RandomState(23).shuffle(shuffle_ids)\n",
    "X,y=X[shuffle_ids],y[shuffle_ids]\n",
    "X_test,X_train=X[:n],X[n:]\n",
    "y_test,y_train=y[:n],y[n:]\n",
    "pl.figure(figsize=(11,3)); pl.grid()\n",
    "pl.scatter(X_test[:,0],X_test[:,1],marker='o',\n",
    "           s=10,c=y_test,cmap='cool');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d67926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self,num_features):\n",
    "        self.num_features=num_features\n",
    "        self.weights=torch.zeros(num_features,1, \n",
    "                                 dtype=torch.float32,device=dev)\n",
    "        self.bias=torch.zeros(1,dtype=torch.float32,device=dev)\n",
    "    def forward(self,x):\n",
    "        values=torch.add(torch.mm(x,self.weights),self.bias)\n",
    "        a,b=torch.ones(values.size()[0],1),torch.zeros(values.size()[0],1)\n",
    "        predictions=torch.where(values>0.,a,b).float()\n",
    "        return predictions        \n",
    "    def backward(self,x,y):  \n",
    "        predictions=self.forward(x)\n",
    "        errors=y-predictions\n",
    "        return errors        \n",
    "    def train(self,x,y,epochs):\n",
    "        for e in range(epochs):            \n",
    "            for i in range(y.size()[0]):\n",
    "                errors=self.backward(x[i].view(1,self.num_features),\n",
    "                                     y[i]).view(-1)\n",
    "                self.weights+=(errors*x[i]).view(self.num_features,1)\n",
    "                self.bias+=errors                \n",
    "    def acc(self,x,y):\n",
    "        predictions=self.forward(x).view(-1)\n",
    "        accuracy=torch.sum(predictions==y).float()/y.size()[0]\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ae831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Perceptron(num_features=2)\n",
    "tX_train=torch.tensor(X_train,dtype=torch.float32,\n",
    "                      device=dev)\n",
    "ty_train=torch.tensor(y_train,dtype=torch.float32,\n",
    "                      device=dev)\n",
    "model.train(tX_train,ty_train,epochs=5)\n",
    "print('Weights: %s'%model.weights)\n",
    "print('Bias: %s'%model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9778d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating\n",
    "tX_test=torch.tensor(X_test,dtype=torch.float32,\n",
    "                     device=dev)\n",
    "ty_test=torch.tensor(y_test,dtype=torch.float32,\n",
    "                     device=dev)\n",
    "acc_test=model.acc(tX_test,ty_test)\n",
    "print('Test accuracy: %.2f%%'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f24f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W,b=model.weights,model.bias\n",
    "x_min=-2; x_max=2\n",
    "y_min=((-(W[0]*x_min)-b[0])/W[1])\n",
    "y_max=((-(W[0]*x_max)-b[0])/W[1])\n",
    "fig,ax=pl.subplots(1,2,sharex=True,figsize=(11,3))\n",
    "ax[0].plot([x_min,x_max],[y_min,y_max],c='red')\n",
    "ax[1].plot([x_min,x_max],[y_min,y_max],c='red')\n",
    "ax[0].scatter(X_train[:,0],X_train[:,1],\n",
    "              c=y_train,s=10,cmap=pl.cm.cool)\n",
    "ax[1].scatter(X_test[:,0], X_test[:,1],\n",
    "              c=y_test,s=10,cmap=pl.cm.cool)\n",
    "ax[0].grid(); ax[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,num_features):\n",
    "        self.num_features=num_features\n",
    "        self.weights=torch.zeros(num_features,1, \n",
    "                                dtype=torch.float32,device=dev)\n",
    "        self.bias=torch.zeros(1,dtype=torch.float32,device=dev)\n",
    "    def forward(self,x):\n",
    "        values=torch.add(torch.mm(x,self.weights),self.bias)\n",
    "        probs=self._sigmoid(values)\n",
    "        return probs       \n",
    "    def backward(self,probs,y):  \n",
    "        errors=y-probs.view(-1)\n",
    "        return errors            \n",
    "    def predict_labels(self,x):\n",
    "        probs=self.forward(x)\n",
    "        a=torch.ones(probs.size()[0],1)\n",
    "        b=torch.zeros(probs.size()[0],1)\n",
    "        labels=torch.where(probs>=.5,a,b)\n",
    "        return labels                \n",
    "    def acc(self,x,y):\n",
    "        labels=self.predict_labels(x).float()\n",
    "        accuracy=torch.sum(labels.view(-1)==y).float()/y.size()[0]\n",
    "        return accuracy    \n",
    "    def _sigmoid(self,z):\n",
    "        return 1./(1.+torch.exp(-z))    \n",
    "    def _logit_cost(self,y,prob):\n",
    "        tmp1=torch.mm(-y.view(1,-1),torch.log(prob))\n",
    "        tmp2=torch.mm((1-y).view(1,-1),torch.log(1-prob))\n",
    "        return tmp1-tmp2\n",
    "    def train(self,x,y,epochs,learning_rate=.01):\n",
    "        for e in range(epochs):\n",
    "            probs=self.forward(x)\n",
    "            errors=self.backward(probs,y)\n",
    "            neg_grad=torch.mm(x.transpose(0,1),errors.view(-1,1))\n",
    "            self.weights+=learning_rate*neg_grad\n",
    "            self.bias+=learning_rate*torch.sum(errors)\n",
    "            print('Epoch: %03d'%(e+1),end=\"\")\n",
    "            print(' | Train accuracy: %.3f'%self.acc(x,y),end=\"\")\n",
    "            print(' | Cost: %.3f'%self._logit_cost(y,self.forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(num_features=2)\n",
    "model.train(tX_train,ty_train,epochs=10,learning_rate=.02)\n",
    "print('Weights: %s'%model.weights)\n",
    "print('Bias: %s'%model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8af42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating\n",
    "acc_test=model.acc(tX_test,ty_test)\n",
    "print('Test accuracy: %.2f%%'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "W,b=model.weights,model.bias\n",
    "x_min=-2; x_max=2\n",
    "y_min=((-(W[0]*x_min)-b[0])/W[1])\n",
    "y_max=((-(W[0]*x_max)-b[0])/W[1])\n",
    "fig,ax=pl.subplots(1,2,sharex=True,figsize=(11,3))\n",
    "ax[0].plot([x_min,x_max],[y_min,y_max],c='red')\n",
    "ax[1].plot([x_min,x_max],[y_min,y_max],c='red')\n",
    "ax[0].scatter(X_train[:,0],X_train[:,1],\n",
    "              c=y_train,s=10,cmap=pl.cm.cool)\n",
    "ax[1].scatter(X_test[:,0], X_test[:,1],\n",
    "              c=y_test,s=10,cmap=pl.cm.cool)\n",
    "ax[0].grid(); ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292ddaf",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=23; batch_size=128\n",
    "train=tmnist(root='data',train=True,download=True,\n",
    "            transform=transforms.ToTensor())\n",
    "test=tmnist(root='data',train=False, \n",
    "            transform=transforms.ToTensor())\n",
    "train_loader=tdl(dataset=train,shuffle=True, \n",
    "                 batch_size=batch_size)\n",
    "test_loader=tdl(dataset=test,shuffle=False, \n",
    "                batch_size=batch_size)\n",
    "for images,labels in train_loader:  \n",
    "    print('Image dimensions: %s'%str(images.shape))\n",
    "    print('Label dimensions: %s'%str(labels.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efe464",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=.1; epochs=15\n",
    "num_features=784; num_classes=10\n",
    "class SoftmaxRegression(torch.nn.Module):\n",
    "    def __init__(self,num_features,num_classes):\n",
    "        super(SoftmaxRegression,self).__init__()\n",
    "        self.linear=torch.nn.Linear(num_features,num_classes)        \n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()     \n",
    "    def forward(self,x):\n",
    "        logits=self.linear(x)\n",
    "        probs=tnnf.softmax(logits,dim=1)\n",
    "        return logits,probs\n",
    "model=SoftmaxRegression(num_features=num_features,\n",
    "                        num_classes=num_classes)\n",
    "model.to(dev)\n",
    "optimizer=torch.optim.SGD(model.parameters(),\n",
    "                          lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(model,data_loader,num_features):\n",
    "    correct_preds,num_examples=0,0    \n",
    "    for features,targets in data_loader:\n",
    "        features=features.view(-1,num_features).to(dev)\n",
    "        targets=targets.to(dev)\n",
    "        logits,probs=model(features)\n",
    "        _,pred_labels=torch.max(probs,1)\n",
    "        num_examples+=targets.size(0)\n",
    "        correct_preds+=(pred_labels==targets).sum()        \n",
    "    return correct_preds.float()/num_examples*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786486ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_ids,(features,targets) in enumerate(train_loader):        \n",
    "        features=features.view(-1,num_features).to(dev)\n",
    "        targets=targets.to(dev)\n",
    "        logits,probs=model(features)\n",
    "        cost=tnnf.cross_entropy(logits,targets)\n",
    "        optimizer.zero_grad(); cost.backward()\n",
    "        optimizer.step()\n",
    "        if not batch_ids%200:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1,epochs,batch_ids, \n",
    "                     len(train)//batch_size,cost))           \n",
    "    with torch.set_grad_enabled(False):\n",
    "        print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n",
    "              (epoch+1,epochs,model_acc(model,train_loader,num_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%'%(model_acc(model,test_loader,num_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ccbdb",
   "metadata": {},
   "source": [
    "## Applying to Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5302e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath='../input/flower-color-images/'\n",
    "f=h5py.File(fpath+'FlowerColorImages.h5','r')\n",
    "keys=list(f.keys()); print(keys)\n",
    "X=np.array(f[keys[0]],dtype='float32')/255\n",
    "y=np.array(f[keys[1]],dtype='int32')\n",
    "N=len(y); n=int(.2*N); batch_size=16\n",
    "shuffle_ids=np.arange(N)\n",
    "np.random.RandomState(23).shuffle(shuffle_ids)\n",
    "X,y=X[shuffle_ids],y[shuffle_ids]\n",
    "X_test,X_train=X[:n],X[n:]\n",
    "y_test,y_train=y[:n],y[n:]\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TData(tds):\n",
    "    def __init__(self,X,y):   \n",
    "        self.X=torch.tensor(X,dtype=torch.float32)\n",
    "        self.y=torch.tensor(y,dtype=torch.int32)\n",
    "    def __getitem__(self,index):\n",
    "        train_img,train_lbl=self.X[index],self.y[index]\n",
    "        return train_img,train_lbl\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "train=TData(X_train,y_train)\n",
    "test=TData(X_test,y_test)\n",
    "train_loader=tdl(dataset=train,batch_size=batch_size,shuffle=True)\n",
    "test_loader=tdl(dataset=test,batch_size=batch_size,shuffle=False)\n",
    "for images,labels in train_loader:  \n",
    "    print('Image dimensions: %s'%str(images.shape))\n",
    "    print('Label dimensions: %s'%str(labels.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=.01; epochs=25\n",
    "num_features=49152; num_classes=10\n",
    "torch.manual_seed(random_seed)\n",
    "model=SoftmaxRegression(num_features=num_features,\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "model.to(dev)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_ids,(features,targets) in enumerate(train_loader):        \n",
    "        features=features.view(-1,num_features).to(dev)\n",
    "        targets=targets.to(dev)\n",
    "        logits,probs=model(features)\n",
    "        cost=tnnf.cross_entropy(logits,targets.long())\n",
    "        optimizer.zero_grad(); cost.backward()\n",
    "        optimizer.step()\n",
    "        if not batch_ids%10:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1,epochs,batch_ids, \n",
    "                     len(train)//batch_size,cost))           \n",
    "    with torch.set_grad_enabled(False):\n",
    "        print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n",
    "              (epoch+1,epochs,model_acc(model,train_loader,num_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%'%(model_acc(model,test_loader,num_features)))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
