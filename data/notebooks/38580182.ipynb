{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d235c8",
   "metadata": {},
   "source": [
    "# <p style=\"font-family: helvetica; letter-spacing: 3px; font-size: 30px; font-weight: bold; color:#1B2631; align:left;padding: 0px\"> Feature Imputation with a Heat Flux Dataset<span class=\"emoji\">üìñü§ìüìñ</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3dfd4",
   "metadata": {},
   "source": [
    "![image.jpg](attachment:images.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0605fe",
   "metadata": {},
   "source": [
    "<p style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üó®Ô∏è</span>Context\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d11b24",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTES TO THE READERS</b><br> This is a 2023 edition of Kaggle's Playground Series where the Kaggle Community hosts a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024dff04",
   "metadata": {},
   "source": [
    "## <a id=\"1\"></a>\n",
    "<p style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üîÄ</span>Install and Import\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af886962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas_profiling as pp\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43ae3",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<div style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üìàüî≠</span>Data Overview\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82786b",
   "metadata": {},
   "source": [
    "#### As per the competition, this is a fairly light-weight dataset that is synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various models/feature engineering ideas. \n",
    "#### Also, as given in the dataset description, this is both train & test dataset generated from a deep learning model trained on the Predicting Critical Heat Flux dataset (link avaiable below). Feature distributions are close to, but not exactly the same, as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data              = pd.read_csv('/kaggle/input/playground-series-s3e15/data.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/playground-series-s3e15/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c9426",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTES TO THE READER</b><br> Use the link:- https://www.kaggle.com/datasets/saurabhshahane/predicting-heat-flux to take a look at the Prediction Critical Heat Flux Dataset from which our data has been obtained.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f1dca",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<div style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üîçüìä</span>Exploratory Data Analysis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df):\n",
    "    print(\"==================================================================\")\n",
    "    print(\"1. Dataframe Shape: \",df.shape)\n",
    "    print(\"==================================================================\")\n",
    "    print(\"2. Explore the Data: \")\n",
    "    display(HTML(df.head(5).to_html()))\n",
    "    print(\"==================================================================\")\n",
    "    print(\"3. Information on the Data: \")\n",
    "    data_info_df                      = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "    data_info_df['Duplicated_Values'] = df.duplicated().sum()\n",
    "    data_info_df['Missing_Values']    = df.isnull().sum().values \n",
    "    data_info_df['%Missing']          = df.isnull().sum().values / len(df)* 100\n",
    "    data_info_df['Unique_Values']     = df.nunique().values\n",
    "    df_desc                           = df.describe(include='all').transpose()\n",
    "    data_info_df['Count']             = df_desc['count'].values\n",
    "    data_info_df['Mean']              = df_desc['mean'].values\n",
    "    data_info_df['STD']               = df_desc['std'].values\n",
    "    data_info_df['Min']               = df_desc['min'].values\n",
    "    data_info_df['Max']               = df_desc['max'].values\n",
    "    data_info_df                      = data_info_df[['Count','Mean','STD', 'Min', 'Max','Duplicated_Values','Missing_Values',\n",
    "                                                     '%Missing','Unique_Values']]   \n",
    "    display(HTML(data_info_df.to_html()))\n",
    "    print(\"==================================================================\")\n",
    "    print(\"4. Correlation Matrix Heatmap - For Numeric Variables:\")\n",
    "    num_cols = df.select_dtypes(include = ['float64']).columns.tolist()\n",
    "    correlation_matrix = df[num_cols].corr()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
    "    plt.show()\n",
    "    print(\"==================================================================\")\n",
    "    print(\"5. Correlation with Target Variable :\")\n",
    "    target_corr = correlation_matrix['x_e_out [-]'].drop('x_e_out [-]')\n",
    "    target_corr_sorted = target_corr.sort_values(ascending=False)\n",
    "    sns.set(font_scale=0.8)\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_palette(\"PuBuGn_d\")\n",
    "    sns.heatmap(target_corr_sorted.to_frame(), cmap=\"coolwarm\", annot=True, fmt='.2f')\n",
    "    plt.show()\n",
    "    print(\"==================================================================\")\n",
    "    print(\"6. Distribution of Numerical Variables\")\n",
    "    for col in num_cols:\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of {}'.format(col))\n",
    "        plt.show()\n",
    "    print(\"==================================================================\")\n",
    "    print(\"7. Distribution of Categorical Variables\")\n",
    "    cat_cols = df.select_dtypes(include = ['object']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        value_counts = df[col].value_counts(normalize=True) * 100\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        #top_n = min(17, len(value_counts))\n",
    "        #ax.barh(value_counts.index[:top_n], value_counts.values[:top_n])\n",
    "        ax.barh(value_counts.index, value_counts.values)\n",
    "        ax.set_xlabel('Percentage Distribution')\n",
    "        ax.set_ylabel(f'{col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    print(\"==================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8d2ab",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<p style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üìùüìö</span>Analysis Summary\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fed6c2",
   "metadata": {},
   "source": [
    "1. There are 10 variables - 8 features, 1 target variable ('x_e_out [-]') & 1 primary key ('id')\n",
    "\n",
    "2. 8 variables are numeric and 2 - 'author' & 'geometry' are categorical in nature\n",
    "\n",
    "3. No duplicates in the data. \n",
    "   However, the columns in this dataset comprise of missing values which need to be imputed. Only 'id' and \n",
    "   'chf_exp[MW/m2]' do not have missing values.\n",
    "\n",
    "4. Positive correlation observed between 'D_e' & D_h' variables. \n",
    "   Negative correlation observed between 'pressure' & 'D_e'/'D_h'due to formulation reasons.\n",
    "\n",
    "##### Other Facts:\n",
    "5. Distribution of our Target Variable is primarily normal with a few outliers which can be treated.\n",
    "\n",
    "6. Distribution of Categorical Variables shows the maximum occurrence of 'Thompson' among authors & 'tube' among geometry. This information can be utilized while imputation of Cateogrical Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5108b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTES TO THE READER</b><br> Refer to this notebook for further iterations !!!</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e38429",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<p style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üß©</span>Basic Imputation Techniques\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df = df.drop([\"x_e_out [-]\"], axis=1) #Since this is our target variable\n",
    "num_cols = df.select_dtypes(include = ['float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include = ['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e06cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation for Numeric Variables\n",
    "impute_mode = SimpleImputer(strategy = 'median')\n",
    "impute_mode.fit(df[num_cols])\n",
    "df[num_cols] = impute_mode.transform(df[num_cols])\n",
    "\n",
    "#Imputation for Categorical Variables\n",
    "impute_mode = SimpleImputer(strategy = 'most_frequent')\n",
    "impute_mode.fit(df[cat_cols])\n",
    "df[cat_cols] = impute_mode.transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749e15d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE TO THE READER</b><br>Since we saw above that a specific column value in both the categorical columns has very high occurrences, therefore, we can fill the missing values using 'most frequent' imputation method.<br>Alternative:<br>However, if you think that it might make the data more biased and imbalanced towards a single column value, you can also perform KNN imputation, for which we need to normalize the input data and perform One Hot Encoding to categorical variables. Please note that this method will increase the dimensionality of our training dataset.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38945b",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<p style=\"font-family: helvetica; letter-spacing: 1px; font-size: 20px; font-weight: bold; color:#1B2631; align:left;padding: 0px;border-bottom: 1px solid #003300\"><span class=\"emoji\">üîúüöÄ</span>Suggestive Next Steps\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da323ef",
   "metadata": {},
   "source": [
    "Few added methods of Data Imputation :\n",
    "1. Mean/Median Imputation: Replace missing values with the mean or median of the available data in the respective feature/column. This method assumes that the missing values are missing at random.\n",
    "\n",
    "2. Mode Imputation: For categorical variables, replace missing values with the mode (the most frequent value) of the feature.\n",
    "\n",
    "3. Forward Fill/Backward Fill: Propagate the last known value forward or the next known value backward to fill missing values. This method is suitable for time series or sequential data.\n",
    "\n",
    "4. Interpolation: Use interpolation methods to estimate missing values based on the values of neighboring data points. Common interpolation methods include linear interpolation, polynomial interpolation, or spline interpolation.\n",
    "\n",
    "5. Model-based Imputation: Train a machine learning model on the available data and use it to predict missing values. This method can provide more accurate imputations but requires a separate training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a6ba3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <span>üîÑ</span>This is currently a WIP (work in progress) version, check out the same notebook for my further approaches!<span>üëÄ</span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa36d68",
   "metadata": {},
   "source": [
    "<p style=\"font-family:helvetica;font-size: 18px;letter-spacing:1px;color:#82E0AA; align:center;padding: 0px\">\n",
    "<span class=\"emoji\">üòä</span>Thank you so much for taking the time to check out my notebook on Kaggle! <br> <span class=\"emoji\">üöÄ</span>Your support means a lot to me. If you found it helpful, please consider giving it a thumbs up or leaving a comment. <br><span class=\"emoji\">üíå</span>Your encouragement and feedback are greatly appreciated. Thank you again!\n",
    "</p>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
