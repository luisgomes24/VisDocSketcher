{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf778d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This librarys is to work with matrices\n",
    "import pandas as pd \n",
    "# This librarys is to work with vectors\n",
    "import numpy as np\n",
    "# This library is to create some graphics algorithmn\n",
    "import seaborn as sns\n",
    "# to render the graphs\n",
    "import matplotlib.pyplot as plt\n",
    "#This library use for building ANN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input\n",
    "#This library use for data preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This function makes the plot directly on browser\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0c01b",
   "metadata": {},
   "source": [
    "# Tuning packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "import kerastuner as kt\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8c71d",
   "metadata": {},
   "source": [
    "reference: https://www.kaggle.com/harunshimanto/tps-2021-eda-build-an-artificial-neural-network by Harun-Ur-Rashid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\n",
    "sample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n",
    "    train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n",
    "    test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n",
    "label = {var:index for index, var in enumerate(sorted(train['target'].unique()))}\n",
    "train['target'] = train['target'].map(label)\n",
    "\n",
    "target = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "train = train.values\n",
    "target = target.values\n",
    "target =  to_categorical(target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.1, random_state = 2, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef37926",
   "metadata": {},
   "source": [
    "optimizers list\n",
    "optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae39c5",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(hp, num_columns, num_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('hidden_units_1', 9, 99, 3), activation='relu',input_dim = num_columns,kernel_initializer='uniform'))\n",
    "    model.add(Dropout(hp.Float(\"dropout_rate_1\", 0.01, 0.5)))\n",
    "    model.add(Dense(hp.Int('hidden_units_2', 9, 99, 3), kernel_initializer = 'uniform',activation ='relu'))\n",
    "    model.add(Dropout(hp.Float(\"dropout_rate_2\", 0.01, 0.5)))\n",
    "    model.add(Dense(hp.Int('hidden_units_3', 9, 150, 3), kernel_initializer = 'uniform',activation ='relu'))\n",
    "    model.add(Dropout(hp.Float(\"dropout_rate_3\", 0.01, 0.5)))\n",
    "    model.add(Dense(num_labels, kernel_initializer='uniform', \n",
    "                    activation = hp.Choice('out_activation',['softmax','sigmoid'])))\n",
    "    model.compile(optimizer = 'sgd', \n",
    "                       loss = 'categorical_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ec6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_columns': 50, 'num_labels': 4}\n",
    "EPOCHS = 3\n",
    "MAX_TRIAL = 100\n",
    "model_fn = lambda hp: create_model1(hp, **params)\n",
    "tuner = kt.tuners.BayesianOptimization(model_fn, kt.Objective('accuracy', direction='max'), MAX_TRIAL, seed = 2020)\n",
    "tuner.search(X_train, y_train, epochs=EPOCHS, validation_data = (X_val, y_val))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tuner.get_best_models()[0]\n",
    "model1.fit(X_train, y_train, epochs = 30, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e62731",
   "metadata": {},
   "source": [
    "**Evaluating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90239c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model1.evaluate(X_train, y_train, batch_size=30)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = model1.predict(test)\n",
    "sample_submission.to_csv('BO.csv',index=False)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc096633",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(num_columns, num_labels, hidden_units_1, hidden_units_2, hidden_units_3,\n",
    "                dropout_rate_1, dropout_rate_2, dropout_rate_3, out_activation):\n",
    "    hidden_units = [hidden_units_1, hidden_units_2, hidden_units_3]\n",
    "    dropout_rates = [dropout_rate_1, dropout_rate_2, dropout_rate_3]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units[0], activation='relu',input_dim = num_columns, kernel_initializer='uniform'))\n",
    "    model.add(Dropout(dropout_rates[0]))\n",
    "    model.add(Dense(hidden_units[1], kernel_initializer = 'uniform',activation ='relu'))\n",
    "    model.add(Dropout(dropout_rates[1]))\n",
    "    model.add(Dense(hidden_units[2], kernel_initializer = 'uniform',activation ='relu'))\n",
    "    model.add(Dropout(dropout_rates[2]))\n",
    "    model.add(Dense(num_labels, kernel_initializer='uniform', \n",
    "                    activation = out_activation))\n",
    "    model.compile(optimizer = 'sgd', \n",
    "                       loss = 'categorical_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return model\n",
    "def objective(trial , X = X_train , y = y_train):   \n",
    "    params = {'num_columns': 50, \n",
    "              'num_labels': 4, \n",
    "          'hidden_units_1': trial.suggest_int('hidden_units_1' ,9 , 99), \n",
    "          'hidden_units_2': trial.suggest_int('hidden_units_2' ,9 , 99), \n",
    "          'hidden_units_3': trial.suggest_int('hidden_units_3' ,9 , 150),\n",
    "          'dropout_rate_1': trial.suggest_uniform('dropout_rate_1' ,0.01 , 0.5), \n",
    "          'dropout_rate_2': trial.suggest_uniform('dropout_rate_2' ,0.01 , 0.5), \n",
    "          'dropout_rate_3': trial.suggest_uniform('dropout_rate_3' ,0.01 , 0.5),        \n",
    "          'out_activation': trial.suggest_categorical('out_activation' , ['softmax','sigmoid'])}\n",
    "    # pruning_callback = optuna.integration.KerasPruningCallback(trial, monitor = 'accuracy')\n",
    "    model2 = create_model2(**params)\n",
    "    model2.fit(X_train, y_train, epochs = 3, verbose = 0\n",
    "               #, callbacks = [pruning_callback]\n",
    "              )\n",
    "    y_pred = model2.predict(X_val)\n",
    "    ll = log_loss(y_val, y_pred)\n",
    "    return ll\n",
    "              \n",
    "study = optuna.create_study(direction = 'minimize' , study_name = 'Optuna NN'\n",
    "                        #    , pruner = optuna.pruners.HyperbandPruner()\n",
    "                           )\n",
    "study.optimize(objective, n_trials = 100)\n",
    "print('numbers of the finished trials:' , len(study.trials))\n",
    "print('the best params:' , study.best_trial.params)\n",
    "print('the best value:' , study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a80d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = create_model2(**study.best_trial.params, num_columns = 50, num_labels = 4)\n",
    "model2.fit(X_train, y_train, epochs = 30, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2367599",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model2.evaluate(X_train, y_train, batch_size=30)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = model2.predict(test)\n",
    "sample_submission.to_csv('Optuna.csv',index=False)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = (model1.predict(test) + model2.predict(test)) / 2\n",
    "sample_submission.to_csv('avg.csv',index=False)\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
