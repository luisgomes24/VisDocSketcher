{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae68158",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.\"></a>\n",
    "# Content\n",
    "\n",
    "* [1. Summary](#1.)\n",
    "* [2. Cats and Dogs Dataset](#2.)\n",
    "* * [2.1. Randomly Visualization of Samples in the Dataset](#2.1.)\n",
    "* * [2.2. Some Evaluations About the Dataset](#2.2.)\n",
    "* [3. Convolutional Neural Network(CNN)](#3.)\n",
    "* * [3.1. Implementing CNN Architecture with Keras](#3.1.)\n",
    "* [4.Transfer Learning 1: Feature Extractor](#4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058abdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras import applications\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import glob\n",
    "import os\n",
    "print(\"Cats&Dogs Dataset Folder Contain:\",os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d74d1d",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"1.\"></a>1. Summary\n",
    "\n",
    "In this study, CNN architecture and transfer learning techniques will be used to classify cats and dogs in the Cats & Dogs dataset. Firstly, the dataset will be visualized and evaluated. Then, a CNN architecture will be created with keras, and trained and estimated on training and test sets respectively.  Then transfer learning technques will be applied on the dataset. \n",
    "\n",
    "Transfer learning is one of the important advantages of deep learning. There are two different transfer learning types used on image data; feature extractor and fine tunning. In this kernel transfer learning used as feature extractor on the Cats & Dogs dataset.\n",
    "\n",
    "In this study you will learn:\n",
    "\n",
    "* Visualization of images in form of gallery\n",
    "* Use of CNN architecture in image classification.\n",
    "* Transfer Learning Type 1-Feature Extractor : pretrained model used such as feature extractor.\n",
    "\n",
    "Accuracy performace of the approaches as follows:\n",
    "\n",
    "* Custom CNN accurcy rate is %80(+-2)\n",
    "* Transfer Learning Type 1-Feature Extractor accuracy rate is %95(+-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab7918",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"2.\"></a>2. Cats and Dogs Dataset\n",
    "\n",
    "The dataset provide 25000 cats and dogs images to classify. Samples of the dataset as in form image gallery can be seen in figures in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077292f",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"2.1.\"></a>2.1. Randomly Visualization of Samples in the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "\n",
    "zip_files = ['test1', 'train']\n",
    "# Will unzip the files so that you can see them..\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(\"../input/{}.zip\".format(zip_file),\"r\") as z:\n",
    "        z.extractall(\".\")\n",
    "        print(\"{} unzipped\".format(zip_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856933cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir('../input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71de64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER_PATH=\"../working/train\"\n",
    "FILE_NAMES=os.listdir(IMAGE_FOLDER_PATH)\n",
    "WIDTH=150\n",
    "HEIGHT=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64087941",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=list()\n",
    "full_paths=list()\n",
    "for file_name in FILE_NAMES:\n",
    "    target=file_name.split(\".\")[0]\n",
    "    full_path=os.path.join(IMAGE_FOLDER_PATH, file_name)\n",
    "    full_paths.append(full_path)\n",
    "    targets.append(target)\n",
    "\n",
    "dataset=pd.DataFrame()\n",
    "dataset['image_path']=full_paths\n",
    "dataset['target']=targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts=dataset['target'].value_counts()\n",
    "print(\"Number of dogs in the dataset:{}\".format(target_counts['dog']))\n",
    "print(\"Number of cats in the dataset:{}\".format(target_counts['cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel=img.shape\n",
    "    if side_type==\"horizontal\":\n",
    "        return np.ones((height,side_size,  channel), dtype=np.float32)*255\n",
    "        \n",
    "    return np.ones((side_size, width,  channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show=\"both\"):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(full_paths)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(targets)\n",
    "    for path, target in zip(full_paths, targets):\n",
    "        if target!=show and show!=\"both\":\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        #Image loading from disk as JpegImageFile file format\n",
    "        img=load_img(path, target_size=(WIDTH,HEIGHT))\n",
    "        #Converting JpegImageFile to numpy array\n",
    "        img=img_to_array(img)\n",
    "        \n",
    "        hside=get_side(img, side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if counter%10==0:\n",
    "            himage=np.hstack((images))\n",
    "            vside=get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images=list()\n",
    "\n",
    "    gallery=np.vstack((vertical_images)) \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title={\"both\":\"Dogs and Cats\",\n",
    "          \"cat\": \"Cats\",\n",
    "          \"dog\": \"Dogs\"}\n",
    "    plt.title(\"100 samples of {} of the dataset\".format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7057ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(show=\"cat\")\n",
    "show_gallery(show=\"dog\")\n",
    "show_gallery(show=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dc779",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"2.1.\"></a>2.2. Some Evaluations About the Dataset\n",
    "There are  three image galleries in above figures. First one showing only images of cats, second one showing only images of dogs and third one shows images of cats and dogs.  When the images in galleries are examined, it is possible to make the following evaluations;\n",
    "\n",
    "\n",
    "\n",
    "* There are many different types of cats\n",
    "* There are many different types of dogs\n",
    "* Some cat (dog) breeds are very similar to some dog (cat) breeds.\n",
    "* The backgrounds in the images are very different and noisy.\n",
    "* The difference in exposure of cats and dogs in the images is quite high.\n",
    "\n",
    "The above features have the effect of making image classification difficult. In addition, the difference in light that makes image classification difficult, is little to be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3cff9",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\".\"></a>3. Convolutional Neural Network(CNN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_history(modelHistory, model_name):\n",
    "    history=pd.DataFrame()\n",
    "    history[\"Train Loss\"]=modelHistory.history['loss']\n",
    "    history[\"Validatin Loss\"]=modelHistory.history['val_loss']\n",
    "    history[\"Train Accuracy\"]=modelHistory.history['accuracy']\n",
    "    history[\"Validatin Accuracy\"]=modelHistory.history['val_accuracy']\n",
    "  \n",
    "    history.plot(figsize=(12,8))\n",
    "    plt.title(\" Convulutional Model {} Train and Validation Loss and Accuracy History\".format(model_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e8a00",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"3.1.\"></a>3.1. Implementing CNN Architecture with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(WIDTH, HEIGHT, 3)))\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecec1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", \n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=[\"accuracy\"])\n",
    "print(\"[INFO]: model compiled...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test=train_test_split(dataset,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "rotation_range=15,\n",
    "rescale=1./255,\n",
    "shear_range=0.1,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1)\n",
    "\n",
    "train_datagenerator=train_datagen.flow_from_dataframe(dataframe=dataset_train,\n",
    "                                                     x_col=\"image_path\",\n",
    "                                                     y_col=\"target\",\n",
    "                                                     target_size=(WIDTH, HEIGHT),\n",
    "                                                     class_mode=\"binary\",\n",
    "                                                     batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator=test_datagen.flow_from_dataframe(dataframe=dataset_test,\n",
    "                                                   x_col=\"image_path\",\n",
    "                                                   y_col=\"target\",\n",
    "                                                   target_size=(WIDTH, HEIGHT),\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelHistory=model.fit_generator(train_datagenerator,\n",
    "                                epochs=50,\n",
    "                                validation_data=test_datagenerator,\n",
    "                                validation_steps=dataset_test.shape[0]//150,\n",
    "                                steps_per_epoch=dataset_train.shape[0]//150\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aaf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy:{:.3f}\".format(modelHistory.history['accuracy'][-1]))\n",
    "print(\"Test Accuracy:{:.3f}\".format(modelHistory.history['val_accuracy'][-1]))\n",
    "show_model_history(modelHistory=modelHistory, model_name=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d2362",
   "metadata": {},
   "source": [
    "[Go to Content Menu](#0.)\n",
    "\n",
    "# <a class=\"anchor\" id=\"4.\"></a>4.Transfer Learning 1: Feature Extractor\n",
    "\n",
    "In this section and in the next section, the use of  pretrained model on a dataset, on another dataset will be explained.\n",
    "\n",
    "In traditional computer vision approaches, feature vectors are extracted from the images in the dataset, and these features are classified by supervised machine learning algorithms. In CNN deep learning approaches, images are given to the CNN model, which makes classification without feature extraction process. \n",
    "\n",
    "The only advantage of deep learning is not to make classification without using feature extractor. CNN also allows for the use of pretrained models on new datasets. This approach is called Transfer Learning. There are two different Transfer Learning approaches;\n",
    "\n",
    "* Feature Extractor\n",
    "* Fine Tunning\n",
    "\n",
    "Transfer learning is based on the paradigm where a model previously trained on the A dataset can be used as a starting point on the B dataset. For example, a model that is trained for classification on snake and frog dataset can be used as a starting point for the classification of bear, panda and deer dataset. This can be thought of as how to find models that have been previously trained on the appropriate dataset. The models of the CNN architectures, which are featured in the image classification, are trained on \"ImageNet\" and are available in the keras library. These architectures can be easily used for the purpose of transfer learning on new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(WIDTH, HEIGHT, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7866be1",
   "metadata": {},
   "source": [
    "Since the last layer (4,4,512) is in dimensions, the length of the feature vector will be 4x4x512 = 8192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "features=list()\n",
    "for path, target in zip(full_paths, targets):\n",
    "    img=load_img(path, target_size=(WIDTH, HEIGHT))\n",
    "    img=img_to_array(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    feature=model.predict(img)\n",
    "    features.append(feature)\n",
    "    counter+=1\n",
    "    if counter%2500==0:\n",
    "        print(\"[INFO]:{} images loaded\".format(counter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c86bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.array(features)\n",
    "print(\"Before reshape,features.shape:\",features.shape)\n",
    "features=features.reshape(features.shape[0], 4*4*512)\n",
    "print(\"After reshape, features.shape:\",features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84dbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "targets=le.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features.shape:\",features.shape)\n",
    "print(\"targets.shape:\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(solver=\"lbfgs\")\n",
    "print(\"{} training...\".format(clf.__class__.__name__))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"The model trained and used to predict the test data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2584ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, y_pred, target_names=[\"cat\", \"dog\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923485c",
   "metadata": {},
   "source": [
    "Notice here that we are able to reach 94% classification accuracy! This number is a massive improvement from our previous best of 80% in our custom CNN model. \n",
    "\n",
    "Let's find cross validated score for more trusted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ae058",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores=cross_val_score(LogisticRegression(solver=\"lbfgs\"), features, targets, cv=3 )\n",
    "print(\"Cross validation scores obtained...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab6658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross validated scores:{}\".format(cv_scores))\n",
    "print(\"Mean of cross validated scores:{:.3f}\".format(cv_scores.mean()))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
