{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261d6c8c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">ULTRA MNIST</h2>\n",
    "<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER</h5>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 18px;\">üõë &nbsp; WARNING:</b><br><br><b>THIS IS A WORK IN PROGRESS</b><br>\n",
    "</div></center>\n",
    "\n",
    "\n",
    "<center><div class=\"alert alert-block alert-warning\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 18px;\">üëè &nbsp; IF YOU FORK THIS OR FIND THIS HELPFUL &nbsp; üëè</b><br><br><b style=\"font-size: 22px; color: darkorange\">PLEASE UPVOTE!</b><br><br>This was a lot of work for me and while it may seem silly, it makes me feel appreciated when others like my work. üòÖ\n",
    "</div></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10e343",
   "metadata": {},
   "source": [
    "<p id=\"toc\"></p>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: black; background-color: #ffffff;\">TABLE OF CONTENTS</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#imports\">0&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#background_information\">1&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#setup\">2&nbsp;&nbsp;&nbsp;&nbsp;SETUP</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#helper_functions\">3&nbsp;&nbsp;&nbsp;&nbsp;HELPER FUNCTIONS</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#dataset_exploration\">4&nbsp;&nbsp;&nbsp;&nbsp;DATASET EXPLORATION & PREPROCESSING</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#model_baseline\">5&nbsp;&nbsp;&nbsp;&nbsp;BASELINE</a></h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fdb03c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id=\"imports\"></a>\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: black;\" id=\"imports\">0&nbsp;&nbsp;IMPORTS&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n... IMPORTS STARTING ...\\n\")\n",
    "\n",
    "print(\"\\n... PIP/APT INSTALLS AND DOWNLOADS/ZIP STARTING ...\")\n",
    "!pip install imutils\n",
    "import imutils\n",
    "print(\"... PIP/APT INSTALLS COMPLETE ...\\n\")\n",
    "\n",
    "print(\"\\n\\tVERSION INFORMATION\")\n",
    "# Machine Learning and Data Science Imports\n",
    "import tensorflow as tf; print(f\"\\t\\t‚Äì TENSORFLOW VERSION: {tf.__version__}\");\n",
    "import tensorflow_hub as tfhub; print(f\"\\t\\t‚Äì TENSORFLOW HUB VERSION: {tfhub.__version__}\");\n",
    "import tensorflow_addons as tfa; print(f\"\\t\\t‚Äì TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\n",
    "import pandas as pd; pd.options.mode.chained_assignment = None;\n",
    "import numpy as np; print(f\"\\t\\t‚Äì NUMPY VERSION: {np.__version__}\");\n",
    "import sklearn; print(f\"\\t\\t‚Äì SKLEARN VERSION: {sklearn.__version__}\");\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from pandarallel import pandarallel; pandarallel.initialize();\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "\n",
    "# # RAPIDS\n",
    "# import cudf, cupy, cuml\n",
    "# from cuml.neighbors import NearestNeighbors\n",
    "# from cuml.manifold import TSNE, UMAP\n",
    "\n",
    "# Built In Imports\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import warnings\n",
    "import requests\n",
    "import hashlib\n",
    "import imageio\n",
    "import IPython\n",
    "import sklearn\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import gzip\n",
    "import ast\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Visualization Imports\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm; tqdm.pandas();\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageEnhance\n",
    "import matplotlib; print(f\"\\t\\t‚Äì MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "from matplotlib import animation, rc; rc('animation', html='jshtml')\n",
    "import plotly\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "import plotly.io as pio\n",
    "print(pio.renderers)\n",
    "\n",
    "def seed_it_all(seed=7):\n",
    "    \"\"\" Attempt to be Reproducible \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    \n",
    "print(\"\\n\\n... IMPORTS COMPLETE ...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4e60c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id=\"background_information\"></a>\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: black; background-color: #ffffff;\" id=\"background_information\">1&nbsp;&nbsp;BACKGROUND INFORMATION&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccea2a6",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">1.1 BASIC COMPETITION INFORMATION</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">PRIMARY TASK DESCRIPTION</b>\n",
    "\n",
    "TBD\n",
    "---\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">CONTEXT</b>\n",
    "\n",
    "TBD\n",
    "\n",
    "---\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">MORE BACKGROUND INFORMATION</b>\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e96f7",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">1.2 COMPETITION EVALUATION</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">GENERAL EVALUATION INFORMATION</b>\n",
    "\n",
    "TBD\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase; color: red;\">IS THIS A CODE COMPETITION?</b>\n",
    "\n",
    "<font style=\"color:red; font-weight: bold; font-size: 20px;\">NO!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409efde",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">1.3 DATASET OVERVIEW</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">GENERAL INFORMATION</b>\n",
    "\n",
    "TBD\n",
    "\n",
    "<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">DISCOVERED  INFORMATION [TENTATIVE]</b>\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65f7e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id=\"background_information\"></a>\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: black; background-color: #ffffff;\" id=\"setup\">2&nbsp;&nbsp;SETUP&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8281bdc",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">2.1 ACCELERATOR DETECTION</h3>\n",
    "\n",
    "---\n",
    "\n",
    "In order to use **`TPU`**, we use **`TPUClusterResolver`** for the initialization which is necessary to connect to the remote cluster and initialize cloud TPUs. Let's go over two important points\n",
    "\n",
    "1. When using TPU on Kaggle, you don't need to specify arguments for **`TPUClusterResolver`**\n",
    "2. However, on **G**oogle **C**ompute **E**ngine (**GCE**), you will need to do the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# The name you gave to the TPU to use\n",
    "TPU_WORKER = 'my-tpu-name'\n",
    "\n",
    "# or you can also specify the grpc path directly\n",
    "# TPU_WORKER = 'grpc://xxx.xxx.xxx.xxx:8470'\n",
    "\n",
    "# The zone you chose when you created the TPU to use on GCP.\n",
    "ZONE = 'us-east1-b'\n",
    "\n",
    "# The name of the GCP project where you created the TPU to use on GCP.\n",
    "PROJECT = 'my-tpu-project'\n",
    "\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER, zone=ZONE, project=PROJECT)\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üõë &nbsp; WARNING:</b><br><br>- Although the Tensorflow documentation says it is the <b>project name</b> that should be provided for the argument <b><code>`project`</code></b>, it is actually the <b>Project ID</b>, that you should provide. This can be found on the GCP project dashboard page.<br>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üìñ &nbsp; REFERENCES:</b><br><br>\n",
    "    - <a href=\"https://www.tensorflow.org/guide/tpu#tpu_initialization\"><b>Guide - Use TPUs</b></a><br>\n",
    "    - <a href=\"https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver\"><b>Doc - TPUClusterResolver</b></a><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "except ValueError:\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n",
    "    # Yield the default distribution strategy in Tensorflow\n",
    "    #   --> Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "\n",
    "# What Is a Replica?\n",
    "#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n",
    "#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n",
    "#    --> Each replica is essentially a copy of the training graph that is run on each core and \n",
    "#        trains a mini-batch containing 1/8th of the overall batch size\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "    \n",
    "print(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n",
    "\n",
    "print(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad46665",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">2.2 COMPETITION DATA ACCESS</h3>\n",
    "\n",
    "---\n",
    "\n",
    "TPUs read data must be read directly from **G**oogle **C**loud **S**torage **(GCS)**. Kaggle provides a utility library ‚Äì¬†**`KaggleDatasets`** ‚Äì which has a utility function **`.get_gcs_path`** that will allow us to access the location of our input datasets within **GCS**.<br><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üìå &nbsp; TIPS:</b><br><br>- If you have multiple datasets attached to the notebook, you should pass the name of a specific dataset to the <b><code>`get_gcs_path()`</code></b> function. <i>In our case, the name of the dataset is the name of the directory the dataset is mounted within.</i><br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n",
    "\n",
    "if TPU:\n",
    "    # Google Cloud Dataset path to training and validation images\n",
    "    DATA_DIR = KaggleDatasets().get_gcs_path('ultra-mnist')\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "else:\n",
    "    # Local path to training and validation images\n",
    "    DATA_DIR = \"/kaggle/input/ultra-mnist\"\n",
    "    save_locally = None\n",
    "    load_locally = None\n",
    "\n",
    "print(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\n",
    "\n",
    "print(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\n",
    "for file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n",
    "\n",
    "print(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d09755",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">2.3 LEVERAGING XLA OPTIMIZATIONS</h3>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**XLA** (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. **The results are improvements in speed and memory usage**.\n",
    "\n",
    "<br>\n",
    "\n",
    "When a TensorFlow program is run, all of the operations are executed individually by the TensorFlow executor. Each TensorFlow operation has a precompiled GPU/TPU kernel implementation that the executor dispatches to.\n",
    "\n",
    "XLA provides us with an alternative mode of running models: it compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. Because these kernels are unique to the model, they can exploit model-specific information for optimization.<br><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üõë &nbsp; WARNING:</b><br><br>- XLA can not currently compile functions where dimensions are not inferrable: that is, if it's not possible to infer the dimensions of all tensors without running the entire computation<br>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üìå &nbsp; NOTE:</b><br><br>- XLA compilation is only applied to code that is compiled into a graph (in <b>TF2</b> that's only a code inside <b><code>tf.function</code></b>).<br>- The <b><code>jit_compile</code></b> API has must-compile semantics, i.e. either the entire function is compiled with XLA, or an <b><code>errors.InvalidArgumentError</code></b> exception is thrown)\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n",
    "    <b style=\"font-size: 16px;\">üìñ &nbsp; REFERENCE:</b><br><br>    - <a href=\"https://www.tensorflow.org/xla\"><b>XLA: Optimizing Compiler for Machine Learning</b></a><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a12893",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n... XLA OPTIMIZATIONS STARTING ...\\n\")\n",
    "\n",
    "print(f\"\\n... CONFIGURE JIT (JUST IN TIME) COMPILATION ...\\n\")\n",
    "# enable XLA optmizations (10% speedup when using @tf.function calls)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "print(f\"\\n... XLA OPTIMIZATIONS COMPLETED ...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecd5b4",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">2.4 BASIC DATA DEFINITIONS & INITIALIZATIONS</h3>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n",
    "\n",
    "print(\"\\n... TRAIN DATAFRAME ...\\n\")\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df[\"f_path\"] = DATA_DIR+\"/train/\"+train_df.id+\".jpeg\"\n",
    "display(train_df)\n",
    "\n",
    "print(\"\\n... SAMPLE SUBMISSION DATAFRAME ...\\n\")\n",
    "SS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "ss_df = pd.read_csv(SS_CSV)\n",
    "ss_df[\"f_path\"] = DATA_DIR+\"/test/\"+ss_df.id+\".jpeg\"\n",
    "display(ss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c809ec5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"helper_functions\"></a>\n",
    "\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: black; background-color: #ffffff;\" id=\"helper_functions\">\n",
    "    3&nbsp;&nbsp;HELPER FUNCTION & CLASSES&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a>\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeade26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_l_o_l(nested_list):\n",
    "    \"\"\" Flatten a list of lists \"\"\"\n",
    "    nested_list = [x if type(x) is list else [x,] for x in nested_list]\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "def sector_cleaner_2nd(img):\n",
    "    img=img/255\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            border = \\\n",
    "                img[1000*i:1000*(i+1),min(1000*j,3999)].sum() +\\\n",
    "                img[1000*i:1000*(i+1),1000*(j+1)-1].sum() +\\\n",
    "                img[min(1000*i,3999),1000*j:1000*(j+1)].sum() +\\\n",
    "                img[1000*(i+1)-1,1000*j:1000*(j+1)].sum()\n",
    "            if border>=2000:\n",
    "                img[1000*i:1000*(i+1),1000*j:1000*(j+1)]=np.abs(img[1000*i:1000*(i+1),1000*j:1000*(j+1)]-1)\n",
    "            \n",
    "    return (img*255).astype(np.uint8)\n",
    "\n",
    "def path_to_crops(f_path, tmp_size=(4000,4000), resize_to=(28,28), pad_black=(2,2), \n",
    "                  blur_kernel=(7,7), fill_kernel=(11,11), thresh_val=50, \n",
    "                  inter_down=cv2.INTER_AREA, c_area_max=0.000001, use_sec_clean=True,\n",
    "                  return_sec=False, save_to_disk=True, save_dir=\"/kaggle/working/28x28_crops\"):\n",
    "    \n",
    "    if pad_black is not None:\n",
    "        resize_to = (resize_to[0]-pad_black[0]*2, resize_to[1]-pad_black[1]*2)\n",
    "    \n",
    "    # Read Image\n",
    "    orig_img = cv2.imread(f_path, flags=cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    sec_clean_img = sector_cleaner_2nd(orig_img.copy())\n",
    "    \n",
    "    # Resize To Smaller For Performance Improvement \n",
    "    sec_clean_img = cv2.resize(sec_clean_img, tmp_size, interpolation=inter_down)\n",
    "    \n",
    "    # Create a copy to use to find the bounding boxes for the numbers\n",
    "    img = sec_clean_img.copy()\n",
    "    \n",
    "    # Some intermediate initialization\n",
    "    resized_area = tmp_size[0]*tmp_size[1]\n",
    "    cnt_area_thresh = c_area_max*resized_area\n",
    "    \n",
    "    # Blur the image\n",
    "    img = cv2.GaussianBlur(img, blur_kernel, 0)\n",
    "    \n",
    "    # Threshold the image\n",
    "    img = cv2.threshold(img, thresh_val, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Fill in contours that are near to each other\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, fill_kernel));\n",
    "    \n",
    "    # find contours in the image and return bounding boxes\n",
    "    cnts = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    bboxes = [cv2.boundingRect(cnt) for cnt in imutils.grab_contours(cnts) if cv2.contourArea(cnt)>cnt_area_thresh]\n",
    "    crops = [cv2.copyMakeBorder(cv2.resize(sec_clean_img[box[1]:box[1]+box[3], box[0]:box[0]+box[2]], resize_to, interpolation=inter_down), top=pad_black[1], bottom=pad_black[1], left=pad_black[0], right=pad_black[1], borderType=cv2.BORDER_CONSTANT, value=0) for box in bboxes]\n",
    "    \n",
    "    # print(len(cnts))\n",
    "    if save_to_disk:\n",
    "        for i, crop in enumerate(crops):\n",
    "            cv2.imwrite(os.path.join(save_dir, f\"crop_{(i+1):03}of{len(crops):03}_{f_path.rsplit('/', 1)[-1]}\"), crop)\n",
    "    else:\n",
    "        if return_sec:\n",
    "            return sec_clean_img, crops\n",
    "        else:\n",
    "            return crops\n",
    "    \n",
    "def plot_df_row(row):\n",
    "    _sec_clean, _crops = path_to_crops(row.f_path, save_to_disk=False, return_sec=True)\n",
    "    _rows = int(np.ceil((len(_crops)+2)/4))\n",
    "\n",
    "    print(\"\\n... DETECTED DIGITS ...\\n\")\n",
    "    plt.figure(figsize=(20,6*_rows))\n",
    "\n",
    "    plt.subplot(_rows,4,1)\n",
    "    plt.imshow(cv2.resize(cv2.imread(row.f_path), (4000,4000), interpolation=cv2.INTER_AREA), cmap=\"gray\")\n",
    "    plt.title(f\"ORIGINAL IMAGE - SUM={row.digit_sum}\", fontweight=\"bold\")\n",
    "    plt.axis(False)\n",
    "    \n",
    "    plt.subplot(_rows,4,2)\n",
    "    plt.imshow(_sec_clean, cmap=\"gray\")\n",
    "    plt.title(f\"SEC CLEAN IMAGE - SUM={row.digit_sum}\", fontweight=\"bold\")\n",
    "    plt.axis(False)\n",
    "\n",
    "    for i, _crop in enumerate(_crops):\n",
    "        plt.subplot(_rows,4,i+3)\n",
    "        plt.imshow(_crop, cmap=\"gray\") \n",
    "        plt.title(f\"\\nDETECTED DIGIT #{i+1}\", fontweight=\"bold\")\n",
    "        plt.axis(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "    \n",
    "def get_tfgan_pred(crops, return_sum=False, combo=\"max\", do_combo=True):\n",
    "    try:\n",
    "        pred_1 = tfgan(tf.cast(tf.expand_dims(tf.stack(crops, axis=0), axis=-1), tf.float32))\n",
    "\n",
    "        if do_combo:\n",
    "            pred_2 = tfgan(255.- tf.cast(tf.expand_dims(tf.stack(crops, axis=0), axis=-1), tf.float32))\n",
    "            if combo==\"max\":\n",
    "                preds = tf.argmax(tf.math.reduce_max(tf.stack([pred_1, pred_2]), axis=0), axis=-1)\n",
    "            elif combo==\"mean\":\n",
    "                preds = tf.argmax(tf.math.reduce_mean(tf.stack([pred_1, pred_2]), axis=0), axis=-1)\n",
    "        else:\n",
    "            preds=tf.argmax(pred_1, axis=-1)\n",
    "        if return_sum:\n",
    "            return tf.math.reduce_sum(preds).numpy()\n",
    "        else:\n",
    "            return preds.numpy()\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb9a5d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"model_baseline\"></a>\n",
    "\n",
    "\n",
    "<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: black; background-color: #ffffff;\" id=\"dataset_exploration\">\n",
    "    5&nbsp;&nbsp;MODEL BASELINE&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a>\n",
    "</h1>\n",
    "\n",
    "---\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78af454",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/28x28_crops', exist_ok=True)\n",
    "_ = ss_df.f_path.progress_apply(lambda x: path_to_crops(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfgan = tfhub.KerasLayer(\"https://tfhub.dev/tensorflow/tfgan/eval/mnist/logits/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_row = train_df.iloc[3]\n",
    "\n",
    "# plot_df_row(demo_row)\n",
    "\n",
    "# _crops = path_to_crops(demo_row.f_path, save_to_disk=False)\n",
    "# print(get_tfgan_pred(_crops, do_combo=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823621b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_train_df = train_df.sample(100).reset_index(drop=True)\n",
    "\n",
    "# sub_train_df[\"pred_sum\"] = sub_train_df.f_path.progress_apply(lambda x: get_tfgan_pred(path_to_crops(x, save_to_disk=False), return_sum=True, do_combo=False).numpy())\n",
    "# sub_train_df[\"pred_sum\"] = sub_train_df[\"pred_sum\"].apply(lambda x: x if x<=27 else 27)\n",
    "# display(sub_train_df)\n",
    "# (sub_train_df[\"pred_sum\"]==sub_train_df[\"digit_sum\"]).sum()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss_df[\"digit_sum\"] = ss_df.f_path.progress_apply(lambda x: get_tfgan_pred(path_to_crops(x, save_to_disk=False), return_sum=True, do_combo=False))\n",
    "# ss_df[\"digit_sum\"] = ss_df[\"digit_sum\"].apply(lambda x: x if x<=27 else 27)\n",
    "# ss_df[[\"id\", \"digit_sum\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
