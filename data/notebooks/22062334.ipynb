{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f20e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caa338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "pd_submit = pd.read_csv('/kaggle/input/cat-dog-action-classification/sample_submit.csv')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, split, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 이미지가 들어있는 'train_data' 와 'test_data'의 상위 폴더\n",
    "            split (string): 'train' / 'test'\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        if split == 'train':\n",
    "            img_path = os.path.join(root_dir, 'train_data')\n",
    "            self.img_paths = [ i for i in sorted(os.listdir(img_path))]\n",
    "            self.labels = [i.split('_')[0] for i in sorted(os.listdir(img_path))]\n",
    "        elif split == 'test':\n",
    "            img_path = os.path.join(root_dir, 'test_data')\n",
    "            self.img_paths = [i for i in sorted(os.listdir(img_path))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == 'train':\n",
    "            img_path = os.path.join(root_dir, 'train_data/' + self.img_paths[idx])\n",
    "            img = PIL.Image.open(img_path)\n",
    "            #img = cv2.imread(self.img_paths[idx])\n",
    "            text_label_dict = {'arm':0, 'bodylower':1, 'sit':2, 'walkrun': 3, 'lying': 4}\n",
    "            label = text_label_dict[self.labels[idx]]\n",
    "                \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        elif self.split == 'test':\n",
    "            img_path = os.path.join(root_dir, 'test_data/' + self.img_paths[idx])\n",
    "            img = PIL.Image.open(img_path)\n",
    "            #img = cv2.imread(self.img_paths[idx])\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1632ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "root_dir = '../input/cat-dog-action-classification'\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.RandomCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224,244)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CatDogDataset(root_dir = root_dir, split = 'train', transform = train_transform)\n",
    "test_dataset = CatDogDataset(root_dir = root_dir, split = 'test', transform = test_transform)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=False)\n",
    "\n",
    "total_batch = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8771252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# random.seed(42)\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=5)\n",
    "model = model.to(device)\n",
    "# 기존 resnet50모델 대신 efficientnet을 사용함\n",
    "# model = models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fc.out_featurse = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from efficientnet_pytorch import EfficientNet\n",
    "# model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=5)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "model.train()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 5e-5)\n",
    "\n",
    "epochs = 21 #0.41-> 베이스코드가 seed고정이 되어있지 않아서 0.47이 나옴\n",
    "# epochs = 30\n",
    "# epochs = 15\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    avg_loss = 0\n",
    "    for X, Y in train_data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        loss = loss_fn(hypothesis, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "        tmp_h = torch.Tensor()\n",
    "        tmp_h = torch.cat([tmp_h,torch.argmax(hypothesis,1).cpu()])\n",
    "        tmp_y = torch.Tensor()\n",
    "        tmp_y = torch.cat([tmp_y, Y.cpu()])\n",
    "\n",
    "    accuracy = sum(tmp_y == tmp_h) / len(tmp_y)\n",
    "    print('epoch : {:4d}, Avg loss: {:.7f}, Accuracy: {:.7f}'.format(epoch , avg_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231836a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    for X_test in test_data_loader:\n",
    "        prediction = model(X_test.to(device))\n",
    "        argmax_pred = torch.argmax(prediction, dim = 1)\n",
    "        pred_list.extend(argmax_pred.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = np.array(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit['Category'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580baf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit = pd_submit.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d84191",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_submit.to_csv('results.csv', index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
