{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36060da",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1221f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da8e69",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test = pd.read_csv('//kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check train & test sets first 5 rows\n",
    "print(train.head(5) , '\\n\\n')\n",
    "print(test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the shapes of the dataset\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check column names with data types\n",
    "print(train.dtypes , '\\n')\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf09f2",
   "metadata": {},
   "source": [
    "### Check and treat missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3488835",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check null/missing values\n",
    "print(train.isnull().sum() , '\\n')\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb079ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy the dataset to new variables\n",
    "train2 = train.copy()\n",
    "test2 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a075d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace null values\n",
    "\n",
    "train2['Age'] = train2['Age'].replace(np.NAN, train2['Age'].mean()) # replace by mean value\n",
    "train2['Cabin'] = train2['Cabin'].replace(np.NAN, 'XX')\n",
    "train2['Embarked'] = train2['Embarked'].replace(np.NAN, 'YY')\n",
    "\n",
    "test2['Age'] = test2['Age'].replace(np.NAN, test2['Age'].mean()) # replace by mean value\n",
    "test2['Cabin'] = test2['Cabin'].replace(np.NAN, 'XX')\n",
    "test2['Fare'] = test2['Fare'].replace(np.NAN, test2['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3591b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check no null/missing values\n",
    "print(train2.isnull().sum() , '\\n')\n",
    "print(test2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c2e3a",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5ede1",
   "metadata": {},
   "source": [
    "#### define action on variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check Data Dictionary at https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5337789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived :- ok\n",
    "# Pclass :: Ticket class :: ordered categorical variable :- ok\n",
    "# Name :- drop\n",
    "# Sex :: unordered categorical variable :- do one-hot encoding\n",
    "# Age :- scale\n",
    "# SibSp :- scale\n",
    "# Parch :- scale\n",
    "# Ticket :- extract number only then scale\n",
    "# Fare :- scale\n",
    "# Cabin : extract first character and do on-hot encoding\n",
    "# Embarked : do one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17a63b",
   "metadata": {},
   "source": [
    "#### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "oHE = OneHotEncoder(sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sex // train\n",
    "print(train2['Sex'].value_counts().to_frame().sort_values('Sex'))\n",
    "Sex1 = pd.DataFrame(oHE.fit_transform(train2[['Sex']]))\n",
    "Sex1.columns = ['Sex-female', 'Sex-male']\n",
    "print(Sex1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sex // test\n",
    "print(test2['Sex'].value_counts().to_frame().sort_values('Sex'))\n",
    "Sex2 = pd.DataFrame(oHE.fit_transform(test2[['Sex']]))\n",
    "Sex2.columns = ['Sex-female', 'Sex-male']\n",
    "print(Sex2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cabin // train\n",
    "Cb1 = pd.DataFrame(train2['Cabin'].str.get(0))\n",
    "print(Cb1.value_counts().to_frame().sort_values('Cabin'))\n",
    "Cabin1 =pd.DataFrame(oHE.fit_transform(Cb1))\n",
    "Cabin1.columns = ['Cabin-A', 'Cabin-B', 'Cabin-C', 'Cabin-D', 'Cabin-E', 'Cabin-F', 'Cabin-G', 'Cabin-T', 'Cabin-X']\n",
    "print(Cabin1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cabin // test\n",
    "cb2 = pd.DataFrame(test2['Cabin'].str.get(0))\n",
    "print(cb2.value_counts().to_frame().sort_values('Cabin'))\n",
    "Cabin2 = pd.DataFrame(oHE.fit_transform(cb2))\n",
    "Cabin2.columns = ['Cabin-A', 'Cabin-B', 'Cabin-C', 'Cabin-D', 'Cabin-E', 'Cabin-F', 'Cabin-G', 'Cabin-X']\n",
    "print(Cabin2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embarked // train\n",
    "print(train2['Embarked'].value_counts().to_frame().sort_values('Embarked'))\n",
    "Embarked1 = pd.DataFrame(oHE.fit_transform(train2[['Embarked']]))\n",
    "Embarked1.columns = ['Embarked-C', 'Embarked-Q', 'Embarked-S', 'Embarked-YY']\n",
    "print(Embarked1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embarked // test\n",
    "print(test2['Embarked'].value_counts().to_frame().sort_values('Embarked'))\n",
    "Embarked2 = pd.DataFrame(oHE.fit_transform(test2[['Embarked']]))\n",
    "Embarked2.columns = ['Embarked-C', 'Embarked-Q', 'Embarked-S']\n",
    "print(Embarked2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555435da",
   "metadata": {},
   "source": [
    "#### sandard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract only numbers from 'Ticket'\n",
    "train2['Ticket_num'] = train2['Ticket'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "test2['Ticket_num'] = test2['Ticket'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "print (train2['Ticket_num'].head(5), '\\n', test2['Ticket_num'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91693615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## // train\n",
    "scl_train = pd.DataFrame(scl.fit_transform(train2[['Pclass', 'Age', 'SibSp', 'Parch', 'Ticket_num', 'Fare']]))\n",
    "scl_train.columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Ticket_num', 'Fare']\n",
    "print(scl_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa12c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## // train\n",
    "scl_test = pd.DataFrame(scl.fit_transform(test2[['Pclass', 'Age', 'SibSp', 'Parch', 'Ticket_num', 'Fare']]))\n",
    "scl_test.columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Ticket_num', 'Fare']\n",
    "print(scl_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1daab",
   "metadata": {},
   "source": [
    "### Combine column dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed566ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Survived_train = pd.DataFrame(train2['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d197d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.concat([Survived_train, Sex1, Cabin1, Embarked1, scl_train], axis =1).reset_index(drop = True)\n",
    "print(train3.shape, '\\n')\n",
    "print(train3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = pd.concat([Sex2, Cabin2, Embarked2, scl_test], axis =1).reset_index(drop = True)\n",
    "print(test3.shape, '\\n')\n",
    "print(test3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if any null value produced\n",
    "print(train3.isnull().sum(), '\\nn')\n",
    "print(test3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace four null values in 'Ticket_num'\n",
    "train3['Ticket_num'] = train3['Ticket_num'].replace(np.NAN, train3['Ticket_num'].mean())\n",
    "train3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03650e",
   "metadata": {},
   "source": [
    "### train ~ test(validation) split of processed train data (train3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train3.drop('Survived', axis = 1)\n",
    "Y = train3['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1e198",
   "metadata": {},
   "source": [
    "### Apply Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a73ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "LG = LogisticRegression(solver = 'liblinear', random_state = 0)\n",
    "LG.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check coefficients\n",
    "print('Coefficients :' , LG.coef_ , 'Intercept :', LG.intercept_)\n",
    "print('Coefficient of determination : ', LG.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict on the validation set\n",
    "y_pred = pd.Series(LG.predict(x_test))\n",
    "y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517de5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm, '\\n')\n",
    "print(classification_report(y_test, y_pred, target_names = ['class 0', 'class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize confusion matrix\n",
    "cmp = sns.heatmap(cm, annot = True)\n",
    "\n",
    "cmp.set_title('Confusion Matrix with labels \\n')\n",
    "cmp.set_xlabel('\\n PREDICTED')\n",
    "cmp.set_ylabel('\\n ACTUAL')\n",
    "\n",
    "cmp.xaxis.set_ticklabels(['0', '1'])\n",
    "cmp.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d92ef",
   "metadata": {},
   "source": [
    "### Apply the Logistic Regression model to the Test set (test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee240be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare columns in the train and test sets (train3 & test3)\n",
    "print('Columns in both x_test & test3', x_test.columns.intersection(test3.columns), '\\n')\n",
    "print('Columns in x_test but not in test3', x_test.columns.difference(test3.columns), '\\n')\n",
    "print('Columns in test3 but not in x_test', test3.columns.difference(x_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ed014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create missing column in test3 with 0\n",
    "test3['Cabin-T'] = 0\n",
    "test3['Embarked-YY'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35801a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Test = pd.Series(LG.predict(test3))\n",
    "y_pred_Test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict on the Test set\n",
    "id = test['PassengerId'].to_frame('PassengerId').reset_index(drop = True)\n",
    "sv = y_pred_Test.to_frame('Survived').reset_index(drop = True)\n",
    "\n",
    "df_LG = pd.concat([id, sv], axis = 1)\n",
    "print(df_LG )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25027879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the .csv file\n",
    "df_LG.to_csv(\"kaggale_titanic_LG_v2.csv\", index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
