{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;sns.set()\n",
    "\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.metrics         import confusion_matrix,classification_report,accuracy_score,roc_auc_score,roc_curve\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from IPython.display         import Image\n",
    "from sklearn.tree            import export_graphviz\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8301b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../input/creditcardfraud/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ff519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564d091",
   "metadata": {},
   "source": [
    "check missing values\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc497c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax  = plt.subplots(figsize = (6,4))\n",
    "ax = sns.countplot(x = 'Class',data= data)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Class'].value_counts())\n",
    "print('\\n percentage of fraud:{:.2%}'.format((data[data['Class']==1].shape[0]/data.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e45831",
   "metadata": {},
   "source": [
    "o.17% of data is fraud \n",
    "dataset is highly imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b84950",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,\n",
    "            linewidths=.1, cmap=\"RdBu\", ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e0ec2",
   "metadata": {},
   "source": [
    "no relation between variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324b054",
   "metadata": {},
   "source": [
    "preprocessing\n",
    "\n",
    "scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "scaler = StandardScaler()\n",
    "data_clean['std_amount'] = scaler.fit_transform(data_clean['Amount'].values.reshape(-1, 1))\n",
    "data_clean['std_time'] = scaler.fit_transform(data_clean['Time'].values.reshape(-1, 1))\n",
    "\n",
    "data_clean.drop(['Amount', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our feature matrix and target vector\n",
    "X = data_clean.drop('Class', axis=1)\n",
    "y = data_clean['Class']\n",
    "\n",
    "# train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122d3bc",
   "metadata": {},
   "source": [
    "undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_rus,y_rus = rus.fit_sample(X_train,y_train)\n",
    "\n",
    "#lets check sampled data\n",
    "print(pd.Series(y_rus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9417520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_correlation\n",
    "cor_rus = pd.DataFrame(X_rus).corr()\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (9,7))\n",
    "sns.heatmap(cor_rus,xticklabels=corr.columns, yticklabels=corr.columns,\n",
    "            linewidths=.1, cmap=\"RdBu\", ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ea27a",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression()\n",
    "\n",
    "model_log.fit(X_rus,y_rus)\n",
    "\n",
    "y_pred_log = model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91058ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "# ROC AUC score\n",
    "print(\"AUC: {:.2f}\\n\".format(roc_auc_score(y_test, y_pred_log)))\n",
    "\n",
    "# confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_log, normalize='true'), annot=True, ax=ax)\n",
    "\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "ax.set_ylabel(\"Real Value\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=4,criterion = 'entropy')\n",
    "model_tree.fit(X_rus,y_rus)\n",
    "y_pred_tree = model_tree.predict(X_test)\n",
    "#clssi_reprt\n",
    "print(classification_report(y_test,y_pred_tree))\n",
    "#auc_roc_score\n",
    "print(\"AUC: {:.2%}\\n \".format(roc_auc_score(y_test,y_pred_tree)))\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_tree, normalize='true'), annot=True, ax=ax)\n",
    "\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "ax.set_ylabel(\"Real Value\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebe3eb",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Both models, **Logistic Regression** and **Decision Tree** performed extremely well in classifying credit card activities into the classes Regular Transaction and Fraudulent Transaction, with accuracy, ROC AUC scores and precision above 90%. Although they produced similar outcomes, the Logistic Regression showed slightly better results, with a greater ROC AUC score, which measures how well the model is capable to distinguish between classes.\n",
    "\n",
    "> One of the biggest problems is the occurrence of False Positives, that is when the algorithm incorrectly detects a fraud. Thus, we are always searching for ways to shrink even more that 3% of False Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
