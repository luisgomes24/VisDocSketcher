{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d9e5fa",
   "metadata": {},
   "source": [
    "# Exploration of Data and trying AutoGluon\n",
    "## Table of Contents\n",
    "* [Import and first glance](#import)\n",
    "* [EDA](#EDA)\n",
    "* [Data Preparations](#prep)\n",
    "* [Fit Model](#fit)\n",
    "* [Model Evaluation (Leader)](#model_eval)\n",
    "* [Predict on Test Set (Leader)](#pred_test)\n",
    "* [Model on 2nd place](#model_2)\n",
    "* [Model on 3rd place](#model_3)\n",
    "* [Blend 2nd and 3rd model](#blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6317b80",
   "metadata": {},
   "source": [
    "### AutoGluon Docs: https://auto.gluon.ai/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install package\n",
    "!pip install autogluon\n",
    "\n",
    "# for interpretable models:\n",
    "!pip install imodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# statistics\n",
    "from scipy import stats\n",
    "\n",
    "# AutoGluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1be760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "pd.set_option('display.max_columns', None) # we want to display all columns in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b64546",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "# Import and first glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac69931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../input/playground-series-s3e3/train.csv')\n",
    "df_test = pd.read_csv('../input/playground-series-s3e3/test.csv')\n",
    "df_sub = pd.read_csv('../input/playground-series-s3e3/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b31f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure of data - train\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59959e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure of data - test\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8a9f9",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ Train and Test Set are really small here. We have to be careful to not overfit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a0fb6",
   "metadata": {},
   "source": [
    "<a id='EDA'></a>\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats - train\n",
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fa8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats - test\n",
    "df_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eafa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "features_num = ['Age','DailyRate','DistanceFromHome','Education', 'EmployeeCount',\n",
    "                'EnvironmentSatisfaction','HourlyRate','JobInvolvement',\n",
    "                'JobLevel','JobSatisfaction', \n",
    "                'MonthlyIncome','MonthlyRate','NumCompaniesWorked', \n",
    "                'PercentSalaryHike','PerformanceRating',\n",
    "                'RelationshipSatisfaction','StandardHours','StockOptionLevel',\n",
    "                'TotalWorkingYears','TrainingTimesLastYear','WorkLifeBalance',\n",
    "                'YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion',\n",
    "                'YearsWithCurrManager']\n",
    "\n",
    "features_cat = ['BusinessTravel','Department','EducationField',\n",
    "                'Gender','JobRole','MaritalStatus','Over18','OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b48a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms (train and test)\n",
    "for f in features_num:\n",
    "    plt.figure(figsize=(12,3))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    df_train[f].plot(kind='hist', color='darkblue')\n",
    "    plt.title(f + ' - Train')\n",
    "    plt.grid()\n",
    "    ax2 = plt.subplot(1,2,2, sharex=ax1)\n",
    "    df_test[f].plot(kind='hist', color='darkgreen')\n",
    "    plt.title(f + ' - Test')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3eb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots (train and test)\n",
    "for f in features_num:\n",
    "    plt.figure(figsize=(12,1))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    plt.boxplot(df_train[f], vert=False)\n",
    "    plt.title(f + ' - Train')\n",
    "    plt.grid()\n",
    "    ax2 = plt.subplot(1,2,2, sharex=ax1)\n",
    "    plt.boxplot(df_test[f], vert=False)\n",
    "    plt.title(f + ' - Test')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c844ad",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ DailyRate and Education each show one strange outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot categorical features (train and test)\n",
    "for f in features_cat:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    df_train[f].value_counts().plot(kind='bar', color='darkblue')\n",
    "    plt.title(f + ' - Train')\n",
    "    plt.grid()\n",
    "    ax2 = plt.subplot(1,2,2, sharex=ax1)\n",
    "    df_test[f].value_counts().plot(kind='bar', color='darkgreen')\n",
    "    plt.title(f + ' - Test')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2892b",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ Observations: EmployeeCount, StandardHours and Over18 are constant. Therefore we do not use them as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef6ac3",
   "metadata": {},
   "source": [
    "<a id='prep'></a>\n",
    "# Data Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986aa80e",
   "metadata": {},
   "source": [
    "#### Let's remove outliers observed in boxplots above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1051a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "df_train = df_train[(df_train.DailyRate <= 3500) & (df_train.Education <= 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2235c",
   "metadata": {},
   "source": [
    "<a id='target_features'></a>\n",
    "# Target vs Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "label = 'Attrition'\n",
    "\n",
    "# predictors\n",
    "predictors = features_num + features_cat\n",
    "\n",
    "# remove constant features (see above)\n",
    "predictors.remove('EmployeeCount')\n",
    "predictors.remove('StandardHours')\n",
    "predictors.remove('Over18')\n",
    "\n",
    "print('Number of predictors:', len(predictors))\n",
    "print()\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions split by target\n",
    "for f in predictors:\n",
    "    if (f in features_num):\n",
    "        sns.violinplot(data=df_train, x=label, y=f)\n",
    "        plt.title(f + ' vs Target')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # calc cross table\n",
    "        ctab = pd.crosstab(df_train[f],df_train[label])\n",
    "        # ...and normalized by column\n",
    "        ctab_norm = ctab / ctab.sum()\n",
    "        # plot as heatmap\n",
    "        plt.figure(figsize=(10,3))\n",
    "        g = sns.heatmap(ctab_norm, annot=True,\n",
    "                        fmt='.2%', linecolor='black',\n",
    "                        linewidths=1,\n",
    "                        cmap='Greens', \n",
    "                        vmin=0, vmax=+1)\n",
    "        plt.title(f + ' vs Target')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08a76a",
   "metadata": {},
   "source": [
    "<a id='fit'></a>\n",
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "eval_metric = 'roc_auc'\n",
    "# path for model storage\n",
    "save_path = 'saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35148a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time limit for Auto ML in seconds\n",
    "time_limit = 5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf487dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define setup\n",
    "fit_auto = TabularPredictor(label=label,\n",
    "                            problem_type='binary',\n",
    "                            eval_metric=eval_metric,\n",
    "                            path=save_path)\n",
    "\n",
    "# and fit models\n",
    "fit_auto.fit(df_train[predictors+[label]],\n",
    "             presets='best_quality',\n",
    "             num_bag_folds=10, \n",
    "             num_bag_sets=5, \n",
    "             num_stack_levels=0,\n",
    "             excluded_model_types=['KNN'],\n",
    "             time_limit=time_limit)\n",
    "\n",
    "# presets types: [â€˜best_qualityâ€™, â€˜high_qualityâ€™, â€˜good_qualityâ€™, â€˜medium_qualityâ€™, â€˜optimize_for_deploymentâ€™, â€˜interpretableâ€™, â€˜ignore_textâ€™]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1f4df",
   "metadata": {},
   "source": [
    "<a id='model_eval'></a>\n",
    "# Model Evaluation (Leader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results of AutoML\n",
    "results = fit_auto.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa126357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance (permutation method)\n",
    "vi = fit_auto.feature_importance(df_train[predictors+[label]])\n",
    "vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ee31a",
   "metadata": {},
   "source": [
    "<a id='pred_test'></a>\n",
    "# Predict on Test Set (Leader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892eb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "pred_test = fit_auto.predict_proba(data=df_test[predictors])\n",
    "pred_test = pred_test[1]\n",
    "# stats\n",
    "print(pred_test.describe())\n",
    "\n",
    "# distribution of predictions\n",
    "plt.figure(figsize=(8,3))\n",
    "pred_test.plot(kind='hist', bins=30, color='darkblue')\n",
    "plt.title('Predictions Test - Leader')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected frequency\n",
    "sum(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "df_sub.Attrition = pred_test\n",
    "df_sub.to_csv('submission_1st.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3d931",
   "metadata": {},
   "source": [
    "<a id='model_2'></a>\n",
    "#  Model on 2nd place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ce32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get leaderboard data\n",
    "leadertab = results['model_performance']\n",
    "# sort by metric\n",
    "leadertab = dict(sorted(leadertab.items(), key=lambda item: item[1], reverse=True))\n",
    "leadertab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract name of 2nd best model\n",
    "model_2nd = list(leadertab.items())[2-1][0]\n",
    "model_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49895f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance\n",
    "vi_2nd = fit_auto.feature_importance(df_train[predictors+[label]], model=model_2nd)\n",
    "vi_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 2nd best model\n",
    "pred_test_2nd = fit_auto.predict_proba(data=df_test[predictors], model=model_2nd)\n",
    "pred_test_2nd = pred_test_2nd[1]\n",
    "# stats\n",
    "print(pred_test_2nd.describe())\n",
    "\n",
    "# distribution of predictions\n",
    "plt.figure(figsize=(8,3))\n",
    "pred_test_2nd.plot(kind='hist', bins=30, color='darkblue')\n",
    "plt.title('Predictions Test - 2nd best model')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected frequency\n",
    "sum(pred_test_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission of 2nd model\n",
    "df_sub_2nd = df_sub.copy()\n",
    "df_sub_2nd.Attrition = pred_test_2nd\n",
    "df_sub_2nd.to_csv('submission_2nd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d761d",
   "metadata": {},
   "source": [
    "<a id='model_3'></a>\n",
    "#  Model on 3rd place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b937d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract name of 3rd best model\n",
    "model_3rd = list(leadertab.items())[3-1][0]\n",
    "model_3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92280eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 3rd best model\n",
    "pred_test_3rd = fit_auto.predict_proba(data=df_test[predictors], model=model_3rd)\n",
    "pred_test_3rd = pred_test_3rd[1]\n",
    "# stats\n",
    "print(pred_test_3rd.describe())\n",
    "\n",
    "# distribution of predictions\n",
    "plt.figure(figsize=(8,3))\n",
    "pred_test_3rd.plot(kind='hist', bins=30, color='darkblue')\n",
    "plt.title('Predictions Test - 3rd best model')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daeaac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected frequency\n",
    "sum(pred_test_3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission of 3rd model\n",
    "df_sub_3rd = df_sub.copy()\n",
    "df_sub_3rd.Attrition = pred_test_3rd\n",
    "df_sub_3rd.to_csv('submission_3rd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation of predictions\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(pred_test_2nd, pred_test_3rd, \n",
    "            color='darkblue', alpha=0.3)\n",
    "plt.title('Predictions 3rd vs 2nd')\n",
    "plt.xlabel('2nd')\n",
    "plt.ylabel('3rd')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation (and significance)\n",
    "stats.pearsonr(pred_test_2nd, pred_test_3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1382c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank correlation (and significance)\n",
    "stats.spearmanr(pred_test_2nd, pred_test_3rd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c80276",
   "metadata": {},
   "source": [
    "<a id='blend'></a>\n",
    "# Blend 2nd and 3rd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_blend = df_sub.copy()\n",
    "df_sub_blend.Attrition = 0.5*pred_test_2nd + 0.5*pred_test_3rd\n",
    "df_sub_blend.to_csv('submission_blend23.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_blend.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected frequency\n",
    "sum(df_sub_blend.Attrition)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
