{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661fd0b",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d149a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/co2-emissions/CO2 Emissions.csv')\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18596874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e40353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('VehicleClass').aggregate({'CO2Emissions(g/km)': 'mean', 'Model': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FuelType').aggregate({'CO2Emissions(g/km)': 'mean', 'Model': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dcef9e",
   "metadata": {},
   "source": [
    "We only have one car with Fuel Type of N.  Let's drop this from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aace809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.FuelType != 'N'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470540b",
   "metadata": {},
   "source": [
    "# Explore Categorical Variables Relationship w/CO2 Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b683f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.boxplot(data = df, x = 'FuelType', y = 'CO2Emissions(g/km)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.boxenplot(data = df, x = 'CO2Emissions(g/km)', y = 'VehicleClass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ce48a",
   "metadata": {},
   "source": [
    "# Explore  Continous Variables relationship w/CO2 Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = df, x ='EngineSize(L)', y = 'CO2Emissions(g/km)', hue = 'Cylinders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data = df, x = 'FuelConsumptionComb(L/100km)', y = 'CO2Emissions(g/km)')\n",
    "plt.title(\"Relationship between Fuel Consumption\\n and CO2 Emissions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(numeric_only = True).round(2), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14959f11",
   "metadata": {},
   "source": [
    "# Prepare Data for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef57905",
   "metadata": {},
   "source": [
    "Many of the predictors are heavily correlated, therefore we will run a PCA to turn multiple columns into a single predictor value.  \n",
    "\n",
    "Also, the categorical variables seem to be fairly predictive, so we turn these into a series of one hot encoded values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21933cc",
   "metadata": {},
   "source": [
    "# Split into Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['VehicleClass', 'EngineSize(L)', 'Cylinders', 'FuelType', 'FuelConsumptionComb(L/100km)']\n",
    "target = 'CO2Emissions(g/km)'\n",
    "\n",
    "# use stratified shuffle split to preserve distribution of Vehicle Class between train and test set\n",
    "split = StratifiedShuffleSplit(n_splits = 1, train_size = 0.8, random_state = 42)\n",
    "\n",
    "for train_index, test_index in split.split(df, df['VehicleClass']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "    \n",
    "strat_train_set.head()\n",
    "\n",
    "\n",
    "X_train = strat_train_set[predictors].copy()\n",
    "y_train = np.array(strat_train_set[target].copy())\n",
    "\n",
    "X_test = strat_test_set[predictors].copy()\n",
    "y_test = np.array(strat_test_set[target].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42cd43",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 1, random_state = 42)\n",
    "pca.fit(X_train[['EngineSize(L)', 'Cylinders', 'FuelConsumptionComb(L/100km)']])\n",
    "print(\"These three components explain {:.2f}% of the variance\".format(pca.explained_variance_ratio_[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4e04b",
   "metadata": {},
   "source": [
    "# One Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "one_hot.fit(X_train[['VehicleClass', 'FuelType']])\n",
    "one_hot.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot.fit_transform(X_train[['VehicleClass', 'FuelType']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c799e",
   "metadata": {},
   "source": [
    "# Create Pipelines to Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=1, random_state=42)), # turn 3 numerically correlated variables into one variable\n",
    "    ('scaler', StandardScaler()) # scale and standardize values\n",
    "])\n",
    "\n",
    "X_num_tr = num_pipeline.fit_transform(X_train[['EngineSize(L)', 'Cylinders', 'FuelConsumptionComb(L/100km)']])\n",
    "X_num_tr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['EngineSize(L)', 'Cylinders', 'FuelConsumptionComb(L/100km)']\n",
    "cat_attribs = ['VehicleClass', 'FuelType']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train).toarray()\n",
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1954d8",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit test dataset using pipeline\n",
    "x_test_prepared = full_pipeline.fit_transform(X_test).toarray()\n",
    "x_test_prepared[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd51a4d",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, max_depth = 7, min_samples_split = 20)\n",
    "rf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf05f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(x_test_prepared)\n",
    "\n",
    "rf_error = mean_absolute_error(y_test, predictions)\n",
    "rf_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6e1b6",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcad361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce338a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_predictions = lin_reg.predict(x_test_prepared)\n",
    "\n",
    "lin_error = mean_absolute_error(y_test, lin_reg_predictions)\n",
    "lin_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22448690",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c84667",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=5)\n",
    "ridge.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_predictions = ridge.predict(x_test_prepared)\n",
    "\n",
    "ridge_error = mean_absolute_error(y_test, ridge_predictions)\n",
    "ridge_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a760df",
   "metadata": {},
   "source": [
    "# Tensorflow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# define model with 3 layers, 50 nodes in first, 25 in second\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(75, activation = 'linear', kernel_regularizer=tf.keras.regularizers.l2(.05)),\n",
    "    Dense(50, activation = 'linear', kernel_regularizer=tf.keras.regularizers.l2(.05)),\n",
    "    Dense(25, activation = 'linear', kernel_regularizer=tf.keras.regularizers.l2(.05)),\n",
    "    Dense(1, activation = 'linear', kernel_regularizer=tf.keras.regularizers.l2(.05))\n",
    "])\n",
    "\n",
    "\n",
    "# define loss\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = .01),\n",
    "    loss='mean_absolute_error'\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    X_train_prepared,\n",
    "    y_train,\n",
    "    epochs = 1000,\n",
    "    verbose = 0, # suppress logging\n",
    "    validation_split = .2 # calculate validation results on 20% of training data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5dfa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.ylim([0, 50])\n",
    "\n",
    "plt.title(\"Line plot of MAE\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfad569",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_predictions = model.predict(x_test_prepared)\n",
    "\n",
    "tf_error = mean_absolute_error(y_test, tf_predictions)\n",
    "tf_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244f5fd",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc929472",
   "metadata": {},
   "source": [
    "Let's take a peek at some of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = strat_test_set[predictors].copy()\n",
    "y_test = strat_test_set[target].copy()\n",
    "df_test = pd.merge(x_test, y_test, how = 'inner', left_index = True, right_index = True)\n",
    "df_test['RF_Pred'] = predictions.round(2)\n",
    "df_test['LinReg_Pred'] = lin_reg_predictions.round(2)\n",
    "df_test['Ridge_Pred'] = ridge_predictions.round(2)\n",
    "df_test['NN_Pred'] = tf_predictions.round(2)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36816de",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = pd.DataFrame(data = [rf_error, lin_error, ridge_error, tf_error],\n",
    "                            columns = ['Avg. Error'],\n",
    "                            index = ['RF Error', 'LinReg Error', 'Ridge Error', 'Neural Net Error'])\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eca5c1",
   "metadata": {},
   "source": [
    "The Random Forest regressor appears to fit the data best, only off by an average of ~6 for the CO2 Emissions target variable"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
