{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f00792",
   "metadata": {},
   "source": [
    "# Use a Community QLattice to find explainable models for diabetes\n",
    "\n",
    "The QLattice is a supervised machine learning tool for symbolic regression developed by [Abzu](https://www.abzu.ai) . It is inspired by Richard Feynman's path integral formulation. That's why the python module to use it is called *Feyn*, and the *Q* in QLattice is for Quantum.\n",
    "\n",
    "Abzu provides free QLattices for non-commercial use to anyone. These free community QLattices gets allocated for us automatically if we use Feyn without an active subscription, as we will do in this notebook. Read more about how it works here: https://docs.abzu.ai/docs/guides/getting_started/community.html\n",
    "\n",
    "The feyn Python module is not installed on Kaggle by default so we have to pip install it first. \n",
    "\n",
    "__Note__: the pip install will fail unless you enable *Internet* in the *settings* to the right --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install feyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27edac",
   "metadata": {},
   "source": [
    "# Python imports\n",
    "In this notebook we will use only three python modules: the `feyn` module to access the QLattice, and the `pandas` module to access the data, and sklearn to split the data in test/train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f836897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feyn\n",
    "import pandas as pd\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c94334",
   "metadata": {},
   "source": [
    "# Data\n",
    "Read in the data and have a quick look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/kaggle/input/predict-diabetes-based-on-diagnostic-measures/diabetes.csv'\n",
    "df = pd.read_csv(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241b306",
   "metadata": {},
   "source": [
    "# Adjust data types\n",
    "The \"gender\" and \"diabetes\" features are really boolean, but represented as text. Let's start by fixing that.\n",
    "We will also remove the patient_number column as it will overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"]=(df[\"gender\"]==\"male\").astype(int)\n",
    "df[\"diabetes\"]=(df[\"diabetes\"]==\"Diabetes\").astype(int)\n",
    "df.drop([\"patient_number\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0129f",
   "metadata": {},
   "source": [
    "There is also a problem with the three real-valued columns: \"chol_hdl_ratio\", \"bmi\" and \"waist_hip_ratio\". They use comma as a decimal seperator, European-style, which the csv parser in pandas did not know about. Lets fix that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5624cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bmi\"] = df[\"bmi\"].str.replace(\",\",\".\").astype(float)\n",
    "df[\"waist_hip_ratio\"] = df[\"waist_hip_ratio\"].str.replace(\",\",\".\").astype(float)\n",
    "df[\"chol_hdl_ratio\"] = df[\"chol_hdl_ratio\"].str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8ff49",
   "metadata": {},
   "source": [
    "# Target balance\n",
    "Let's have a quick look at the balance of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23cce0d",
   "metadata": {},
   "source": [
    "We are skewed towards \"No diabetes\". \n",
    "\n",
    "# Splitting\n",
    "Let's split the data for train/test. We will stratify by diabetes and take 2/3 for training. This will leave 20 diabetic patients in the test set, so we are at the quite low end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(df,stratify=df[\"diabetes\"], train_size=.66, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f064f37",
   "metadata": {},
   "source": [
    "# Allocate a QLattice\n",
    "The actual QLattice is a quantum simulator that runs on Abzu's hardware, but we can allocate one to use for our analysis with a single line of code. Hopefully the following line will get us one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8af1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql = feyn.connect_qlattice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9644f9",
   "metadata": {},
   "source": [
    "# Resetting and reproducability\n",
    "The QLattice has the potential to store learnings between sessions to enable transfer of learning and federated learning. This is not possible with Community QLattices, since a new one gets allocated whenever we run the notebook, so it is not strictly necessary to call the reset function on our new QLattice. \n",
    "\n",
    "But the reset function also allows us to provide a random seed, which will ensure that we get the same results every time we run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql.reset(random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179093b2",
   "metadata": {},
   "source": [
    "\n",
    "# Search for the best model\n",
    "\n",
    "We are now ready to instruct the QLattice to search for the best mathematical model to explain the data. Here we use the high-level convenience function that does everything with sensible defaults: https://docs.abzu.ai/docs/guides/essentials/auto_run.html.\n",
    "\n",
    "For more detailed control, we could use the primitives: https://docs.abzu.ai/docs/guides/primitives/using_primitives.html\n",
    "\n",
    "NOTE: This will take a minute to complete. It involves work done on the QLattice machine remotely as well as in the local notebook. The part that runs locally is slowing things down because of the limited CPU resources on Kaggle. Running the same on my machine locally only takes 10 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b17e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ql.auto_run(train, output_name=\"diabetes\", kind=\"classification\", max_complexity=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f783376",
   "metadata": {},
   "source": [
    "# A quite simple model\n",
    "We have ended up with a model that uses only two features, age and glucose. That is quite minimal, and impressive if it works well. \n",
    "\n",
    "# Evaluate the performance of the model\n",
    "Lets look at the ROC curves of the model on the training and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].plot_roc_curve(train, label=\"Training data\")\n",
    "models[0].plot_roc_curve(test, label=\"Test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f7008",
   "metadata": {},
   "source": [
    "# Seems good\n",
    "With only two features we get an AUC of .94 on the test data. This is pretty much exactly thee same as the performance on the training data, indicating that the model generalises very well. This is consistent with other findings, such as for example this research paper:\n",
    "[Symbolic regression outperforms other models for small data sets](https://arxiv.org/abs/2103.15147)\n",
    "\n",
    "Let's have a look at the actual mathematical expression found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2343cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].sympify(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ce861",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "Finally, let's compare it to the usual model methods, random forest, gradient boosting and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = feyn.reference.RandomForestClassifier(train, target=\"diabetes\")\n",
    "gb = feyn.reference.GradientBoostingClassifier(train, target=\"diabetes\")\n",
    "lr = feyn.reference.LogisticRegressionClassifier(train, target=\"diabetes\", max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4624ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.plot_roc_curve(test, label=\"Random Forest\")\n",
    "gb.plot_roc_curve(test, label=\"Gradient Boosting\")\n",
    "lr.plot_roc_curve(test, label=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464150a9",
   "metadata": {},
   "source": [
    "# Pretty consistent\n",
    "All the four models curiously perform about equally well. The unique property of the QLattice is really that it is able to explain the data with the use of only two features in a fairly straightforward mathematical equation.\n",
    "\n",
    "# Conclusion\n",
    "Using the QLattice for symbolic regression, we were able to find a model that predicts diabetes in this dataset with the same accuracy as the usual black-box machine learning techniques.\n",
    "\n",
    "A simple result such as this one will have much more clinical credibility than a black-box model, and will also help medical researchers understand what actually drives diabetes.\n",
    "\n",
    "Note though, that the findings are quite limited by the small size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8566e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
