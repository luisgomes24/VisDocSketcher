{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa4a3d",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a92d9a",
   "metadata": {},
   "source": [
    "## \"Modelo preentrenado para su afinado en un dataset de clasificación de imágenes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fcc4e8",
   "metadata": {},
   "source": [
    "Para la realización del siguiente trabajo ha sido necesario un *dataset* proporcionado por el profesor en la tarea propuesta.\n",
    "Dicho *dataset* consta de una serie de imágenes de tres categorías distintas de osos: oso negro, que llamaremos ***black***, pardo, que llamaremos ***grizzly*** y osito de peluche que llamaremos ***teddy***.\n",
    "\n",
    "Vamos a utilizar una red neuronal convonucional también conocida como CNN (sus siglas en inglés). Se van a realizar una serie de tests de entrenamiento con el fin de localizar el modelo óptimo. Para ello, van a ser estudiados la red base, los optimizadores, el *learning rate* y las funciones de activación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acf08f",
   "metadata": {},
   "source": [
    "Comenzamos importando las liberías que vamos a necesitar para la realización de nuestro trabajo, así como una línea de código que nos permita de manera sencilla \"resetear\" el estado del *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "os.environ [\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f67a8",
   "metadata": {},
   "source": [
    "Posteriormente indicamos el directorio en el que se encuentran las dos carpetas con las que vamos a trabajar y en las que están las imágenes, la carpeta de entrenamiento *(train)* y la de test *(test)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4edf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"C:\\\\Users\\\\gemma\\\\Documents\\\\osos\\\\\"\n",
    "test = \"C:\\\\Users\\\\gemma\\\\Documents\\\\osostest\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f0696",
   "metadata": {},
   "source": [
    "A modo de presentación, decidimos extraer algunas de las imágenes para poder identificar cada uno de los tipos de osos de los que trata el presente trabajo. Se establece asímismo su tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenes (path, row = 1, col = 1):\n",
    "    imagen = tf.keras.preprocessing.image\n",
    "    imges = len (os.listdir (path))\n",
    "    for i in range (row):\n",
    "        for j in range (col):\n",
    "            num = str (rnd.randint (0, imges - 1)); num = num.zfill (8)\n",
    "            img = imagen.load_img (path + num + \".jpg\"); img = img.resize ((224,224))\n",
    "    plt.imshow (img) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c01fc",
   "metadata": {},
   "source": [
    "Concretamos el directorio en el que se encuentra cada tipo de oso para poder importar una imagen de cada uno de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a75fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\gemma\\\\Documents\\\\osos\\\\black\\\\\" \n",
    "blackimages = imagenes (path)\n",
    "print (\"Este oso es un black:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\gemma\\\\Documents\\\\osos\\\\grizzly\\\\\" \n",
    "grizzlyimages = imagenes (path)\n",
    "print (\"Este oso es un grizzly:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\gemma\\\\Documents\\\\osos\\\\teddys\\\\\" \n",
    "teddysimages = imagenes (path)\n",
    "print (\"Este oso es de tipo teddy:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7e9eb",
   "metadata": {},
   "source": [
    "Proseguimos con la presentación de las funciones que van a ser esenciales en nuestro proyecto. Iniciamos con la definición de la función para el modelo base de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffed758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo (path, bmod = \"VGG16\", inc = False, wth = \"imagenet\",\\\n",
    "              act1 = \"relu\", act2 = \"softmax\", summary = False):\n",
    "    tipos = len (os.listdir (path))\n",
    "    primer_model, procesado_previo = fbase (bmod, inc, wth)\n",
    "    capas = primer_model.output\n",
    "    capa1 = tf.keras.layers.GlobalAveragePooling2D () (capas)\n",
    "    capa2 = tf.keras.layers.Dense (512, activation = act1) (capa1) \n",
    "    fin_capas = tf.keras.layers.Dense (tipos, activation = act2) (capa2) \n",
    "    model = tf.keras.models.Model (inputs = primer_model.input, outputs = fin_capas)\n",
    "    for layer in model.layers [:len (primer_model.layers)]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers [len (primer_model.layers):]:\n",
    "        layer.trainable = True\n",
    "    if summary == True:\n",
    "        model.summary ()\n",
    "    return model, procesado_previo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372831ad",
   "metadata": {},
   "source": [
    "Han sido escogidos tres modelos de CNN con los que vamos a trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbase (bmod, inc, wth):\n",
    "    if bmod == \"MNet\":\n",
    "        Ma = tf.keras.applications.MobileNetV2\n",
    "        primer_model = Ma (weights = wth,include_top = inc, input_shape = (224, 224, 3))\n",
    "        procesado_previo = tf.keras.applications.mobilenet_v2.preprocess_input \n",
    "    elif bmod == \"Vgg19\":\n",
    "        Ma = tf.keras.applications.VGG19\n",
    "        primer_model = Ma (weights = wth,include_top = inc)\n",
    "        procesado_previo = tf.keras.applications.vgg19.preprocess_input \n",
    "    else:\n",
    "        Ma = tf.keras.applications.VGG16\n",
    "        primer_model = Ma (weights = wth,include_top = inc)\n",
    "        procesado_previo = tf.keras.applications.vgg16.preprocess_input\n",
    "    return primer_model, procesado_previo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba477c2e",
   "metadata": {},
   "source": [
    "Para hacer un cálculo del tiempo se utiliza la clase *TimeHistory (https://keras.io/callbacks/)*, que como se indica en el *link* desde el cual se ha encontrado la información acerca de dicha clase, es la manera más sencilla para calcularlo después de cada computación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory (tf.keras.callbacks.Callback):\n",
    "    def on_train_begin (self, logs = {}):\n",
    "        self.times = []\n",
    "    def on_epoch_begin (self, batch, logs = {}):\n",
    "        self.epoch_time_start = time.time()\n",
    "    def on_epoch_end (self, batch, logs = {}):\n",
    "        self.times.append (time.time () - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887651d",
   "metadata": {},
   "source": [
    "Vamos a utilizar la puntuación que obtengan en el test como un parámetro que nos permita medir cada modelo de otra manera, puntuándolo mejor o peor en función de los aciertos o fallos que vaya teniendo. Debido a que una de las categorías se considera claramente diferenciable, se le otorgará una puntuación de -7 puntos sobre 10 en el caso de confundirla con una de las otras dos. Cuando en cambio el error sea por confundir los osos *black* y *grizzly*, la penalización será menor, de tres puntos sobre diez (como vamos a ver más abajo).\n",
    "Las imágenes de la carpeta osostest han sido seleccionadas aleatoriamente de internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6e6ef",
   "metadata": {},
   "source": [
    "Con la siguiente función se da el puntaje y se establece el porcentaje de acierto en la identificación de los osos de la carpeta osostest. Hemos mencionado que ocurre en caso de cometer un error, pero en caso de acierto se suma un punto. Dicha carpeta consta de 24 imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_test (path, model, genera_train, procesado_previo, tamano = (224, 224), num_imagenes = 24.0):\n",
    "    res = [\"black\", \"grizzly\", \"teddys\",]\n",
    "    list_images, resultado = random_test (num_imagenes); puntos = 0.0\n",
    "    clase = {v:k for k, v in genera_train.class_indices.items ()}\n",
    "    imagen = tf.keras.preprocessing.image\n",
    "    for i in range (len (list_images)):\n",
    "        img = imagen.load_img (path + list_images [i]).resize (tamano)\n",
    "        data = procesado_previo (np.expand_dims (imagen.img_to_array (img), 0))\n",
    "        predic = model.predict (data)\n",
    "        pre = clase [np.argmax (predic)]\n",
    "        if pre == resultado [i]:\n",
    "            puntos += 1.0\n",
    "            print (\"Test número %i : Tipo de oso = %s -> Solución = %s (+1 pts) \\n\" % (i+1, pre, resultado [i]))\n",
    "        else:\n",
    "            if (pre == res [2] and (resultado [i] == res [0] or resultado [i] == res [0])) or \\\n",
    "                ((pre == res [0] or pre == res [1])  and resultado [i] == res [2]):\n",
    "                puntos -= 0.70\n",
    "                print (\"Test número %i : Tipo de oso = %s -> Solución = %s (-0.75 pts) \\n\" % (i+1, pre, resultado [i]))\n",
    "            else:\n",
    "                puntos -= 0.30\n",
    "                print (\"Test número %i : Tipo de oso = %s -> Solución = %s (-0.25 pts) \\n\" % (i+1, pre, resultado [i]))\n",
    "    print (\"_ _ _ _ _\\n\")\n",
    "    porcentaje = puntos * 100.0/ num_imagenes\n",
    "    print (\"Puntaje total = %.2f   Nivel de acierto en porcentaje -> %.1f\" % (puntos, porcentaje))\n",
    "    return porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test (num_imagenes):\n",
    "    random = []; resultado = []; nume_l = []\n",
    "    conteo = 0\n",
    "    while conteo < num_imagenes:\n",
    "        n = rnd.randint (1, num_imagenes)\n",
    "        if n not in nume_l:\n",
    "            random.append (\"test%i.jpg\" %n)\n",
    "            if n <= 8:\n",
    "                resultado.append (\"black\")\n",
    "            elif n > 8 and n <= 16:\n",
    "                resultado.append (\"grizzly\")\n",
    "            elif n >= 17 and n <= 24:\n",
    "                resultado.append (\"teddys\")\n",
    "            conteo += 1\n",
    "            nume_l.append (n)\n",
    "    return random, resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acffd6",
   "metadata": {},
   "source": [
    "Se introducen las medidas de *crossentropy* y las métricas de *accuracy* en la red neuronal. Información obtenida de: *https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy* y *https://www.freecodecamp.org/news/how-to-build-your-first-neural-network-to-predict-house-prices-with-keras-f8db83049159/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba98eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceso_train (model, genera_train, opt = \"Adam\",\\\n",
    "                  lr = 0.001, metrics = [\"accuracy\"], epochs = 5):\n",
    "    optimizer = optimizador (opt, lr)\n",
    "    model.compile (optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = metrics)\n",
    "    step_size_train = genera_train.n// genera_train.batch_size\n",
    "    time_callback = TimeHistory ()\n",
    "    data_model = model.fit_generator (generator = genera_train,\\\n",
    "                                    steps_per_epoch = step_size_train,\\\n",
    "                                    epochs = epochs, callbacks = [time_callback])\n",
    "    times = time_callback.times\n",
    "    return data_model, times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceac553",
   "metadata": {},
   "source": [
    "La siguiente función procesa las imágenes de la carpeta *train* (o entrenamiento) con el fin de llegar a la optimización para el modelo base. Utilizamos los valores que hemos ido utilizando a lo largo de la asignatura en las prácticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3133962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_p (path, procesado_previo, tamano = (224, 224), batch_size = 2): \n",
    "    imagen = tf.keras.preprocessing.image\n",
    "    data_train = imagen.ImageDataGenerator (preprocessing_function = procesado_previo)\n",
    "    genera_train = data_train.flow_from_directory (path, target_size = tamano,\\\n",
    "                                                      color_mode = \"rgb\",\\\n",
    "                                                      batch_size = batch_size,\\\n",
    "                                                      class_mode = \"categorical\",\\\n",
    "                                                      shuffle = True)  \n",
    "    return genera_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7138b0",
   "metadata": {},
   "source": [
    "La siguiente función utiliza dos algoritmos de optimización de parámetros. Hemos utilizado el de *Adam* y *RMSprop*. Información obtenida de: *ttps://keras.io/optimizers/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94008f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizador (opt, lr):\n",
    "    if opt == \"RMS\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop (learning_rate = lr)\n",
    "    else :\n",
    "        optimizer = tf.keras.optimizers.Adam (learning_rate = lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ddc15",
   "metadata": {},
   "source": [
    "Vamos a relacionar también para cada modelo dos medidas o parámetros: la exactitud que tiene el modelo obtenido y el tiempo que ha tardado en entrenarse con las siguientes líneas de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278755ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cr (model_fit, times):\n",
    "    nup = len (model_fit.history [\"accuracy\"])\n",
    "    n_row = [\"epoch%i\" %i for i in range (1, nup + 1)]\n",
    "    data = pd.concat ([pd.DataFrame (model_fit.history, index = n_row),\n",
    "                     pd.DataFrame (times, index = n_row)] , axis = 1, sort = False)\n",
    "    data = data.rename (columns = {0: \"time\"})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa63f56",
   "metadata": {},
   "source": [
    "Como se puede observar, en data_cr hemos hecho uso de la librería *pandas* para crear un *dataframe* que relacionase las dos medidas que acabamos de mencionar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5a715",
   "metadata": {},
   "source": [
    "**MODELOS PREENTRENADOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31e23f",
   "metadata": {},
   "source": [
    "Vamos a utilizar cinco *epoch* para cada modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdd = [\"Vgg16\", \"Vgg19\", \"MNet\"]\n",
    "def bbdd_comparacion (bbdd):\n",
    "    model, procesado_previo = modelo (train, bmod = bbdd, summary = True)\n",
    "    genera_train = train_p (train, procesado_previo)\n",
    "    fit, times = proceso_train (model, genera_train, epochs = 5)\n",
    "    data = data_cr (fit, times)\n",
    "    puntuacion = imagen_test (test, model, genera_train, procesado_previo)\n",
    "    return data, puntuacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804fc5e",
   "metadata": {},
   "source": [
    "Para ver cómo funciona la red neuronal *VGG16* ejecutamos la siguiente línea de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b98951",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_vgg16, puntos_vgg16 = bbdd_comparacion (bbdd [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0e34d",
   "metadata": {},
   "source": [
    "Podemos ver que son 240 imágenes en total que pertenecen a tres clases. También podemos apreciar las capas, su número y cómo se agrupan, el número de nodos, el número total de parámetros, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ab8ee",
   "metadata": {},
   "source": [
    "A continuación vemos cómo se comporta la red neuronal *VGG19*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ae9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_vgg19, puntos_vgg19 = bbdd_comparacion (bbdd [1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf648f",
   "metadata": {},
   "source": [
    "Y finalmente, el último tipo de red elegida es la *MobileNet V2*. Información obtenida de: *https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_mnet, puntos_mnet = bbdd_comparacion (bbdd [2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507fce1",
   "metadata": {},
   "source": [
    "Comparamos los resultados obtenidos en los modelos mediante la realización de un gráfico. Aunque, mirando el puntaje, podemos ver que las tres tienen muy buena puntuación, especialmente la *VGG19* y la *MNet*, que llegan a un nivel de acierto total. En este caso, el gráfico es especialmente importante, ya que añadiendo el tiempo que ha tardado en computarse, esto nos va a ayudar a tomar una decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot (osos_vgg16 [\"accuracy\"] * 100/ osos_vgg16 [\"time\"],'--o',\\\n",
    "         color = \"Blue\" , label = bbdd [0])\n",
    "plt.plot (osos_vgg19 [\"accuracy\"] * 100/ osos_vgg19 [\"time\"],'--o',\\\n",
    "         color = \"Red\", label = bbdd [1])\n",
    "plt.plot (osos_mnet [\"accuracy\"] * 100/ osos_mnet [\"time\"],'--o',\\\n",
    "         color = \"Aqua\", label = bbdd [2])\n",
    "plt.legend (loc = 0)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01ef9e",
   "metadata": {},
   "source": [
    "Vemos que aunque los tres modelos tienen el mismo porcentaje de acierto, observando el gráfico obtenido, vamos a considerar el último tipo de red neuronal, la *MobileNet V2*, como la red elegida para realizar nuestro trabajo por ser (dentro de los buenos resultados de todas las redes), la que mejores resultados ha dado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89352fe5",
   "metadata": {},
   "source": [
    "**OPTIMIZADORES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c946467",
   "metadata": {},
   "source": [
    "A continuación procederemos a evaluar los optimizadores ya comentados con la red neuronal elegida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizadores = [\"Adam\", \"RMS\"]\n",
    "def optimizadores_comparados (optimizer):\n",
    "    model, procesado_previo = modelo (train, bmod = \"MNet\")\n",
    "    genera_train = train_p (train, procesado_previo)\n",
    "    fit, times = proceso_train (model, genera_train, opt = optimizer, epochs = 5)\n",
    "    data = data_cr (fit, times)\n",
    "    puntuacion = imagen_test (test, model, genera_train, procesado_previo)\n",
    "    return data, puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_adam, puntos_adam = optimizadores_comparados (optimizadores [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_rms, puntos_rms = optimizadores_comparados (optimizadores [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520be3cd",
   "metadata": {},
   "source": [
    "Comparamos los dos algoritmos de optimización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (osos_adam [\"accuracy\"] * 100/ osos_adam [\"time\"],'--o',\\\n",
    "         color = \"Blue\" , label = optimizadores [0])\n",
    "plt.plot (osos_rms [\"accuracy\"] * 100/ osos_rms [\"time\"],'--o',\\\n",
    "         color = \"Red\", label = optimizadores [1])\n",
    "plt.legend (loc = 0)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfc19c",
   "metadata": {},
   "source": [
    "Y, observando el gráfico obtenido, concretamente la métrica de precisión o *accuracy*, el algoritmo elegido es el de Adam, ya que es el que tiene una subida sostenida, por lo que es con el que continuaremos trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df5847",
   "metadata": {},
   "source": [
    "**LEARNING RATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828190a7",
   "metadata": {},
   "source": [
    "Analizamos el *learning rate*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0197b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = [0.001, 0.01]\n",
    "def lr_comparado (lr):\n",
    "    model, procesado_previo = modelo (train, bmod = \"MNet\")\n",
    "    genera_train = train_p (train, procesado_previo, batch_size = 5)\n",
    "    fit, times = proceso_train (model, genera_train, opt = \"Adam\", epochs = 5, lr = lr)\n",
    "    data = data_cr (fit, times)\n",
    "    puntuacion = imagen_test (test, model, genera_train, procesado_previo)\n",
    "    return data, puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_lr2, puntos_lr2 = lr_comparado (learningrate [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_lr3, puntos_lr3 = lr_comparado (learningrate [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = [\"LR2\", \"LR3\"]\n",
    "plt.plot (osos_lr2 [\"accuracy\"] * 100/ osos_lr2 [\"time\"],'--o',\\\n",
    "         color = \"Blue\", label = str (rate [0]))\n",
    "plt.plot (osos_lr3 [\"accuracy\"] * 100/ osos_lr3 [\"time\"],'--o',\\\n",
    "         color = \"Red\", label = str (rate [1]))\n",
    "plt.legend (loc = 0)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a238f",
   "metadata": {},
   "source": [
    "Podemos comprobar cómo el learning rate más bajo, el 3, es más efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4b8ac",
   "metadata": {},
   "source": [
    "**FUNCIONES DE ACTIVACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98afc8",
   "metadata": {},
   "source": [
    "Finalmente procedemos a estudiar la combinación de varios tipos de funciones de activación, pero solamente para las últimas capas, ya que el resto han sido elegidos en los análisis ya realizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d747ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "funciondeactivacion = [[\"relu\", \"softmax\"], [\"tanh\", \"softmax\"]]\n",
    "def factiv_comparadas (act1, act2):\n",
    "    model, procesado_previo = modelo (train, bmod = \"MNet\", act1 = act1, act2 = act2)\n",
    "    genera_train = train_p (train, procesado_previo, batch_size = 5)\n",
    "    fit, times = proceso_train (model, genera_train, epochs = 5, lr = 1E-3)\n",
    "    data = data_cr (fit, times)\n",
    "    puntuacion = imagen_test (test, model, genera_train, procesado_previo)\n",
    "    return data, puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_act1, puntos_act4 = factiv_comparadas (funciondeactivacion [0][0],\\\n",
    "                                             funciondeactivacion [0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "osos_act4, puntos_act1 = factiv_comparadas (funciondeactivacion [1][0],\\\n",
    "                                             funciondeactivacion [1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab831e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "activa = [\"relu+softmax\", \"tanh+softmax\"]\n",
    "plt.plot (osos_act1 [\"accuracy\"] * 100/ osos_act1 [\"time\"],'--o',\\\n",
    "         color = \"Blue\" , label = activa [0])\n",
    "plt.plot (osos_act4 [\"accuracy\"] * 100/ osos_act4 [\"time\"],'--o',\\\n",
    "         color = \"Red\", label = activa [1])\n",
    "plt.legend (loc = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bcc4e",
   "metadata": {},
   "source": [
    "Gracias al gráfico vemos como *tanh+softmax* constituye la mejor combinación de activadores para que el modelo tenga éxito. Hemos decidido obviar los activadores que daban una tasa de acierto nula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0976e",
   "metadata": {},
   "source": [
    "Hemos medido el rendimiento del test a través de los parámetros de *accuracy*, tiempo y puntaje en cada test. Comprobamos que el resto de indicadores medidos hacen que la exactitud del modelo no varíe en exceso con la excepción de la eleción de las funciones de activación, que es de gran importancia.\n",
    "\n",
    "Finalmente, podemos pasar a recordar que el modelo de red neuronal elegido ha sido la ***MobileNet V2***, el tipo de optimizador **Adam**, el learning rate el **3** y la función de activación ***tanh+softmax***."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
