{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d115769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required Libraries\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sn.set()\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelBinarizer, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
    "from xgboost import XGBClassifier # XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications import ResNet101 # ResNet 101\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    '''\n",
    "        parameters\n",
    "        ----------\n",
    "        path : input path of the images\n",
    "        \n",
    "        returns\n",
    "        -------\n",
    "        loadedImages : list of loaded images \n",
    "    '''\n",
    "    sample = []\n",
    "    \n",
    "    for filename in glob.glob(path):\n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        img = skimage.transform.resize(img, (224, 224, 3))\n",
    "        IMG = np.array(img)\n",
    "        sample.append(IMG)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path1 = 'train/NonDemented/*.jpg' \n",
    "train_path2 = 'train/VeryMildDemented/*.jpg'\n",
    "train_path3 = 'train/MildDemented/*.jpg'\n",
    "train_path4 = 'train/ModerateDemented/*.jpg'\n",
    "\n",
    "test_path1 = 'test/NonDemented/*.jpg' \n",
    "test_path2 = 'test/VeryMildDemented/*.jpg'\n",
    "test_path3 = 'test/MildDemented/*.jpg'\n",
    "test_path4 = 'test/ModerateDemented/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ND = loadImages(train_path1)\n",
    "train_VMD = loadImages(train_path2)\n",
    "train_MID = loadImages(train_path3)\n",
    "train_MOD = loadImages(train_path4)\n",
    "\n",
    "test_ND = loadImages(test_path1)\n",
    "test_VMD = loadImages(test_path2)\n",
    "test_MID = loadImages(test_path3)\n",
    "test_MOD = loadImages(test_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CREATION OF DATASETS\n",
    "\n",
    "df_train_ND = pd.DataFrame({'image':train_ND, 'label': 'ND'})\n",
    "df_train_VMD = pd.DataFrame({'image':train_VMD, 'label': 'VMD'})\n",
    "df_train_MID = pd.DataFrame({'image':train_MID, 'label': 'MID'})\n",
    "df_train_MOD = pd.DataFrame({'image':train_MOD, 'label': 'MOD'})\n",
    "\n",
    "df_test_ND = pd.DataFrame({'image':test_ND, 'label': 'ND'})\n",
    "df_test_VMD = pd.DataFrame({'image':test_VMD, 'label': 'VMD'})\n",
    "df_test_MID = pd.DataFrame({'image':test_MID, 'label': 'MID'})\n",
    "df_test_MOD = pd.DataFrame({'image':test_MOD, 'label': 'MOD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = [df_train_ND, df_train_VMD, df_train_MID, df_train_MOD, df_test_ND, df_test_VMD, df_test_MID, df_test_MOD]\n",
    "final_data = pd.concat(final_data)\n",
    "\n",
    "print(\"Entire data size:\",final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% TRAIN LABEL SEPARATION\n",
    "\n",
    "train_data = final_data['image']\n",
    "labels = final_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% LOOKING AT THE AMOUNT OF ITEMS PER CLASS \n",
    "\n",
    "print(\"Labels Count:\",Counter(np.array(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ENCODING THE LABELS\n",
    "onehot = LabelEncoder()\n",
    "labels = onehot.fit_transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48397f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SPLITTING INTO TRAIN AND TEST SET, TRAIN SET WILL BE FURTHER SPLIT INTO TRAIN AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = labels,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)\n",
    "\n",
    "print('length X_train:', len(X_train))\n",
    "print('length y_train:', len(y_train))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1775528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72208424",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= np.empty((len(X_train),X_train[0].shape[0],X_train[0].shape[1],X_train[0].shape[2]))\n",
    "for i,x in enumerate(X_train):\n",
    "    x_train[i]=X_train[i]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208335a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test= np.empty((len(X_test),X_test[0].shape[0],X_test[0].shape[1],X_test[0].shape[2]))\n",
    "for i,x in enumerate(X_test):\n",
    "    x_test[i]=X_test[i]\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266884e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327caf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(x_train)\n",
    "test_features=model_feat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Train and validation accuracy\n",
    "x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features,y_train,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = y_train,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc021178",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=test_features,y_test\n",
    "\n",
    "print('length X_train:', len(x_train_acc))\n",
    "print('length y_train:', len(y_train_acc))\n",
    "\n",
    "print('length X_val:',  len(x_val_acc))\n",
    "print('length y_val:', len(y_val_acc))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e85613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train= sentiment_fit.predict(X_train)\n",
    "    y_pred_val = sentiment_fit.predict(X_val)\n",
    "    y_pred_test = sentiment_fit.predict(X_test)\n",
    "    \n",
    "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
    "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
    "    train_confusion_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "    \n",
    "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
    "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
    "    val_confusion_matrix = confusion_matrix(y_val,y_pred_val)\n",
    "    \n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
    "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),4) \n",
    "    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Train Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(train_accuracy))\n",
    "    print(\"F1_score : {}\".format(train_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(train_kappa))\n",
    "    print(\"Recall : {}\".format(train_recall))\n",
    "    print(\"Precision : {}\".format(train_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(train_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Validation Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(val_accuracy))\n",
    "    print(\"F1_score : {}\".format(val_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(val_kappa))\n",
    "    print(\"Recall : {}\".format(val_recall))\n",
    "    print(\"Precision : {}\".format(val_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(val_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Test Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall : {}\".format(test_recall))\n",
    "    print(\"Precision : {}\".format(test_precision))\n",
    "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "        \"K Nearest Neighbour Classifier\",\n",
    "        'SVM',\n",
    "        \"Random Forest Classifier\",\n",
    "        \"AdaBoost Classifier\", \n",
    "        \"XGB Classifier\",\n",
    "         ]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "        ]\n",
    "\n",
    "zipped_clf = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print(\"Fitting {} on features \".format(n))\n",
    "        #print(c)\n",
    "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
