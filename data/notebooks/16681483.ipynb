{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eeceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87053b8",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "\n",
    "The Kreuz-Kreis-Plus-Minus-Gartenhag.csv dataset contains 28 x 28 pixel images of all black and white #, +, -, o and x handwritten characters.\n",
    "The first column of the dataset contains the label of the image as integer:\n",
    "\n",
    "- 0 equals #\n",
    "- 1 equals +\n",
    "- 2 equals -\n",
    "- 3 equals o\n",
    "- 4 equals x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/images/Kreuz-Kreis-Plus-Minus-Gartenhag.csv\", sep=',', header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64ca58",
   "metadata": {},
   "source": [
    "After reading, check if there are any null values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ef77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e860a",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "In order to train different models, lets split the data set into x (all columns which contain pixel data) and y (the label).\n",
    "\n",
    "After that, split the data into a train and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d01607",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, df.columns != '0']\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y) # , train_size=11500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001f868",
   "metadata": {},
   "source": [
    "## Compare different algorithms\n",
    "\n",
    "Next up, I'm going to compare the following algorithms:\n",
    "\n",
    "- LogisticRegression\n",
    "- RandomForestClassifier\n",
    "- KNeighborsClassifier\n",
    "- Support Vector Machine\n",
    "- GaussianNB\n",
    "- XGBClassifier\n",
    "\n",
    "Im going to use 5-fold cross validation on the training set.\n",
    "\n",
    "In addition I'm going to print a confusion matrix for every model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b265603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "models = [\n",
    "    ('LogReg', LogisticRegression()),\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', SVC()),\n",
    "    ('GNB', GaussianNB()),\n",
    "    ('XGB', XGBClassifier())\n",
    "]\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'] # , 'roc_auc'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "    cv_results = model_selection.cross_validate(model, x_train.values, y_train.values, cv=kfold, scoring=scoring, error_score=\"raise\")\n",
    "    clf = model.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    this_df = pd.DataFrame(cv_results)\n",
    "    this_df['model'] = name\n",
    "    dfs.append(this_df)\n",
    "    \n",
    "    confusion_matrix = plot_confusion_matrix(model, x_test, y_test)\n",
    "    confusion_matrix.ax_.set_title(name + ':')\n",
    "\n",
    "final = pd.concat(dfs, ignore_index=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544efb2",
   "metadata": {},
   "source": [
    "## Collect metrics\n",
    "\n",
    "Next up I'm going to collect metrics by using the bootstrap method.\n",
    "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_fit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Fit and Score Time')\n",
    "plt.savefig('./benchmark_models_time.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b45e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(set(results_long_nofit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_metrics = list(set(results_long_fit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[time_metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af843199",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the experiment above, the Random Forest Classifier provides the best results."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
