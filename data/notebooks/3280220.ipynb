{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c32f20",
   "metadata": {},
   "source": [
    "# ** What do we plan to do here? **\n",
    "* Read the dataset\n",
    "* Analyze the data for missing values and outliers\n",
    "* Perform uni-variate analysis\n",
    "* Perform bi-variate analysis\n",
    "* We will not do any feature engineering in this particular problem\n",
    "* We will create a lot of visualizations to do a thorough analysis of the problem at hand\n",
    "* Pick a list of algorithms which we can choose to apply in this case\n",
    "* Pick the best algorithm\n",
    "* Score the algorithm based on the evaluation criteria\n",
    "* Fine tune algorithms to achieve the best possible value of the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1) Read the dataset into the notebook\n",
    "cfd=pd.read_csv(\"../input/creditcard.csv\")\n",
    "cfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2) Print the shape of the data\n",
    "cfd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3) List out the feature variables and their data-types\n",
    "cfd.iloc[:,:30].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cb92f",
   "metadata": {},
   "source": [
    "### Q6) Treat the null variables. What is your strategy? Why did you use that? What other strategies could be taken? Explain\n",
    "There are no null variables in this data set and if there were any first we have to check the number of null variables and if possible or a particular feature is important it must be replaced with mean or median values and this can be done only if the number of missing values  are less. If the numbers are very high then those values can be removed using dropna() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d838a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q7) Check for outliers in the feature variables\n",
    "fig= plt.figure(figsize=(15,100))\n",
    "cols = cfd.columns\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4)\n",
    "for i in range(1,30):\n",
    "    ax = fig.add_subplot(10,3,i)\n",
    "    sns.boxplot(x=cfd[cols[i-1]])\n",
    "    plt.title(cols[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c56d50",
   "metadata": {},
   "source": [
    "### Q8) Treat outliers. What is your strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd.iloc[:,:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = cfd.iloc[:,:30].quantile(0.25)\n",
    "q3 = cfd.iloc[:,:30].quantile(0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b466d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = q3 - q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = q1 -(1.5 * iqr) \n",
    "upper_bound = q3 +(1.5 * iqr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((cfd< (q1 - 1.5 * iqr)) |(cfd > (q3 + 1.5 * iqr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd1 = cfd[~((cfd< (q1 - 1.5 * iqr)) |(cfd > (q3 + 1.5 * iqr))).any(axis=1)]\n",
    "cfd1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc0467",
   "metadata": {},
   "source": [
    "### Q9) Pick each one of the feature variables and perform univariate analysis (be as creative as possible in your analysis)\n",
    "* ### Q9.1) Visualize the shape of the distribution of data.Is every feature variable normally distributed? Why is normal distribution important for data?\n",
    "* ### Q9.2) Is the data distribution skewed? If highly skewed,do you still find outliers which you did not treat?\n",
    "* ### Q9.3) Draw box and whiskers plot of each of the feature variables\n",
    "* ### Q9.4) How do the distributions look in terms of variation? Which features are widely spread and which are kind of concentrated towards the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd1.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15,100))\n",
    "cols = cfd1.columns\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4)\n",
    "for i in range(1,30):\n",
    "    ax = fig.add_subplot(10,3,i)\n",
    "    sns.boxplot(x=cfd1[cols[i-1]])\n",
    "    plt.title(cols[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7b4eb",
   "metadata": {},
   "source": [
    "### Q10) Pick the feature variables and perform bi-variate analysis (be as creative as possible)\n",
    "* ### Q10.1) Try creating correlation matrices. See if there are variables which are strongly or weakly related\n",
    "* ### Q10.2) Try build joint distribution charts\n",
    "* ### Q10.3) If there are variables showing high correlation, what corrective action is needed? Why is this a matter of concern? What if we do not treat the variables showing high degree of correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd2=cfd1.corr()\n",
    "cfd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(cfd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f82aa1",
   "metadata": {},
   "source": [
    "### Q11.1) What is the type of machine learning problem at hand? (Supervised or Unsupervised?) Why?\n",
    "### Q11.2) What is the category of the machine learning problem at hand? (Classification or Regression?) Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfc548",
   "metadata": {},
   "source": [
    "### Q12.1) Draw univariate plots for each of the feature variables, color each plotted point as red if the class value = 0 else green.\n",
    "### Q12.2) Which feature segregates the data the cleanest way? How would you calculate the misclassification rate?\n",
    "### Q12.3) Now take two features at a time, again color each plotted point as mentioned in 12.1. Calculate and comment on the misclassification rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da671581",
   "metadata": {},
   "source": [
    "### Q13.1) List down all the algorithms known to you which you think might be applicable in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f7a4a",
   "metadata": {},
   "source": [
    "### Q14) Pick each of the algorithm and perform the below steps : \n",
    "### Q14.1) Split your data between test, train and validation steps. Why 3 and not just test and train? \n",
    "### Q14.2) Build your model\n",
    "### Q14.3) List down the evaluation metrics you would use to evaluate the performance of the model?\n",
    "### Q14.4) Evaluate the model on training data\n",
    "### Q14.5) Predict the response variables for the validation test data\n",
    "### Q14.6) Evaluate the model on test data\n",
    "### Q14.7) How are the two scores? Are they significantly different? Are they the same? Is the test score better than training score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cfd1.iloc[:,:30]\n",
    "y = cfd1['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc98141",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c97d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9905e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
