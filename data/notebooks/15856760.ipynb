{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e00c6a1",
   "metadata": {},
   "source": [
    "### Same code with little variation in parameters and folds from my other notebook, Pleas check out that too [TPS March Lgbm with Optuna](https://www.kaggle.com/nishantdhingra/tps-march-lgbm-with-optuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70be6e2",
   "metadata": {},
   "source": [
    "* Binary Classification problem based on real life data\n",
    "* We have to predict probabilities and the metric is ROC-AUC\n",
    "* This is a sample notebook which gives beginner approach to the data and hyperparameter tuning using Optuna\n",
    "\n",
    "\n",
    "I'm a beginner in this field too, Please give suggestions to improove the score!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d734da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ee4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cd5bf",
   "metadata": {},
   "source": [
    "No null values!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c67cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f264859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in range(19):\n",
    "    le.fit(list(train['cat'+str(i)])+list(test['cat'+str(i)]))\n",
    "    train['cat'+str(i)] = le.transform(train['cat'+str(i)])\n",
    "    test['cat'+str(i)] = le.transform(test['cat'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,1:-1].values\n",
    "y = train.iloc[:,-1].values\n",
    "X_test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb161e87",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8956ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LGBMClassifier()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred_l = lg.predict_proba(X_dev)[:,1]\n",
    "roc_auc_score(y_dev,y_pred_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece6453",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(trial,data=X,target=y):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n",
    "    param = {\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 0.9),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0,1),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0, 0.1 ),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10,100),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n",
    "        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100),\n",
    "        'cat_l2': trial.suggest_int('cat_l2',1,20),\n",
    "        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n",
    "        \n",
    "        'metric': 'auc', \n",
    "        'random_state': 2021,\n",
    "        'n_estimators': 10000,\n",
    "        \n",
    "    }\n",
    "    model = LGBMClassifier(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n",
    "    \n",
    "    preds = model.predict_proba(test_x)[:,1]\n",
    "    \n",
    "    auc = roc_auc_score(test_y, preds)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a43bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(fun, n_trials=30)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cb9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_parallel_coordinate: interactively visualizes the hyperparameters and scores\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_slice: shows the evolution of the search. You can see where in the hyperparameter space your search\n",
    "# went and which parts of the space were explored more.\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize parameter importances.\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da2080",
   "metadata": {},
   "source": [
    "## Best Parameters found by Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_params['n_estimators'] = 10000\n",
    "best_params['cat_feature'] = [i for i in range(19)]\n",
    "best_params['random_state'] = 2021\n",
    "best_params['metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e8cfc",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7dfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in train.columns if col not in ['id','target'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros(X_test.shape[0])\n",
    "kf = StratifiedKFold(n_splits = 10 , random_state = 7 , shuffle = True)\n",
    "auc =[]\n",
    "n=0\n",
    "\n",
    "for tr_idx, test_idx in kf.split(train[columns], train['target']):\n",
    "    \n",
    "    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n",
    "    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n",
    "    \n",
    "    model = LGBMClassifier(**best_params)\n",
    "    \n",
    "    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=500,verbose=False)\n",
    "    \n",
    "    preds+=model.predict_proba(X_test)[:,1]/kf.n_splits\n",
    "    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n",
    "    print(n+1,auc[n])\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88385ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'target':preds})\n",
    "submission.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4c78d",
   "metadata": {},
   "source": [
    "# Please upvote the notebook if it helped in any way! \n",
    "\n",
    "## Have a nice day :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
