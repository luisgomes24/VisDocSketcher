{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6946f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47686e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/mnist_train.csv')\n",
    "test = pd.read_csv('../input/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36de00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train.label)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "print(train)\n",
    "test = np.array(test)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[:,1:]\n",
    "print(train_x)\n",
    "train_y = pd.get_dummies(train[:,0])\n",
    "print(train_y)\n",
    "test_x = test[:,1:]\n",
    "print(test_x)\n",
    "test_y = pd.get_dummies(test[:,0])\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "test_x = test_x.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = shuffle(train_x, train_y)\n",
    "test_X,test_y = shuffle(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56848ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 10\n",
    "learning_rate = 0.001 \n",
    "batch_size = 100\n",
    "\n",
    "n_input = 28\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME') # first 1 is for batch last 1 is for channels\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={}\n",
    "biases={}\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.truncated_normal([3,3,1,32])),\n",
    "    'wc2': tf.Variable(tf.truncated_normal([3,3,32,64])), \n",
    "    'wc3': tf.Variable(tf.truncated_normal([3,3,64,128]))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.truncated_normal([32])),\n",
    "    'bc2': tf.Variable(tf.truncated_normal([64])),\n",
    "    'bc3': tf.Variable(tf.truncated_normal([128]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv3, [-1, 4*4*128])\n",
    "    fc1 = tf.layers.dense(fc1, 100)\n",
    "    \n",
    "    out = tf.layers.dense(fc1, 10, activation=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf107d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init) \n",
    "\n",
    "for i in range(training_iters):\n",
    "    for batch in range(len(train_X)//batch_size):\n",
    "        batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "        batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                             y: batch_y})\n",
    "        \n",
    "        loss = sess.run(cost, feed_dict={x: batch_x,\n",
    "                                         y: batch_y})\n",
    "    predTest = sess.run(pred , feed_dict={x:test_X})\n",
    "\n",
    "    p = np.argmax(predTest,1)\n",
    "    t = np.argmax(np.array(test_y),1)\n",
    "\n",
    "    acc = accuracy_score(p,t)\n",
    "    print(\"Iter \"+str(i)+\" Out of\",training_iters , \" Loss= \",loss, \"acc=\",acc )\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "\n",
    "while(True):\n",
    "    r = np.random.randint(9000)\n",
    "    test_img = np.reshape(test_X[r], (28,28))\n",
    "    plt.imshow(test_img, cmap=\"gray\")\n",
    "    test_pred = sess.run(pred, feed_dict = {x:[test_X[r]]})\n",
    "    print(\"Model : I think it is :    \",np.argmax(test_pred))\n",
    "    plt.show()\n",
    "    \n",
    "    if input(\"Enter n to exit\")=='n':\n",
    "        break\n",
    "    clear_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = test_X[t!=p]\n",
    "wrong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eaf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=np.random.randint(200)\n",
    "plt.imshow(wrong[r].reshape((28,28)),cmap=\"gray\")\n",
    "test_pred_1=sess.run(pred, feed_dict = {x:[wrong[r]]})\n",
    "print(\"Model : I think it is :    \",np.argmax(test_pred_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac709ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(predTest,1)\n",
    "print(p)\n",
    "t = np.argmax(np.array(test_y),1)\n",
    "print(t)\n",
    "acc = accuracy_score(p,t)\n",
    "print(acc*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
