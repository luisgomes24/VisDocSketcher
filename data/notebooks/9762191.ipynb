{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d3472f",
   "metadata": {},
   "source": [
    "# Anchor Point Mystery\n",
    "\n",
    "Help me solve this mystery.\n",
    "\n",
    "During the ion challenge I found something interesting in the data that I still can't explain. Hopefully someone has a good explaination for it.\n",
    "\n",
    "My attempt during the competition was to shift the \"drift\" sections of the data to maximize these points. I was successful but it didn't end up providing any fruitful to my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/data-without-drift/train_clean.csv')\n",
    "test = pd.read_csv('../input/data-without-drift/test_clean.csv')\n",
    "tt = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_groups(tt):\n",
    "    tt.loc[(tt['time'] > 0) & (tt['time'] <= 10), 'sbatch'] = 0\n",
    "    tt.loc[(tt['time'] > 10) & (tt['time'] <= 50), 'sbatch'] = 1\n",
    "    tt.loc[(tt['time'] > 50) & (tt['time'] <= 60), 'sbatch'] = 2\n",
    "    tt.loc[(tt['time'] > 60) & (tt['time'] <= 100), 'sbatch'] = 3\n",
    "    tt.loc[(tt['time'] > 100) & (tt['time'] <= 150), 'sbatch'] = 4\n",
    "    tt.loc[(tt['time'] > 150) & (tt['time'] <= 200), 'sbatch'] = 5\n",
    "    tt.loc[(tt['time'] > 200) & (tt['time'] <= 250), 'sbatch'] = 6\n",
    "    tt.loc[(tt['time'] > 250) & (tt['time'] <= 300), 'sbatch'] = 7\n",
    "    tt.loc[(tt['time'] > 300) & (tt['time'] <= 350), 'sbatch'] = 8\n",
    "    tt.loc[(tt['time'] > 350) & (tt['time'] <= 400), 'sbatch'] = 9\n",
    "    tt.loc[(tt['time'] > 400) & (tt['time'] <= 450), 'sbatch'] = 10\n",
    "    tt.loc[(tt['time'] > 450) & (tt['time'] <= 500), 'sbatch'] = 11\n",
    "    # Test\n",
    "    tt.loc[(tt['time'] > 500) & (tt['time'] <= 510), 'sbatch'] = 12\n",
    "    tt.loc[(tt['time'] > 510) & (tt['time'] <= 520), 'sbatch'] = 13\n",
    "    tt.loc[(tt['time'] > 520) & (tt['time'] <= 530), 'sbatch'] = 14\n",
    "    tt.loc[(tt['time'] > 530) & (tt['time'] <= 540), 'sbatch'] = 15\n",
    "    tt.loc[(tt['time'] > 540) & (tt['time'] <= 550), 'sbatch'] = 16\n",
    "    tt.loc[(tt['time'] > 550) & (tt['time'] <= 560), 'sbatch'] = 17\n",
    "    tt.loc[(tt['time'] > 560) & (tt['time'] <= 570), 'sbatch'] = 18\n",
    "    tt.loc[(tt['time'] > 570) & (tt['time'] <= 580), 'sbatch'] = 19\n",
    "    tt.loc[(tt['time'] > 580) & (tt['time'] <= 590), 'sbatch'] = 20\n",
    "    tt.loc[(tt['time'] > 590) & (tt['time'] <= 600), 'sbatch'] = 21\n",
    "    tt.loc[(tt['time'] > 600) & (tt['time'] <= 610), 'sbatch'] = 22\n",
    "    tt.loc[(tt['time'] > 610) & (tt['time'] <= 630), 'sbatch'] = 23\n",
    "    tt.loc[(tt['time'] > 630) & (tt['time'] <= 650), 'sbatch'] = 24\n",
    "    tt.loc[(tt['time'] > 650) & (tt['time'] <= 670), 'sbatch'] = 25\n",
    "    tt.loc[(tt['time'] > 670) & (tt['time'] <= 700), 'sbatch'] = 26\n",
    "    return tt\n",
    "\n",
    "def had_drift(tt):\n",
    "    \"\"\"\n",
    "    I dentify if section had drift in the original dataset\n",
    "    \"\"\"\n",
    "    tt.loc[(tt['time'] > 0) & (tt['time'] <= 10), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 10) & (tt['time'] <= 50), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 50) & (tt['time'] <= 60), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 60) & (tt['time'] <= 100), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 100) & (tt['time'] <= 150), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 150) & (tt['time'] <= 200), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 200) & (tt['time'] <= 250), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 250) & (tt['time'] <= 300), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 300) & (tt['time'] <= 350), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 350) & (tt['time'] <= 400), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 400) & (tt['time'] <= 450), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 450) & (tt['time'] <= 500), 'drift'] = True\n",
    "    # Test\n",
    "    tt.loc[(tt['time'] > 500) & (tt['time'] <= 510), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 510) & (tt['time'] <= 520), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 520) & (tt['time'] <= 530), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 530) & (tt['time'] <= 540), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 540) & (tt['time'] <= 550), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 550) & (tt['time'] <= 560), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 560) & (tt['time'] <= 570), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 570) & (tt['time'] <= 580), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 580) & (tt['time'] <= 590), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 590) & (tt['time'] <= 600), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 600) & (tt['time'] <= 610), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 610) & (tt['time'] <= 630), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 630) & (tt['time'] <= 650), 'drift'] = True\n",
    "    tt.loc[(tt['time'] > 650) & (tt['time'] <= 670), 'drift'] = False\n",
    "    tt.loc[(tt['time'] > 670) & (tt['time'] <= 700), 'drift'] = False\n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ad801",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = had_drift(tt)\n",
    "tt = add_model_groups(tt)\n",
    "FILTER_TRAIN = '(time <= 47.6 or time > 48) and (time <= 364 or time > 382.4)'\n",
    "tt = tt.query(FILTER_TRAIN)\n",
    "tt['drift'] = tt['drift'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe359b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in tt.groupby('open_channels'):\n",
    "    d.query('not drift')['signal'].value_counts() \\\n",
    "        .plot(figsize=(15, 5), style='.', label=i,\n",
    "              title='Value Counts by Signal (Excluding Drift Sections)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897c503",
   "metadata": {},
   "source": [
    "# We wee a high number of values with these signal values:\n",
    "- Each corresponding to open channels:\n",
    "```\n",
    "    open_channels -> signal\n",
    "    0 -> -2.5002\n",
    "    1 -> -1.2502\n",
    "    2 -> -0.0002\n",
    "    3 -> 1.2498\n",
    "    4 -> 2.4998\n",
    "    5 -> 3.7498\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eda8ac",
   "metadata": {},
   "source": [
    "Lets look at the value count of these in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [-2.5002, -1.2502, -0.0002, 1.2498, 2.4998, 3.7498]\n",
    "tt.query('drift == False and signal in @anchors').groupby(['signal','open_channels'])[['time']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed7a0c",
   "metadata": {},
   "source": [
    "# Plotting only the anchor points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tt.query('drift == False and signal in @anchors') \\\n",
    "    .groupby('open_channels') \\\n",
    "    .plot(x='time', y='signal', style='.', figsize=(15, 5), ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd08834",
   "metadata": {},
   "source": [
    "# I attempted to \"shift\" the drift sections to maximize the number of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac647178",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['signal_shift'] = np.nan\n",
    "tt.loc[~tt['drift'], 'signal_shift'] = tt.loc[~tt['drift']]['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d45ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the batches with drift\n",
    "drift_batches = tt.query('drift')['sbatch'].unique()\n",
    "print(drift_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899849cd",
   "metadata": {},
   "source": [
    "## First attempt: maximize anchor count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in drift_batches:\n",
    "    d = tt.query('sbatch == @db')\n",
    "    def shift_and_anchor_count(shift):\n",
    "        anchor_count = 0\n",
    "        shifted_signal = (d['signal'] + shift).round(4)\n",
    "        for a in anchors:\n",
    "    #         print(a)\n",
    "            n_anchors = (shifted_signal == a).sum()\n",
    "    #         print(n_anchors)\n",
    "            anchor_count += n_anchors\n",
    "    #     print(f'Shift {shift} ---> anchor count: {anchor_count}')\n",
    "    \n",
    "\n",
    "        return -anchor_count\n",
    "    res = minimize(shift_and_anchor_count, [0], method='Powell', tol=1e-6)\n",
    "    opt_shift = res['x']\n",
    "    print(f'Drift batch {db} - optimal shift {opt_shift}')\n",
    "    tt.loc[tt['sbatch'] == db, 'signal_shift'] = (tt.loc[tt['sbatch'] == db]['signal'] - opt_shift).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016bcee",
   "metadata": {},
   "source": [
    "## Second attempt + max and minimize surrounding values.\n",
    "- This was a better way is to also minize if surrounding values of \"anchors\" have high value counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64732cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in drift_batches:\n",
    "    d = tt.query('sbatch == @db')\n",
    "    def shift_and_anchor_count(shift):\n",
    "        shift = shift/1000\n",
    "        anchor_count = 0\n",
    "        shifted_signal = (d['signal'] + shift).round(4)\n",
    "        for a in anchors:\n",
    "            n_anchors = (shifted_signal == a).sum()\n",
    "            anchor_count += n_anchors\n",
    "            # Penalize for high counts neighbors numbers being high\n",
    "            pprior = round(a - 0.0002, 4)\n",
    "            prior = round(a - 0.0001, 4)\n",
    "            post = round(a + 0.0001, 4)\n",
    "            ppost = round(a + 0.0002, 4)\n",
    "            n_anchor_prior = (shifted_signal == prior).sum()\n",
    "            n_anchor_pprior = (shifted_signal == pprior).sum()\n",
    "#             print(n_anchor_prior)\n",
    "            anchor_count -= (prior - pprior)\n",
    "            n_anchor_post = (shifted_signal == post).sum()\n",
    "            n_anchor_ppost = (shifted_signal == ppost).sum()\n",
    "            anchor_count -= (post - ppost)\n",
    "#         print()\n",
    "        return -anchor_count\n",
    "    res = minimize(shift_and_anchor_count, [0], method='Powell') #, bounds=(-0.0001, 0.0001))\n",
    "    opt_shift = res['x']\n",
    "    print(f'Drift batch {db} - optimal shift {opt_shift}')\n",
    "    tt.loc[tt['sbatch'] == db, 'signal_shift'] = (tt.loc[tt['sbatch'] == db]['signal'] + (opt_shift/1000)).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['signal_round4'] = tt['signal_shift'].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425df86",
   "metadata": {},
   "source": [
    "## We now have a high value count of our anchor points in non-drift areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [-2.5002, -1.2502, -0.0002, 1.2498, 2.4998, 3.7498]\n",
    "tt.query('drift and signal_shift in @anchors').groupby(['signal_shift','open_channels'])[['time']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a316109",
   "metadata": {},
   "source": [
    "# Lets plot the drift sections before and after this shift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in tt.groupby('open_channels'):\n",
    "    d.query('drift')['signal'].round(4) \\\n",
    "        .value_counts() \\\n",
    "        .plot(figsize=(15, 5), style='.', label=i,\n",
    "              title='Unique Value Counts in Drift Segments before shifting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76613101",
   "metadata": {},
   "source": [
    "This looks much cleaner, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in tt.groupby('open_channels'):\n",
    "    d.query('drift')['signal_round4'] \\\n",
    "        .round(4).value_counts() \\\n",
    "        .plot(figsize=(15, 5), style='.', label=i,\n",
    "             title='Unique Value Counts in Drift Data after Shifting to Optimize Anchors')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc06e7",
   "metadata": {},
   "source": [
    "## In the end this \"shifted\" data did not improve my CV/LB Score and I'm still confused by why it exists.\n",
    "- Can you solve this mystery for me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
