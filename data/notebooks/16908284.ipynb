{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3f09e1",
   "metadata": {},
   "source": [
    "This inference notebook is the same as @kkiller's [one](https://www.kaggle.com/kneroma/clean-fast-simple-bird-identifier-inference). Please upvote the original notebook.\n",
    "\n",
    "In this Notebook, I just lower the threshold. And it seems that LB will increase with smaller thresh, maybe which overfitting the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86647908",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import resnest\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q \"../input/resnest50-fast-package/resnest-0.0.6b20200701/resnest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aff47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "from resnest.torch import resnest50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb6a51",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc17aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 397\n",
    "SR = 32_000\n",
    "DURATION = 5\n",
    "THRESH = 0.11\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/test_soundscapes\")\n",
    "SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "TARGET_PATH = None\n",
    "    \n",
    "if not len(list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):\n",
    "    TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/train_soundscapes\")\n",
    "    SAMPLE_SUB_PATH = None\n",
    "    # SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "    TARGET_PATH = Path(\"../input/birdclef-2021/train_soundscape_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c145de",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7afea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr//10)\n",
    "        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr//(10*4))\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, y):\n",
    "\n",
    "        melspec = lb.feature.melspectrogram(\n",
    "            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n",
    "        )\n",
    "\n",
    "        melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "        return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "    \n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, length - np.zeros(len(y))])\n",
    "    elif len(y) > length:\n",
    "        y = y[:length]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDataset(Dataset):\n",
    "    def __init__(self, data, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax or self.sr//2\n",
    "\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration*self.sr\n",
    "        self.step = step or self.audio_length\n",
    "        \n",
    "        self.res_type = res_type\n",
    "        self.resample = resample\n",
    "\n",
    "        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n",
    "                                                 fmax=self.fmax)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "    \n",
    "    def audio_to_image(self, audio):\n",
    "        melspec = self.mel_spec_computer(audio) \n",
    "        image = mono_to_color(melspec)\n",
    "        image = self.normalize(image)\n",
    "        return image\n",
    "\n",
    "    def read_file(self, filepath):\n",
    "        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n",
    "\n",
    "        if self.resample and orig_sr != self.sr:\n",
    "            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "          \n",
    "        audios = []\n",
    "        for i in range(self.audio_length, len(audio) + self.step, self.step):\n",
    "            start = max(0, i - self.audio_length)\n",
    "            end = start + self.audio_length\n",
    "            audios.append(audio[start:end])\n",
    "            \n",
    "        if len(audios[-1]) < self.audio_length:\n",
    "            audios = audios[:-1]\n",
    "            \n",
    "        images = [self.audio_to_image(audio) for audio in audios]\n",
    "        images = np.stack(images)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.read_file(self.data.loc[idx, \"filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af324008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(TEST_AUDIO_ROOT).glob(\"*.ogg\")],\n",
    "    columns = [\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n",
    ")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/birdclef-2021/train_metadata.csv\")\n",
    "\n",
    "LABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\n",
    "INV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47ab9",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ea70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = BirdCLEFDataset(data=data)\n",
    "len(test_data), test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path, num_classes=NUM_CLASSES):\n",
    "    net = resnest50(pretrained=False)\n",
    "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "    dummy_device = torch.device(\"cpu\")\n",
    "    d = torch.load(checkpoint_path, map_location=dummy_device)\n",
    "    for key in list(d.keys()):\n",
    "        d[key.replace(\"model.\", \"\")] = d.pop(key)\n",
    "    net.load_state_dict(d)\n",
    "    net = net.to(DEVICE)\n",
    "    net = net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_paths = [\n",
    "#     Path('../input/bridclef-resnest50-weight/birdclef_resnest50_fold4_epoch_29_f1_val_07694_20210513205331.pth'),\n",
    "#     Path('../input/bridclef-resnest50-weight/birdclef_resnest50_fold1_epoch_18_f1_val_07636_20210512152028.pth'),\n",
    "#     Path('../input/bridclef-resnest50-weight/birdclef_resnest50_fold2_epoch_24_f1_val_07728_20210512202556.pth'),\n",
    "#     Path('../input/bridclef-resnest50-weight/birdclef_resnest50_fold3_epoch_28_f1_val_07609_20210513105835.pth'),\n",
    "    Path('../input/kkiller-birdclef-models-public/birdclef_resnest50_fold0_epoch_10_f1_val_06471_20210417161101.pth')\n",
    "]\n",
    "\n",
    "\n",
    "nets = [\n",
    "        load_net(checkpoint_path.as_posix()) for checkpoint_path in checkpoint_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_thresh_preds(out, thresh=None):\n",
    "    thresh = thresh or THRESH\n",
    "    o = (-out).argsort(1)\n",
    "    npreds = (out > thresh).sum(1)\n",
    "    preds = []\n",
    "    for oo, npred in zip(o, npreds):\n",
    "        preds.append(oo[:npred].cpu().numpy().tolist())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bird_names(preds):\n",
    "    bird_names = []\n",
    "    for pred in preds:\n",
    "        if not pred:\n",
    "            bird_names.append(\"nocall\")\n",
    "        else:\n",
    "            bird_names.append(\" \".join([INV_LABEL_IDS[bird_id] for bird_id in pred]))\n",
    "    return bird_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e03b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nets, test_data, names=True):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for idx in  tqdm(list(range(len(test_data)))):\n",
    "            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n",
    "            pred = 0.\n",
    "            for net in nets:\n",
    "                o = net(xb)\n",
    "                o = torch.sigmoid(o)\n",
    "\n",
    "                pred += o\n",
    "\n",
    "            pred /= len(nets)\n",
    "            \n",
    "            if names:\n",
    "                pred = get_bird_names(get_thresh_preds(pred))\n",
    "\n",
    "            preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = predict(nets, test_data, names=False)\n",
    "print(len(pred_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [get_bird_names(get_thresh_preds(pred, thresh=THRESH)) for pred in pred_probas]\n",
    "# preds[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_as_df(data, preds):\n",
    "    sub = {\n",
    "        \"row_id\": [],\n",
    "        \"birds\": [],\n",
    "    }\n",
    "    \n",
    "    for row, pred in zip(data.itertuples(False), preds):\n",
    "        row_id = [f\"{row.id}_{row.site}_{5*i}\" for i in range(1, len(pred)+1)]\n",
    "        sub[\"birds\"] += pred\n",
    "        sub[\"row_id\"] += row_id\n",
    "        \n",
    "    sub = pd.DataFrame(sub)\n",
    "    \n",
    "    if SAMPLE_SUB_PATH:\n",
    "        sample_sub = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\"])\n",
    "        sub = sample_sub.merge(sub, on=\"row_id\", how=\"left\")\n",
    "        sub[\"birds\"] = sub[\"birds\"].fillna(\"nocall\")\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = preds_as_df(data, preds)\n",
    "print(sub.shape)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
