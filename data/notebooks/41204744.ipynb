{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2460c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219579b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "\n",
    "data=pd.read_csv(\"/kaggle/input/financial-dataset-for-fraud-detection-in-a-comapny/Fraud.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c7811",
   "metadata": {},
   "source": [
    "# Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ba1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rows and columns in the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First five rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical details of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features of data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756600d5",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65164f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique values in column\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28558eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isFraud column values count\n",
    "data.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isFalggedFraud column values count\n",
    "data.isFlaggedFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b41574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is no information for customers that start with M (Merchants)\n",
    "#filter out rows where the recipient name starts with \"M\"\n",
    "\n",
    "new_data=data.loc[~data[\"nameDest\"].str.startswith(\"M\")]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e44985",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical features\n",
    "new_data.describe(include=[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting categorical features to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "new_data = new_data.copy()\n",
    "new_data.loc[:, 'type'] = label.fit_transform(new_data['type'])\n",
    "new_data.loc[:, 'nameOrig'] = label.fit_transform(new_data['nameOrig'])\n",
    "new_data.loc[:, 'nameDest'] = label.fit_transform(new_data['nameDest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ce5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(new_data.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for visualizing outliers\n",
    "features=new_data[['step', 'type', 'amount', 'nameOrig', \n",
    "          'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']]\n",
    "plt.figure(figsize=(20,20))\n",
    "plotnumber = 1\n",
    "\n",
    "for column in features:\n",
    "    if plotnumber<=20 :     \n",
    "        ax = plt.subplot(20,1,plotnumber)\n",
    "        sns.boxplot(x=features[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86196049",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "X = new_data.loc[:,['isFlaggedFraud','amount','oldbalanceOrg','newbalanceOrig','step','type','nameOrig']]\n",
    "y = new_data.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43110721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using random undersampling to handle the imbalanced data\n",
    "# removing random records from the majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trianing and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cdd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model and Training the data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on validation set\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8339979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set accuracy\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "# Model's Performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
