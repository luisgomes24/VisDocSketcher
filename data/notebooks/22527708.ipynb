{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a57fe19",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Semantic search means search with meaning or context. It is useful in sentence/phrase matching application at scale. Usually, Inference is requested for single sentence or in batches but, it still doesn't beat the purpose of matching a phrase with existing corpus of million (let's say) documents.\n",
    "\n",
    "Just imagine, How troublesome that inference would be! That's why, in this article, we are going to implement a semantic search using HuggingFace [sentence-transformers](https://www.sbert.net/) model ([all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)) and [FAISS](https://pypi.org/project/faiss/)\n",
    "\n",
    "\n",
    "**About FIASS**\n",
    "\n",
    "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed by Facebook AI Research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49635d3d",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0fbab",
   "metadata": {},
   "source": [
    "## 1. Installed required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66d146",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f1797",
   "metadata": {},
   "source": [
    "## 3. Create or Load a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Pet Store\",\n",
    "    \"food store\",\n",
    "    \"cat Store\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2dcd6",
   "metadata": {},
   "source": [
    "## 4. Loading the pre-trained model\n",
    "\n",
    "[Usage Guide](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2#usage-sentence-transformers) for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28547845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = model.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e9464",
   "metadata": {},
   "source": [
    "## 5. Create index for your corpus\n",
    "[Guidelines to choose an index](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index). Create index and add your corpus/data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(model.get_sentence_embedding_dimension()))\n",
    "index.add_with_ids(encoded_data, np.array(range(0, len(documents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing Index to export it across different host\n",
    "faiss.write_index(index, 'sample_documents')\n",
    "# De-serializing the index\n",
    "index = faiss.read_index('sample_documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0919598",
   "metadata": {},
   "source": [
    "## 6. Perform semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    t=time.time()\n",
    "    query_vector = model.encode([query])\n",
    "    # Search for top k results\n",
    "    k = 1\n",
    "    top_k = index.search(query_vector, k)\n",
    "    print('totaltime: {}'.format(time.time()-t))\n",
    "    return [documents[_id] for _id in top_k[1].tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17abf7c",
   "metadata": {},
   "source": [
    "## 7. Search from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3283a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Dog store\"\n",
    "results=search(query)\n",
    "print('results :')\n",
    "for result in results:\n",
    "    print('\\t',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
