{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2b01da",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import skimage.io\n",
    "import os \n",
    "import tqdm\n",
    "import glob\n",
    "import tensorflow \n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.color import grey2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "#import tensorflow_addons as tfa\n",
    "#from tensorflow.keras.metrics import Metric\n",
    "#from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\n",
    "from typeguard import typechecked\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14443a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                  \n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = tf.keras.preprocessing.image_dataset_from_directory('../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train',\n",
    "#                                                                        validation_split=0.2,\n",
    "#                                                                        subset=\"training\",\n",
    "#                                                                        shuffle=False,\n",
    "#                                                                        image_size=(224,224),\n",
    "#                                                                        batch_size=32,\n",
    "#                                                                        )\n",
    "\n",
    "train_dataset  = train_datagen.flow_from_directory(directory = '../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train',\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   subset = 'training',\n",
    "                                                   batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc10910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_dataset = tf.keras.preprocessing.image_dataset_from_directory('../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train',\n",
    "#                                                                        validation_split=0.2,\n",
    "#                                                                        subset=\"validation\",\n",
    "#                                                                        shuffle=False,\n",
    "#                                                                        image_size=(224,224),\n",
    "#                                                                        batch_size=32,\n",
    "#                                                                        )\n",
    "valid_dataset = valid_datagen.flow_from_directory(directory = '../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  subset = 'validation',\n",
    "                                                  batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\"../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test\",\n",
    "##                                                            shuffle=False,\n",
    "#                                                            image_size=(224,224),\n",
    "#                                                            batch_size=32,\n",
    "#)\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(directory = '../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d6586",
   "metadata": {},
   "source": [
    "## feature preprocessing and label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19c10e",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    '''Sequential Model creation'''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),padding='same',strides=(3, 3),input_shape = (224,224,3),activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),padding='same',strides=(3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=1,padding = 'same'))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),padding='valid',strides=(3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=1,padding = 'same'))\n",
    "    \n",
    "    model.add(Conv2D(256,(1,1),padding='valid',strides=(1, 1),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=1,padding = 'same'))\n",
    "    \n",
    "    model.add(Conv2D(512,(1,1),padding='valid',strides=(1, 1),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=1,padding = 'valid'))\n",
    "    \n",
    "    model.add(Conv2D(1024,(1,1),padding='valid',strides=(1, 1),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=3,padding = 'same'))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c36ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649da87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "        f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 5) # when i run it for 50 epochs\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c400c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7084650",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_dataset,\n",
    "                        validation_data=valid_dataset,\n",
    "                        epochs = 20,\n",
    "                        verbose = 1,\n",
    "                         callbacks=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n",
    "\n",
    "def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n",
    "    \n",
    "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(acc) + 1), acc)\n",
    "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "    ax1.set_title('History of Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    ax2.plot(range(1, len(loss) + 1), loss)\n",
    "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax2.set_title('History of Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(auc) + 1), auc)\n",
    "    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n",
    "    ax3.set_title('History of AUC')\n",
    "    ax3.set_xlabel('Epochs')\n",
    "    ax3.set_ylabel('AUC')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "    \n",
    "    ax4.plot(range(1, len(precision) + 1), precision)\n",
    "    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n",
    "    ax4.set_title('History of Precision')\n",
    "    ax4.set_xlabel('Epochs')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.legend(['training', 'validation'])\n",
    "    \n",
    "    ax5.plot(range(1, len(f1) + 1), f1)\n",
    "    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n",
    "    ax5.set_title('History of F1-score')\n",
    "    ax5.set_xlabel('Epochs')\n",
    "    ax5.set_ylabel('F1 score')\n",
    "    ax5.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
    "               history.history['loss'],history.history['val_loss'],\n",
    "               history.history['auc'],history.history['val_auc'],\n",
    "               history.history['precision'],history.history['val_precision'],\n",
    "               history.history['f1_score'],history.history['val_f1_score']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = \", scores[1])\n",
    "print(\"Precision = \", scores[2])\n",
    "print(\"Recall = \", scores[3])\n",
    "print(\"AUC = \", scores[4])\n",
    "print(\"F1_score = \", scores[5])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
