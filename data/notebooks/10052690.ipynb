{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from statistics import mode, mean\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/heart-disease-prediction-using-logistic-regression/framingham.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f0973",
   "metadata": {},
   "source": [
    "### Clearing data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bff6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "\n",
    "sns.heatmap(data.corr(), square=True, annot=True, cbar=False,  ax=ax);\n",
    "# and we can see that here no height correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21347216",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e457e8c",
   "metadata": {},
   "source": [
    "Delete from data that rows where >=2 no data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1564ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis='rows', thresh=15)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1e2df",
   "metadata": {},
   "source": [
    "So we have categorical data:\n",
    "- education\n",
    "- BPMeds\n",
    "To fill data by mode.\n",
    "\n",
    "Continuous data:\n",
    "- cigsPerDay\n",
    "- totChol\n",
    "- BMI\n",
    "- heartRate\n",
    "- glucose\n",
    "To fill data by mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342fd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"education\"]=data[\"education\"].fillna(mode(data[\"education\"]))\n",
    "data[\"BPMeds\"]=data[\"BPMeds\"].fillna(mode(data[\"BPMeds\"]))\n",
    "\n",
    "data[\"cigsPerDay\"]=data[\"cigsPerDay\"].fillna((data[\"cigsPerDay\"].mean()))\n",
    "data[\"totChol\"]=data[\"totChol\"].fillna((data[\"totChol\"].mean()))\n",
    "data[\"BMI\"]=data[\"BMI\"].fillna((data[\"BMI\"].mean()))\n",
    "data[\"heartRate\"]=data[\"heartRate\"].fillna((data[\"heartRate\"].mean()))\n",
    "data[\"glucose\"]=data[\"glucose\"].fillna(data[\"glucose\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns[:-1]:\n",
    "    pd.crosstab(data[col], data.TenYearCHD).plot(kind='bar')\n",
    "    plt.xlabel(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ebf99",
   "metadata": {},
   "source": [
    "Only 'currentSmoker' not be a good predictor of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='currentSmoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['male','age','education','cigsPerDay','BPMeds','prevalentStroke','prevalentHyp','diabetes','totChol','sysBP','diaBP','BMI','heartRate','glucose']]\n",
    "y = pd.Series(data['TenYearCHD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba05e67",
   "metadata": {},
   "source": [
    "### Train model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e46472",
   "metadata": {},
   "source": [
    "We need to normalize our data, and shift the mean to the origin. This is important to get accurate results because of the nature of the logistic equation. This is done by the normalize method.\n",
    "StandardScaler transforms the data in such a manner that it has mean as 0 and standard deviation as 1. In short, it standardizes the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3d3a0",
   "metadata": {},
   "source": [
    "Check that the mean of each feature (column) is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(X_train.mean(axis = 0), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cbdf4",
   "metadata": {},
   "source": [
    "Check that the std of each feature (column) is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd77b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ad30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311dcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe96e07",
   "metadata": {},
   "source": [
    "### Research model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ca60",
   "metadata": {},
   "source": [
    "It is the best score in this model and you will see why we stay on it:\n",
    "Creating an array containing labels depending on the specified threshold and looking at the results classification_report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a83d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array([])\n",
    "for i in range(0, 100, 10):\n",
    "    y_pred_new_threshold = (model.predict_proba(X_test)[:, 1]>= i/100).astype(int)\n",
    "    newscore = accuracy_score(y_test, y_pred_new_threshold)\n",
    "    acc = np.append(acc, [y_pred_new_threshold])\n",
    "acc = acc.astype(int)\n",
    "acc = acc.reshape(10,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for l in acc:\n",
    "    print('***', i, '***')\n",
    "    matrix = confusion_matrix(y_test, l)\n",
    "    print('\\n', matrix)\n",
    "    print(classification_report(y_test, l))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cc2f6",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed52ef",
   "metadata": {},
   "source": [
    "In some situations it is possible to maximize either recall or precision at the expense of another metric. For example, when pre-screening patients for follow â€” up, we would probably like to get a review of about 1.0-we want to find all patients who actually have the disease and we can accept low accuracy if the cost of follow-up is not significant. However, there is a simpler metric that takes into account both accuracy and recall, and so you can aim to maximize this number to make the model better. This F1-score that is a harmonic mean of precision and recall.\n",
    "**And now we see that F-1-score of model = 86%**.\n",
    "So it is better result who don`t have disease. And for creatind better model to need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd10dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, labels)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
