{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de82b6eb",
   "metadata": {},
   "source": [
    "# Simple NN baseline using Keras\n",
    "In this notebook, we aim to show a very simple startline using Keras.  \n",
    "\n",
    "This note cointains:  \n",
    "　　Making a starting model by simple NN using keras  \n",
    "and does not handle:  \n",
    "　　EDAs  \n",
    "　　The files formatted in \"mat.\"   \n",
    "\n",
    "This not is based on these kernels about other than modeling part:  \n",
    "    https://www.kaggle.com/yasufuminakama/trends-lgb-baseline  \n",
    "    https://www.kaggle.com/rohitsingh9990/trends-eda-visualization-simple-baseline  \n",
    "BIG THANKS to all kagglers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae842cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import os\n",
    "from time import time\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from numpy.random import seed\n",
    "from urllib.parse import urlparse\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv', dtype={'Id':str})\\\n",
    "            .dropna().reset_index(drop=True) # to make things easy\n",
    "reveal_ID = pd.read_csv('../input/trends-assessment-prediction/reveal_ID_site2.csv', dtype={'Id':str})\n",
    "ICN_numbers = pd.read_csv('../input/trends-assessment-prediction/ICN_numbers.csv')\n",
    "loading = pd.read_csv('../input/trends-assessment-prediction/loading.csv', dtype={'Id':str})\n",
    "fnc = pd.read_csv('../input/trends-assessment-prediction/fnc.csv', dtype={'Id':str})\n",
    "sample_submission = pd.read_csv('../input/trends-assessment-prediction/sample_submission.csv', dtype={'Id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1df329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "OUTPUT_DICT = ''\n",
    "ID = 'Id'\n",
    "TARGET_COLS = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['ID_num'] = sample_submission[ID].apply(lambda x: int(x.split('_')[0]))\n",
    "test = pd.DataFrame({ID: sample_submission['ID_num'].unique().astype(str)})\n",
    "del sample_submission['ID_num']; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d637df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "train = train.merge(loading, on=ID, how='left')\n",
    "train = train.merge(fnc, on=ID, how='left')\n",
    "\n",
    "test = test.merge(loading, on=ID, how='left')\n",
    "test = test.merge(fnc, on=ID, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loading.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fnc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b436270",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925be749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_2s(df):\n",
    "    for i in range(1, len(df.columns)-1):\n",
    "        col = df.iloc[:,i]\n",
    "        average = np.mean(col)\n",
    "        sd = np.std(col)\n",
    "        outlier_min = average - (sd) * 2.2\n",
    "        outlier_max = average + (sd) * 2.2\n",
    "        col[col < outlier_min] = outlier_min\n",
    "        col[col > outlier_max] = outlier_max\n",
    "    return df\n",
    "\n",
    "from sklearn import preprocessing\n",
    "def scaler(df):\n",
    "    for i in range(5, len(df.columns)-5):\n",
    "        col = df.iloc[:,i]\n",
    "        col = preprocessing.minmax_scale(col)\n",
    "    return df\n",
    "\n",
    "def mean_diff1(df):\n",
    "    for i in range(7, 7+len(loading.columns)):\n",
    "        dfa = df.iloc[:,7:7+len(loading.columns)]\n",
    "        average = np.mean(np.mean(dfa))\n",
    "        col = df.iloc[:,i]\n",
    "        for j in range(1,len(train)):\n",
    "            val = df.iloc[j]\n",
    "            val = col - average\n",
    "    return df\n",
    "\n",
    "def mean_diff2(df):\n",
    "    for i in range(7+len(loading.columns), 7+len(loading.columns)+len(fnc.columns)-7):\n",
    "        dfa = df.iloc[:,7+len(loading.columns):7+len(loading.columns)+len(fnc.columns)]\n",
    "        average = np.mean(np.mean(dfa))\n",
    "        col = df.iloc[:,i]\n",
    "        for j in range(1,len(train)):\n",
    "            val = df.iloc[j]\n",
    "            val = col - average\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff1 = mean_diff1(train)\n",
    "#diff2 = mean_diff2(train)\n",
    "#train = train.merge(diff1, on=ID, how='left')\n",
    "#train = train.merge(diff2, on=ID, how='left')\n",
    "\n",
    "\n",
    "#diff1 = mean_diff1(test)\n",
    "#diff2 = mean_diff2(test)\n",
    "#test = test.merge(diff1, on=ID, how='left')\n",
    "#test = test.merge(diff2, on=ID, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48942b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = outlier_2s(train)\n",
    "train = scaler(train)\n",
    "train = train.dropna(how='all').dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Id', axis=1).drop(TARGET_COLS, axis=1)\n",
    "y_train = train.drop('Id', axis=1)[TARGET_COLS]\n",
    "X_test = test.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f65744",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1964)\n",
    "epochs= 16\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "validation_split = 0.25\n",
    "input_dim = X_train.shape[1]\n",
    "n_out = y_train.shape[1]\n",
    "\n",
    "model_1 = Sequential([\n",
    "               #input\n",
    "               Dense(2048, input_shape=(input_dim,)),\n",
    "               Activation('relu'),\n",
    "               Dropout(0.1),\n",
    "               Dense(2048),\n",
    "               Activation('relu'),\n",
    "               Dropout(0.1),\n",
    "#               Dense(256),\n",
    "#               Activation('relu'),\n",
    "#               Dropout(0.1),\n",
    "#               Dense(128),\n",
    "#               Activation('relu'),\n",
    "#               Dropout(0.1),\n",
    "               #output\n",
    "               Dense(n_out),\n",
    "               Activation('relu'),\n",
    "        ])\n",
    "\n",
    "model_1.compile(loss='mse',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['mse'])\n",
    "hist_1 = model_1.fit(X_train, y_train,\n",
    "                        batch_size = batch_size, epochs = epochs,\n",
    "                        callbacks = [],\n",
    "                        verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = model_1.predict(X_test)\n",
    "prediction_dict = pd.DataFrame(prediction_dict)\n",
    "prediction_dict.columns = y_train.columns\n",
    "prediction_dict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "for TARGET in TARGET_COLS:\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp[ID] = [f'{c}_{TARGET}' for c in test[ID].values]\n",
    "    tmp['Predicted'] = prediction_dict[TARGET]\n",
    "    pred_df = pd.concat([pred_df, tmp])\n",
    "\n",
    "print(pred_df.shape)\n",
    "print(sample_submission.shape)\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a11b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(sample_submission, pred_df, on = 'Id')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(sample_submission, pred_df, on = 'Id')[['Id', 'Predicted_y']]\n",
    "submission.columns = ['Id', 'Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
