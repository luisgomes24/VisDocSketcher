{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c75bb8e",
   "metadata": {},
   "source": [
    "As found my previous notebooks, there are some interesting patterns in time series:\n",
    "\n",
    "In the notebook titled [Clustering might helpüòé](https://www.kaggle.com/code/patrick0302/clustering-might-help), clustering results for time series across nearly 500 locations are provided. This clustering approach can significantly aid in the analysis and comprehension of the time series' characteristics.\n",
    "\n",
    "Another notebook, [Find and fix the error bugüêõ](https://www.kaggle.com/code/patrick0302/find-and-fix-the-error-bug), identifies a specific pattern change that led to an huge error. Addressing this issue enhances the accuracy of most participants' scores on the public LB.\n",
    "\n",
    "So, what is this notebook for?\n",
    "\n",
    "**This notebook integrates insights from previous works to detect more potential error bugs in your score. **\n",
    "\n",
    "**It's time to find and fix them! üîç**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683082fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "path = '/kaggle/input/playground-series-s3e20/'\n",
    "path_cluster = '/kaggle/input/clustering-might-help/'\n",
    "train = pd.read_csv(path_cluster+'train_with_ClusterNo.csv')\n",
    "test = pd.read_csv(path_cluster+'test_with_ClusterNo.csv')\n",
    "ss = pd.read_csv(path+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccbf41",
   "metadata": {},
   "source": [
    "Thanks for the [nice notebook](https://www.kaggle.com/code/yeoyunsianggeremie/s3e20-kmeans-smoothing-ensemble-lazypred) from @yeoyunsianggeremie.\n",
    "\n",
    "Let's take his submission as a starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/s3e20-kmeans-smoothing-ensemble-lazypred/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41eec0",
   "metadata": {},
   "source": [
    "Here's the average lineplot of clusters 0 and 4, derived from [Clustering might helpüòé](https://www.kaggle.com/code/patrick0302/clustering-might-help).\n",
    "\n",
    "Do you find anything interesting when comparing the average lines across different years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededa807",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['emission'] = submission['emission']\n",
    "\n",
    "df_plot = pd.concat([train, test], axis=0)\n",
    "df_plot = df_plot[df_plot['ClusterNo'].isin([2])]\n",
    "df_plot = df_plot.pivot_table(index='week_no',columns='year',values='emission')\n",
    "df_plot.columns = [2019, 2020, 2021, '2022 (pred)']\n",
    "\n",
    "# Create the basic lineplot\n",
    "ax = df_plot.plot(figsize=(15, 3),title='Average emissions across years from cluster 0 and 4')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910e72a",
   "metadata": {},
   "source": [
    "Let's look closer - now you may notice that **the peak occurance of 2020 is different.**\n",
    "\n",
    "Although it's just one-week shift, the [Find and fix the error bugüêõ](https://www.kaggle.com/code/patrick0302/find-and-fix-the-error-bug) demonstrated that such one-week shift in one location could lead to a significant impact on your score.\n",
    "\n",
    "So, why not experiment by shifting the peak one week earlier in 2022, mirroring the pattern observed in 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_plot.iloc[10:21]\n",
    "\n",
    "# Create the basic lineplot\n",
    "ax = df_plot.plot(figsize=(6, 3),title=\"Emission peaks across years \\n(2022's prediction is on 14th week)\")\n",
    "\n",
    "# Highlight\n",
    "for year in [2019, 2021, '2022 (pred)']:\n",
    "    ax.scatter(x=[14], y=[df_plot.loc[14, year]], color='red')\n",
    "\n",
    "ax.scatter(x=[13], y=[df_plot.loc[13, 2020]], color='green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b707ac5",
   "metadata": {},
   "source": [
    "To achieve this, we can discard the values for week 13 and replace them with the peak values from week 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[(test['ClusterNo'].isin([0,3,4, 7]))&(test['week_no']==13), 'emission'] = np.nan\n",
    "submission = submission.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95326c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==39), 'emission'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==39), 'emission'] = np.nan\n",
    "submission = submission.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241de18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==39), 'emission'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff60ac",
   "metadata": {},
   "source": [
    "The adjusted result for the 2022 prediction now aligns with the peak of 2020!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286252df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['emission'] = submission['emission']\n",
    "\n",
    "df_plot = pd.concat([train, test], axis=0)\n",
    "df_plot = df_plot[df_plot['ClusterNo'].isin([0,4])]\n",
    "df_plot = df_plot.pivot_table(index='week_no',columns='year',values='emission')\n",
    "df_plot.columns = [2019, 2020, 2021, '2022 (pred)']\n",
    "df_plot = df_plot.iloc[10:21]\n",
    "\n",
    "# Create the basic lineplot\n",
    "ax = df_plot.plot(figsize=(6, 3),title=\"Emission peaks across years \\n(2022's prediction is on 13th week)\")\n",
    "\n",
    "# Highlight\n",
    "for year in [2019, 2021]:\n",
    "    ax.scatter(x=[14], y=[df_plot.loc[14, year]], color='red')\n",
    "\n",
    "ax.scatter(x=[13], y=[df_plot.loc[13, '2022 (pred)']], color='green')\n",
    "ax.scatter(x=[13], y=[df_plot.loc[13, 2020]], color='green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('/kaggle/input/playground-series-s3e20/sample_submission.csv')\n",
    "asd = pd.DataFrame(sample_sub['ID_LAT_LON_YEAR_WEEK'].str.split('_',expand=True))\n",
    "asd.columns = ['ID','latitude','longitude','year','week_no']\n",
    "asd = asd.drop('ID',axis=1)\n",
    "asd = asd.astype('float')\n",
    "asd['emission'] = submission['emission'].values\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40df683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/input/playground-series-s3e20/\"\n",
    "trainee= pd.read_csv(PATH + \"train.csv\",index_col=\"ID_LAT_LON_YEAR_WEEK\")\n",
    "trainee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = trainee[asd.columns].reset_index(drop=True).copy()\n",
    "new_form = pd.concat([upper,asd],axis=0).reset_index(drop=True).copy()\n",
    "focus_1_mean = new_form[new_form['week_no']<=9].groupby(['year','week_no']).mean().reset_index().copy()\n",
    "focus_1_std = new_form[new_form['week_no']<=9].groupby(['year','week_no']).std().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a606879",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1 =  new_form[new_form['week_no']<=9].copy()\n",
    "subset_1.insert(1,\"lat_lon_week_no\", list(zip(subset_1[\"latitude\"],subset_1[\"longitude\"], subset_1[\"week_no\"])))\n",
    "#tempa = subset_1[subset_1['week_no']==0].reset_index().copy()\n",
    "#latlon = [list(i) for i in np.unique([set(i) for i in tempa[['latitude','longitude']].values])]\n",
    "#tempa.insert(1,\"lat_lon\", list(zip(tempa[\"latitude\"],tempa[\"longitude\"])))\n",
    "tempa = subset_1.copy()\n",
    "subtemp = tempa.pivot_table(index='lat_lon_week_no',columns='year',values='emission').copy()\n",
    "subtemp['diff_2019_2021'] =  (subtemp[2021.0] - subtemp[2019.0])\n",
    "subtemp['diff_2020_2021'] =  (subtemp[2021.0] - subtemp[2020.0])\n",
    "subtemp['diff_2019_2020'] =  (subtemp[2020.0] - subtemp[2019.0])\n",
    "subtemp['diff_2019_2021'] = subtemp['diff_2019_2021']/subtemp['diff_2019_2020']\n",
    "subtemp['diff_2020_2021'] = subtemp['diff_2020_2021']/subtemp['diff_2019_2020']\n",
    "subtemp['diff_scale'] = subtemp[['diff_2019_2021','diff_2020_2021']].abs().min(axis=1)\n",
    "final_suba = subtemp[(subtemp['diff_scale'].abs()<=7)&(subtemp['diff_scale'].abs()>=3.5)&subtemp['diff_2019_2021']*subtemp['diff_2020_2021'] >0].reset_index().copy()\n",
    "final_suba[2022.0] = final_suba[2021.0].values\n",
    "final_suba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d010693",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.insert(1,\"lat_lon_week_no\", list(zip(asd[\"latitude\"],asd[\"longitude\"], asd[\"week_no\"])))\n",
    "aassdd = asd.merge(final_suba[['lat_lon_week_no',2022.0]],how='left',on='lat_lon_week_no').copy().rename(columns={2022.0: \"2022\"})\n",
    "aassdd['emission'] = np.where(pd.notna(aassdd['2022']),aassdd['2022'],aassdd['emission'])\n",
    "aassdd = aassdd.drop('2022',axis=1)\n",
    "assert pd.isna(aassdd['emission']).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['emission'] = aassdd['emission'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb11026",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c3bac",
   "metadata": {},
   "source": [
    "Whew! The bugs were removed!\n",
    "\n",
    "Now you might want to discover more bugs or find a more elegant way in removing them? \n",
    "\n",
    "Your choiceüòé"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
