{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732491fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is based on this clean implementation of the [Viterbi Algorithm](https://www.kaggle.com/miklgr500/viterbi-algorithm-without-segmentation-on-groups), which in turn was inspired by [this notebook](https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution). It shows how a relative high score can be achieved using only the provided signal by taking into account the sequential nature of the data. \n",
    "\n",
    "I made the following changes that improved my score locally:\n",
    "* The signal does not need to be discretized to calculate `p_signal`. Instead, estimate the mean and standard deviation using the available labeled data. This allows us to construct a gaussian distribution the signals of each `open_channels` value. We can then use the probability density function of this distribution to get a more accurate `p_signal`.\n",
    "* Changed the calculation of the Viterbi loop.\n",
    "* Fit different models for the different types of data. This is because both the `p_trans` and `p_signal` will differ in each batch.\n",
    "\n",
    "The groups are made by eyeballing the plots in [this notebook](https://www.kaggle.com/cdeotte/one-feature-model-0-930) (Model 0, 1, 2, 3, 4 correspond to 1s, 1f, 3, 5 and 10 respectively.). While this notebook is not yet scoring > 0.940, it could be interesting to add `T1`, which is calculated during the Viterbi algorithm to your feature set.\n",
    "\n",
    "**I also have an implementation of the [forward-backward (posterior decoding) algorithm](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm), which tends to achieve a little bit better results, but it is a lot slower. Let me know if you are interested!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07213afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44151db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/ghost-drift-and-outliers/train_clean_kalman.csv')\n",
    "test  = pd.read_csv('../input/ghost-drift-and-outliers/test_clean_kalman.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10a898",
   "metadata": {},
   "source": [
    "# Viterbi algorithm (collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViterbiClassifier:\n",
    "    def __init__(self):\n",
    "        self._p_trans = None\n",
    "        self._p_signal = None\n",
    "        self._p_in = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._p_trans = self.markov_p_trans(y)\n",
    "        self._dists = []\n",
    "        self._states = len(np.unique(y))\n",
    "        for s in np.arange(y.min(), y.max() + 1):\n",
    "            self._dists.append((np.mean(x[y == s]), np.std(x[y == s])))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x):\n",
    "        p_signal = self.markov_p_signal(x)\n",
    "        return self.viterbi(self._p_trans, p_signal, x)\n",
    "    \n",
    "    def markov_p_signal(self, signal):\n",
    "        p_signal = np.zeros((self._states, len(signal)))\n",
    "        for k, dist in enumerate(self._dists):\n",
    "            p_signal[k, :] = norm.pdf(signal, *dist)\n",
    "            \n",
    "        return p_signal\n",
    "    \n",
    "    def markov_p_trans(self, states):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        max_state = np.max(states)\n",
    "        states_next = np.roll(states, -1)\n",
    "        matrix = []\n",
    "        for i in range(max_state + 1):\n",
    "            current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "            if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "                current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "            else:\n",
    "                current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "            matrix.append(current_row)\n",
    "        return np.array(matrix)\n",
    "    \n",
    "    def viterbi(self, p_trans, p_signal, signal):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        offset = 10**(-20) # added to values to avoid problems with log2(0)\n",
    "\n",
    "        p_trans_tlog  = np.transpose(np.log2(p_trans  + offset)) # p_trans, logarithm + transposed\n",
    "        p_signal_tlog = np.transpose(np.log2(p_signal + offset)) # p_signal, logarithm + transposed\n",
    "        \n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T2 = np.zeros(p_signal.shape)\n",
    "\n",
    "        T1[:, 0] = p_signal_tlog[0, :]\n",
    "        T2[:, 0] = 0\n",
    "\n",
    "        for j in range(1, p_signal.shape[1]):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = np.max(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "                T2[i, j] = np.argmax(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "\n",
    "        x = np.empty(p_signal.shape[1], 'B')\n",
    "        x[-1] = np.argmax(T1[:, p_signal.shape[1] - 1])\n",
    "        for i in reversed(range(1, p_signal.shape[1])):\n",
    "            x[i - 1] = T2[x[i], i]\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2006e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['batch'] = (train['time'] - 0.0001) // 50\n",
    "counts = train.groupby('batch').count()['time'].values\n",
    "models = [0, 0, 1, 2, 4, 3, 1, 2, 3, 4]\n",
    "blocks = [[], [], [], [], []]\n",
    "total = 0\n",
    "for model, count in zip(models, counts):\n",
    "    blocks[model].extend(list(range(total, total + count)))\n",
    "    total += count\n",
    "print([len(x) for x in blocks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_state = train.open_channels.values\n",
    "signal = train.signal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show the (gaussian) distributions of the signals\n",
    "f, ax = plt.subplots(1, len(blocks), figsize=(20, 5))\n",
    "for i, ix in enumerate(blocks):\n",
    "    for label in set(true_state[ix]):\n",
    "        pd.Series(signal[ix][true_state[ix] == label]).plot(kind='hist', ax=ax[i], \n",
    "                                                            alpha=0.5, label=label)\n",
    "    ax[i].set_title('Data #{}'.format(i))\n",
    "    ax[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6df5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "train_predictions = np.zeros(len(signal))\n",
    "for i, ix in enumerate(blocks):\n",
    "    sub_signal = signal[ix]\n",
    "    viterbi = ViterbiClassifier().fit(sub_signal, true_state[ix])\n",
    "    models.append(viterbi)\n",
    "    \n",
    "    train_predictions[ix] = viterbi.predict(sub_signal)\n",
    "    print('[Model #{}] F1 (macro) = {}'.format(i, f1_score(y_pred=train_predictions[ix], y_true=true_state[ix], average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Accuracy =\", accuracy_score(y_pred=train_predictions, y_true=true_state))\n",
    "print(\"Total F1 (macro) =\", f1_score(y_pred=train_predictions, y_true=true_state, average='macro'))\n",
    "\n",
    "# Total Accuracy = 0.9670930385544279\n",
    "# Total F1 (macro) = 0.9359432322559637\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_blocks = [\n",
    "    list(range(0, 100000)) + list(range(300000, 400000)) + list(range(800000, 900000)) + list(range(1000000, 2000000)),\n",
    "    list(range(400000, 500000)),\n",
    "    list(range(100000, 200000)) + list(range(900000, 1000000)),\n",
    "    list(range(200000, 300000)) + list(range(600000, 700000)),\n",
    "    list(range(500000, 600000)) + list(range(700000, 800000))\n",
    "]\n",
    "\n",
    "# Sanity check\n",
    "assert sum([len(x) for x in test_blocks]) == 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv(\"../input/liverpool-ion-switching/sample_submission.csv\")\n",
    "for i, ix in enumerate(test_blocks):\n",
    "    df_subm.loc[ix, 'open_channels'] = models[i].predict(test.signal.values[ix])\n",
    "df_subm.to_csv(\"viterbi.csv\", float_format='%.4f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f082e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "# https://www.kaggle.com/cdeotte/one-feature-model-0-930\n",
    "plt.figure(figsize=(20,5))\n",
    "res = 1000; let = ['A','B','C','D','E','F','G','H','I','J']\n",
    "plt.plot(range(0,test.shape[0],res),df_subm.open_channels[0::res])\n",
    "for i in range(5): plt.plot([i*500000,i*500000],[-5,12.5],'r')\n",
    "for i in range(21): plt.plot([i*100000,i*100000],[-5,12.5],'r:')\n",
    "for k in range(4): plt.text(k*500000+250000,10,str(k+1),size=20)\n",
    "for k in range(10): plt.text(k*100000+40000,7.5,let[k],size=16)\n",
    "plt.title('Test Data Predictions',size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee29bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
