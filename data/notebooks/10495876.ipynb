{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df7d6b1",
   "metadata": {},
   "source": [
    "#Hospital Sírio e Libanês and AI.\n",
    "\n",
    "How can artificial intelligence change the future of medicine? The doctor and general director of the Sírio-Libanês hospital , Paulo Chapchap , spoke exclusively to the Consumidor Moderno and Whow! on the use of new technologies and the main challenges faced in daily application, such as ethics in the use of patient data.\n",
    "\n",
    "He also commented on the evolution in the relationship with the hospital's clients , the plans for an expansion of the application of voice within the medical field, in addition to the possible elimination of diseases through the use of big data, artificial intelligence and machine learning.https://translate.google.com.br/translate?hl=en&sl=pt&u=https://www.consumidormoderno.com.br/2020/02/14/sirio-libanes-experiencia-de-voz/&prev=search&pto=aue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb53068",
   "metadata": {},
   "source": [
    "![](https://www.hospitalsiriolibanes.org.br/solidariedade-coronavirus/PublishingImages/banner-solidariedade-coronavirus.png)\n",
    "hospitalsiriolibanes.org.br\n",
    "\n",
    "Philanthropy has been the raison d'être of the Sociedade Beneficente de Senhoras Hospital Sírio-Libanês for almost 100 years. Their history was born from the feeling of solidarity and it is our mission to exercise it.\n",
    "\n",
    "In this unprecedented moment of global crisis, due to the COVID-19 pandemic, they are mobilizing to minimize the impact of this scenario on the lives of the most vulnerable families and health professionals, and to support society in general.\n",
    "\n",
    "Therefore, they have structured their own initiatives and in partnership with other institutions, in a joint effort, to deliver the greatest possible number of solutions, which aim to overcome this crisis as soon as possible.\n",
    "On April 8, they launched the Campaign “Solidarity Action to Combat Covid-19”. \n",
    "\n",
    "#My Notebook Plot.Solidarity  https://www.kaggle.com/mpwolke/plot-solidarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/kaggle/input/covid19/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26dd5b",
   "metadata": {},
   "source": [
    "I dropped the columns below because I couldn't encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['AGE_PERCENTIL', 'WINDOW']\n",
    "df=df.drop(cols_to_drop,axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc811e4",
   "metadata": {},
   "source": [
    "#Codes from Ossamu  https://www.kaggle.com/ossamum/eda-and-feat-import-recall-0-95-roc-auc-0-61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "df['ICU'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "# checking null values\n",
    "msno.bar(df, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ca49f",
   "metadata": {},
   "source": [
    "We've many values null in the dataset. Drop the columns that only have one value in the target, since they'll hardly help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fad80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum() / df.shape[0]).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_null_series = (df.isnull().sum() != 0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ccc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = 'ICU'\n",
    "#just_one_target = []\n",
    "\n",
    "#for col in contain_null_series:\n",
    "#    i = df[df[col].notnull()][target].nunique()\n",
    "#    if i == 1:\n",
    "#        just_one_target.append(col)    \n",
    "\n",
    "# columns that only are present when ICU is needed        \n",
    "#print(just_one_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in just_one_target:\n",
    " #   print(df[df[col].notnull()][target].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(just_one_target, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e2c5f",
   "metadata": {},
   "source": [
    "We'll plot the columns that doesn't have any null to check if they can discriminate the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_series = (df.isnull().sum() == 0)\n",
    "not_null_columns = not_null_series[not_null_series == True].index\n",
    "not_null_columns = not_null_columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, cols, subplots_rows, subplots_cols, figsize=(16, 8), target='ICU'):\n",
    "    df_neg = df[df[target] == 'negative']\n",
    "    df_pos = df[df[target] == 'positive']\n",
    "    \n",
    "    cols = cols.tolist()\n",
    "    cols.remove(target)\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(subplots_rows, subplots_cols, figsize=figsize)\n",
    "    \n",
    "    i = 0    \n",
    "    for col in cols:\n",
    "        i += 1\n",
    "        plt.subplot(subplots_rows, subplots_cols, i)\n",
    "        sns.distplot(df_neg[col], label=\"Negative\", bins=15, kde=False)\n",
    "        sns.distplot(df_pos[col], label=\"Positive\", bins=15, kde=False)\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_histograms(df, not_null_columns, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e5f52",
   "metadata": {},
   "source": [
    "Right data, wrong snippet. No distplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd915a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['PATIENT_VISIT_IDENTIFIER', 'ICU'], axis=1)\n",
    "x.fillna(999999, inplace=True)\n",
    "y = df['ICU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf681e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff762940",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73add671",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_feat = pd.DataFrame(dt.feature_importances_, index=x.columns, columns=['feat_importance'])\n",
    "dt_feat.sort_values('feat_importance').tail(8).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "graph = Source(export_graphviz(dt, out_file=None, feature_names=x.columns, filled = True))\n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['ICU'] == 1]['LEUKOCYTES_MAX'], label=\"ICU\")\n",
    "sns.distplot(df[df['ICU'] == 0]['LEUKOCYTES_MAX'], label=\"NO ICU\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79e4e4",
   "metadata": {},
   "source": [
    "#Modeling\n",
    "\n",
    "We'll try to identify ICU need by applying several models combined with random over sampler and random under sampler. The samplers will balance the dataset, therefore it should reduce the bias of the models. We'll also apply xgboost with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38568be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'Logistic Regression' : LogisticRegression(),\n",
    "               'KNN': KNeighborsClassifier(),\n",
    "               'Decision Tree': DecisionTreeClassifier(),\n",
    "               'Random Forest': RandomForestClassifier(),\n",
    "               'AdaBoost': AdaBoostClassifier(),\n",
    "               'SVM': SVC()}\n",
    "\n",
    "samplers = {'Random_under_sampler': RandomUnderSampler(),\n",
    "            'Random_over_sampler': RandomOverSampler()}\n",
    "\n",
    "drop_cols = ['PATIENT_VISIT_IDENTIFIER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split(df, target='ICU', drop_cols=drop_cols):\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    df = df.fillna(999)\n",
    "    x = df.drop(target, axis=1)\n",
    "    y = df[target]    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)                          \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def train_clfs(df, classifiers, samplers):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = df_split(df)\n",
    "    \n",
    "    names_samplers = []\n",
    "    names_clfs = []\n",
    "    results_train_cv_roc_auc = []\n",
    "    results_train_cv_recall = []\n",
    "    results_train_cv_accuracy = []\n",
    "    results_test_roc_auc = []\n",
    "    results_test_recall = []\n",
    "    results_test_accuracy = []\n",
    "    \n",
    "    for name_sampler, sampler in samplers.items():\n",
    "        print(f'Sampler: {name_sampler}\\n')\n",
    "        for name_clf, clf in classifiers.items():\n",
    "            print(f'Classifier: {name_clf}\\n')\n",
    "            \n",
    "            pipeline = Pipeline([('sampler', sampler),\n",
    "                                 ('clf', clf)])\n",
    "            \n",
    "            cv_auc = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='roc_auc') \n",
    "            cv_rec = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='recall')                                \n",
    "            cv_acc = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='accuracy')        \n",
    "\n",
    "            pipeline.fit(x_train, y_train)        \n",
    "            y_pred = pipeline.predict(x_test)\n",
    "            \n",
    "            names_samplers.append(name_sampler)\n",
    "            names_clfs.append(name_clf)\n",
    "            results_train_cv_roc_auc.append(cv_auc)\n",
    "            results_train_cv_recall.append(cv_rec)\n",
    "            results_train_cv_accuracy.append(cv_acc)\n",
    "            results_test_roc_auc.append(roc_auc_score(y_test, y_pred))\n",
    "            results_test_recall.append(recall_score(y_test, y_pred))\n",
    "            results_test_accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "            print(f'CV\\t-\\troc_auc:\\t{round(cv_auc.mean(), 3)}')\n",
    "            print(f'CV\\t-\\trecall:\\t\\t{round(cv_rec.mean(), 3)}')\n",
    "            print(f'CV\\t-\\taccuracy:\\t{round(cv_acc.mean(), 3)}')\n",
    "\n",
    "            print(f'Test\\t-\\troc_auc:\\t{round(roc_auc_score(y_test, y_pred), 3)}')         \n",
    "            print(f'Test\\t-\\trecall:\\t\\t{round(recall_score(y_test, y_pred), 3)}')          \n",
    "            print(f'Test\\t-\\taccuracy:\\t{round(accuracy_score(y_test, y_pred), 3)}')      \n",
    "            print('\\n<-------------------------->\\n')\n",
    "\n",
    "    df_results_test = pd.DataFrame(index=[names_clfs, names_samplers], columns=['ROC_AUC', 'RECALL', 'ACCURACY'])\n",
    "    df_results_test['ROC_AUC'] = results_test_roc_auc\n",
    "    df_results_test['RECALL'] = results_test_recall\n",
    "    df_results_test['ACCURACY'] = results_test_accuracy\n",
    "\n",
    "    return df_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cea80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test = train_clfs(df, classifiers, samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60121f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(df, clf):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = df_split(df)\n",
    "\n",
    "    scale_pos_weight = len(df[df['ICU'] == 0]) / len(df[df['ICU'] == 1])\n",
    "\n",
    "    param_grid = {'xgb__max_depth': [3, 4, 5, 6, 7, 8],\n",
    "                  'xgb__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                  'xgb__colsample_bytree': [0.6, 0.7, 0.8],\n",
    "                  'xgb__min_child_weight': [0.4, 0.5, 0.6],\n",
    "                  'xgb__gamma': [0, 0.01, 0.1],\n",
    "                  'xgb__reg_lambda': [6, 7, 8, 9, 10],\n",
    "                  'xgb__n_estimators': [150, 200, 300],\n",
    "                  'xgb__scale_pos_weight': [scale_pos_weight]}\n",
    "\n",
    "    rs_clf = RandomizedSearchCV(clf, param_grid, n_iter=100,\n",
    "                                n_jobs=-1, verbose=2, cv=5,                            \n",
    "                                scoring='roc_auc', random_state=42)\n",
    "\n",
    "    rs_clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(f'XGBOOST BEST PARAMS: {rs_clf.best_params_}')\n",
    "    \n",
    "    y_pred = rs_clf.predict(x_test)\n",
    "\n",
    "    df_results_xgb = pd.DataFrame(index=[['XGBoost'], ['No_sampler']], columns=['ROC_AUC', 'RECALL', 'ACCURACY'])\n",
    "\n",
    "    df_results_xgb['ROC_AUC'] = roc_auc_score(y_test, y_pred)\n",
    "    df_results_xgb['RECALL'] = recall_score(y_test, y_pred)\n",
    "    df_results_xgb['ACCURACY'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return df_results_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_xgb = train_xgb(df, xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat([df_results_test, df_results_xgb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eed043",
   "metadata": {},
   "source": [
    "The top 9 pipelines for each metric ROC_AUC, RECALL, and ACCURACY in the test dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.concat([df_results.sort_values('ROC_AUC', ascending=False).head(3),\n",
    "                     df_results.sort_values('RECALL', ascending=False).head(3),\n",
    "                     df_results.sort_values('ACCURACY', ascending=False).head(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d308970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test(df, xlim_min, xlim_max):\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10,12))\n",
    "    color = ['blue', 'red', 'green', 'yellow', 'orange', 'purple', 'navy', 'turquoise', 'darkorange']\n",
    "\n",
    "    df['ROC_AUC'].plot(kind='barh', ax=ax1, xlim=(xlim_min, xlim_max), title='ROC_AUC', color=color)\n",
    "    df['RECALL'].plot(kind='barh', ax=ax2, xlim=(xlim_min, xlim_max), title='RECALL', color=color)\n",
    "    df['ACCURACY'].plot(kind='barh', ax=ax3, xlim=(xlim_min, xlim_max), title='ACCURACY', color=color)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test(df_plot, 0.4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, title='Confusion matrix'):\n",
    "    \n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def train_clf_threshold(df, clf, sampler=None):\n",
    "    thresholds = np.arange(0.1, 1, 0.1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = df_split(df)\n",
    "    \n",
    "    if sampler:\n",
    "        clf_train = Pipeline([('sampler', sampler),\n",
    "                              ('clf', clf)])\n",
    "        \n",
    "    else:        \n",
    "        clf_train = clf\n",
    "            \n",
    "    clf_train.fit(x_train, y_train)\n",
    "    y_proba = clf_train.predict_proba(x_test)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    j = 1\n",
    "    for i in thresholds:\n",
    "        y_pred = y_proba[:,1] > i\n",
    "\n",
    "        plt.subplot(4, 3, j)\n",
    "        j += 1\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        print(f\"Threshold: {round(i, 1)} | Test Accuracy: {round(accuracy_score(y_test, y_pred), 2)}| Test Recall: {round(recall_score(y_test, y_pred), 2)} | Test Roc Auc: {round(roc_auc_score(y_test, y_pred), 2)}\")\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, title=f'Threshold >= {round(i, 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e56f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clf_threshold(df, RandomForestClassifier(), sampler=RandomUnderSampler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfd6a8",
   "metadata": {},
   "source": [
    "#All codes from  Ossamu  https://www.kaggle.com/ossamum/eda-and-feat-import-recall-0-95-roc-auc-0-61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963317d",
   "metadata": {},
   "source": [
    "Das War's, Kaggle Notebook Runner: Marília Prata  @mpwolke"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
