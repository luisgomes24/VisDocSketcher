{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/us-crime-data/US_Crime_Data.csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f03b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4148ec",
   "metadata": {},
   "source": [
    "## For this model we just need headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee955154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['Title']]\n",
    "df = df.dropna().reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'][123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc04600",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    df['Title'] = df['Title'].apply(lambda x : x.lower())\n",
    "    tokens = df['Title'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20550024",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de11e8",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32539f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(tokens)\n",
    "seq = tokenizer.texts_to_sequences(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba946578",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c283e",
   "metadata": {},
   "source": [
    "# Creating input and output data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "total_words_drop = 0\n",
    "for i in seq:\n",
    "    if len(i) > 1:\n",
    "        for j in range(1, len(i)):\n",
    "            x.append(i[:j])\n",
    "            y.append(i[j])\n",
    "            \n",
    "    else : \n",
    "        total_words_drop +=1\n",
    "print('Total Words Dropped : {}'.format(total_words_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a774e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713eba09",
   "metadata": {},
   "source": [
    "# Padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.preprocessing.sequence.pad_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b292e56",
   "metadata": {},
   "source": [
    "# Shaping y same as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca049e2",
   "metadata": {},
   "source": [
    "# Vocab Size : total no. of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d05843",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fae66",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ed54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size,49 ),\n",
    "                            tf.keras.layers.LSTM(100, return_sequences = True),\n",
    "                            tf.keras.layers.LSTM(100),\n",
    "                            tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(vocab_size, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss  = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x,y,\n",
    "                   epochs = 100,\n",
    "                    batch_size = 256,\n",
    "                    callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                               patience = 5,\n",
    "                                                               restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4dcdf",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f669aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b323fa",
   "metadata": {},
   "source": [
    "# Vocab Array : list of all the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_array = np.array(list(tokenizer.word_index.keys()))\n",
    "vocab_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900a994",
   "metadata": {},
   "source": [
    "# Final Function for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9059bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(text, n_words):\n",
    "    for i in range(n_words):\n",
    "        text_tokenize = tokenizer.texts_to_sequences([text])\n",
    "        text_padding  = tf.keras.preprocessing.sequence.pad_sequences(text_tokenize, maxlen = 49)\n",
    "        prediction = np.squeeze(np.argmax(model.predict(text_padding), axis = -1))\n",
    "        prediction = str(vocab_array[prediction - 1])\n",
    "        text += \" \" + prediction\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e2087",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('california',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('new york',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('highway',8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21850b63",
   "metadata": {},
   "source": [
    "> Its so fun to get prediction !\n",
    "\n",
    "# Thanks!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
