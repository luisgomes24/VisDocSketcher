{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cd8c0a",
   "metadata": {},
   "source": [
    "# Body segmentation with Catalyst\n",
    "\n",
    "   The purpose of this work is find out how to use Catalyst for the segmentation task.Make a pipeline for this, using only catalyst.\n",
    "    Catalyst is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d49c4",
   "metadata": {},
   "source": [
    "# 1) Import libraries and set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eeee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 \n",
    "from catalyst.contrib.nn import DiceLoss, IoULoss\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst import dl\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMAGE_DIR = '../input/segmentation-full-body-mads-dataset/segmentation_full_body_mads_dataset_1192_img/images'\n",
    "MASK_DIR = '../input/segmentation-full-body-mads-dataset/segmentation_full_body_mads_dataset_1192_img/masks'\n",
    "IMAGE_HEIGHT = 200\n",
    "IMAGE_WIDTH = 200\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b40c8",
   "metadata": {},
   "source": [
    "# 2) Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = Path(IMAGE_DIR)\n",
    "img_list = list(path_img.glob('*.png'))\n",
    "path_mask = Path(MASK_DIR)\n",
    "mask_list = list(path_mask.glob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77059bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullBodySegmentation(data.Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None):\n",
    "        super().__init__() \n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx : int):\n",
    "        \n",
    "        input_image = self.inputs[idx]\n",
    "        target_image = self.targets[idx]\n",
    "\n",
    "        image = np.array(Image.open(input_image).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(target_image).convert(\"L\"), dtype=np.float32)\n",
    "        mask = mask / 255\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ae2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, x_test ,y_data, y_test = train_test_split(\n",
    "                                            img_list,\n",
    "                                            mask_list,\n",
    "                                            test_size=0.1, \n",
    "                                            random_state=42, \n",
    "                                            shuffle=True)\n",
    "\n",
    "x_train, x_val ,y_train, y_val = train_test_split(\n",
    "                                            x_data,\n",
    "                                            y_data,\n",
    "                                            test_size=0.1, \n",
    "                                            random_state=42, \n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_maskdir,\n",
    "    val_dir,\n",
    "    val_maskdir,\n",
    "    test_dir,\n",
    "    test_maskdir,   \n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    train_ds = FullBodySegmentation(\n",
    "        inputs=train_dir,\n",
    "        targets=train_maskdir,\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = FullBodySegmentation(\n",
    "        inputs=val_dir,\n",
    "        targets=val_maskdir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    test_ds = FullBodySegmentation(\n",
    "        inputs=test_dir,\n",
    "        targets=test_maskdir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec12c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966831aa",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_loader, val_loader, test_loader = get_loaders(\n",
    "                                            x_train,\n",
    "                                            y_train,\n",
    "                                            x_val,\n",
    "                                            y_val,\n",
    "                                            x_test,\n",
    "                                            y_test,   \n",
    "                                            BATCH_SIZE,\n",
    "                                            train_transform,\n",
    "                                            val_transform,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True,\n",
    "                                        )\n",
    "loaders = {\"train\": train_loader, \"valid\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292ccc7",
   "metadata": {},
   "source": [
    "# 3) Let's look at the data and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of the train data: {len(train_loader)*BATCH_SIZE} images')\n",
    "print(f'Length of the validation_data: {len(val_loader)*BATCH_SIZE} images')\n",
    "print(f'Length of the test data: {len(test_loader)*BATCH_SIZE} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87177fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_mask = next(iter(train_loader))\n",
    "val_image, val_mask = next(iter(val_loader))\n",
    "print(f'Shape of input images:\\n train -  {train_image.shape},\\n val -  {val_image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that the mask images in [0,1] range\")\n",
    "print(f'Shape of input masks:\\n train -  {train_mask.shape},\\n val -  {val_mask.shape}')\n",
    "print(f'Train mask values: \\n max - {train_mask.max()} \\n min - {train_mask.min()}')\n",
    "print(f'Validate mask values: \\n max - {val_mask.max()} \\n min - {val_mask.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b15008",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4,figsize=(15,15))\n",
    "\n",
    "for batch in val_loader:\n",
    "    images,mask_target = batch\n",
    "    for i in range(len(images)+len(mask_target)):\n",
    "        if i <len(images):\n",
    "            axs[0,i].imshow(images[i].permute(1,2,0).cpu().numpy())\n",
    "        else:\n",
    "            axs[1,i%4].imshow(mask_target[i%4].cpu().numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773eb14",
   "metadata": {},
   "source": [
    "# 4) Make a training loop\n",
    "   Let's take UNET model from catalyst library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.models.cv.segmentation.unet import Unet\n",
    "\n",
    "model = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRunner(dl.Runner):\n",
    "    def predict_batch(self, batch):\n",
    "        # model inference step\n",
    "        return self.model(batch[0].to(self.device))\n",
    "    def handle_batch(self, batch):\n",
    "        x, y = batch\n",
    "        #logits = self.model(x)['out'].squeeze(1)\n",
    "        logits = self.model(x).squeeze(1)\n",
    "        binar = torch.sigmoid(logits)\n",
    "        num_classes = logits.shape[-1]\n",
    "        self.batch = {\n",
    "            \"features\": x,\n",
    "            \"logits\": logits,\n",
    "            \"targets\": y,\n",
    "            \"binar\": binar,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad373c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = {\n",
    "    \"dice\": DiceLoss(),\n",
    "    \"iou\": IoULoss(),\n",
    "    \"bce\": BCEWithLogitsLoss()\n",
    "}\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "# training\n",
    "runner = CustomRunner()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=\"./logdir\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    num_epochs=10,\n",
    "    callbacks=[\n",
    "        dl.CriterionCallback(\n",
    "            input_key=\"binar\",\n",
    "            target_key=\"targets\",\n",
    "            metric_key=\"loss_dice\",\n",
    "            criterion_key=\"dice\",\n",
    "        ),\n",
    "        dl.CriterionCallback(\n",
    "            input_key=\"binar\",\n",
    "            target_key=\"targets\",\n",
    "            metric_key=\"loss_iou\",\n",
    "            criterion_key=\"iou\",\n",
    "        ),\n",
    "        dl.CriterionCallback(\n",
    "            input_key=\"logits\",\n",
    "            target_key=\"targets\",\n",
    "            metric_key=\"loss_bce\",\n",
    "            criterion_key=\"bce\",\n",
    "        ),\n",
    "        # loss aggregation\n",
    "        dl.MetricAggregationCallback(\n",
    "            metric_key=\"loss\",\n",
    "            metrics={\"loss_dice\": 1.0, \"loss_iou\": 1.0, \"loss_bce\": 0.8},\n",
    "            mode=\"weighted_sum\",\n",
    "        ),\n",
    "        dl.OptimizerCallback(metric_key=\"loss\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0666bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,4,figsize=(15,15))\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    images,mask = batch\n",
    "    batch_preds = torch.sigmoid(model(images.to(device)) )\n",
    "    batch_preds = batch_preds.detach().cpu()  \n",
    "    for i in range(len(images)+len(mask)+len(images)):\n",
    "        if i <len(images):\n",
    "            axs[0,i].imshow(batch_preds[i].squeeze(0).cpu().numpy(),cmap='gray')\n",
    "        elif i >=len(images) and i<(len(images)+len(mask)):\n",
    "            axs[1,i%4].imshow(images[i%4].permute(1,2,0).cpu().numpy())\n",
    "        else:\n",
    "            axs[2,i%4].imshow(mask[i%4].cpu().numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval\n",
    "with torch.no_grad():\n",
    "    loss = 0\n",
    "    criterion_bce = torch.nn.BCEWithLogitsLoss()\n",
    "    for batch in val_loader:\n",
    "        image, mask = batch[0].cuda(), batch[1].cuda()\n",
    "        result = model(image)\n",
    "        result = result.squeeze(1)\n",
    "        loss_bce = criterion_bce(result, mask) \n",
    "        loss +=  loss_bce.item()* image.size(0)\n",
    "    epoch_loss = loss / len(val_loader)\n",
    "    print(\"--------------------\")\n",
    "    print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23257819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval\n",
    "with torch.no_grad():\n",
    "    loss = 0\n",
    "    criterion_bce = torch.nn.BCEWithLogitsLoss()\n",
    "    for batch in test_loader:\n",
    "        image, mask = batch[0].cuda(), batch[1].cuda()\n",
    "        result = model(image)\n",
    "        result = result.squeeze(1)\n",
    "        loss_bce = criterion_bce(result, mask) \n",
    "        loss +=  loss_bce.item()* image.size(0)\n",
    "    epoch_loss = loss / len(val_loader)\n",
    "    print(\"--------------------\")\n",
    "    print(epoch_loss)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
