{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1c90ab",
   "metadata": {},
   "source": [
    "# Visualization - Using PCA\n",
    "\n",
    "This time, I will Visualization many columns using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ce4f5",
   "metadata": {},
   "source": [
    "#### Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4319a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3904d13",
   "metadata": {},
   "source": [
    "#### Load Dataset and Data Preprocessing\n",
    "\n",
    "I just dropped 'Id' column and, divide 'Cover_Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1237c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\n",
    "train = train.drop('Id',axis=1)\n",
    "\n",
    "X_train = train.drop('Cover_Type',axis=1)\n",
    "y_train = train['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab3c9b",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "PCA is one of the way to decrease column's length <br>\n",
    "Then, How we can find best n_components? <br>\n",
    "I usually using Eigen Vector <br>\n",
    "It mean that, how much n_component accommodate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e90d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(X_train.columns), svd_solver='auto')\n",
    "pca.fit(X_train)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot([*range(len(X_train.columns))], pca.explained_variance_ratio_)\n",
    "plt.xlim(0,10)\n",
    "plt.title(\"Eigen Vector\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How much n_components accommodate the data : ', sum(pca.explained_variance_ratio_[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3934840",
   "metadata": {},
   "source": [
    "Look this Eigen Vector chart. If you select 2, You can take the 95% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, svd_solver='auto')\n",
    "X_train = pca.fit_transform(X_train)\n",
    "train = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b124cc",
   "metadata": {},
   "source": [
    "#### 2D Viusailzation\n",
    "\n",
    "Now, we have only 2 columns and target data('Cover_Type'). <br>\n",
    "So we can visualization it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train['Cover_Type'].unique()\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for index in a:\n",
    "    plt.scatter(x=train[train['Cover_Type']==index][0], y=train[train['Cover_Type']==index][1], alpha=0.3)\n",
    "    \n",
    "plt.title(\"2D Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf6b",
   "metadata": {},
   "source": [
    "#### 3D Visualization\n",
    "\n",
    "How about using 3D visualization. <br>\n",
    "I think it's better way than using 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 13))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "for target_class in train['Cover_Type'].unique():\n",
    "    x = train[train['Cover_Type'] == target_class][0]\n",
    "    y = train[train['Cover_Type'] == target_class][1]\n",
    "    z = train[train['Cover_Type'] == target_class]['Cover_Type']\n",
    "    ax1.scatter(x, y, z, s= 10, alpha=0.05)\n",
    "    \n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "for target_class in train['Cover_Type'].unique():\n",
    "    sample_train = train[train['Cover_Type'] == target_class].sample(min(10000, train.Cover_Type.value_counts()[target_class]))\n",
    "    x = sample_train[0]\n",
    "    y = sample_train[1]\n",
    "    z = sample_train['Cover_Type']\n",
    "    ax2.scatter(x, y, z, s= 10, alpha=0.05)\n",
    "    \n",
    "ax1.set_title(\"3D scatter All scatter\")\n",
    "ax2.set_title(\"3D scatter Sample scatter - max 10000\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
