{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a311bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf835c",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float')/255.\n",
    "x_test = x_test.astype('float')/255.\n",
    "x_train = np.reshape(x_train, (60000, 784))\n",
    "x_test = np.reshape(x_test, (10000, 784))\n",
    "x_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071cf6d",
   "metadata": {},
   "source": [
    "## 2. Adding Noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = x_train + np.random.rand(60000, 784) * 0.9\n",
    "x_test_noisy = x_test + np.random.rand(10000, 784) * 0.9\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ebe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,predictions, labels=False):\n",
    "    plt.figure(figsize=(20,2))\n",
    "    for i in range(10):\n",
    "        plt.subplot(1,10,i+1)\n",
    "        plt.imshow(x[i].reshape(28,28),cmap=\"binary\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        if labels:\n",
    "            plt.xlabel(np.argmax(p[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40011e",
   "metadata": {},
   "source": [
    "We see the original images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_train,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6300c89",
   "metadata": {},
   "source": [
    "We see the noisy images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_train_noisy,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff9031",
   "metadata": {},
   "source": [
    "## 3. Building the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=256,activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(units=256,activation=\"relu\"))\n",
    "model.add(Dense(units=10,activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a038a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train,validation_data=(x_test,y_test), epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101a1ea",
   "metadata": {},
   "source": [
    "As seen our model's prediction is very low in the noisy images %97 versus %26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5220706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b7240",
   "metadata": {},
   "source": [
    "## 4. Building the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb634d28",
   "metadata": {},
   "source": [
    "<font color=\"green\">\n",
    "An autoencoder is an unsupervised learning technique for neural networks that learns efficient data representations (encoding) by training the network to ignore signal “noise.” Autoencoders can be used for image denoising, image compression, and, in some cases, even generation of image data.\n",
    "  \n",
    "Autoencoder gets the noisy images as input and the original images as output. This forces the model to learn the most important characteristics of the image like Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(784,))\n",
    "encoded = Dense(units=64,activation=\"relu\")(input_image) # This will reduce the dimensionality of the image and get the most important parts\n",
    "decoded = Dense(units=784,activation=\"sigmoid\")(encoded) # This will return 1 or 0 on the encoded pixels, so will reduce the noises.\n",
    "\n",
    "autoencoder = Model(input_image, decoded)\n",
    "autoencoder.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f06feb",
   "metadata": {},
   "source": [
    "## 5. Training the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x=x_train_noisy,y=x_train, epochs =100, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "print(' ***********************************************************************************')\n",
    "print('Training is complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb274f",
   "metadata": {},
   "source": [
    "## 6.Denoised Images and Evaluate Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f791dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_test_noisy, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(predictions, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb6557",
   "metadata": {},
   "source": [
    "Lets see the performance of our classifier with the denoised images. As seen below, we have almost the same accuracy as we had with the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74f651",
   "metadata": {},
   "source": [
    "## 7. Composite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image = Input(shape=(784,))\n",
    "x = autoencoder(noisy_image)\n",
    "y = model(x)\n",
    "\n",
    "denoise_and_classify = Model(noisy_image, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = denoise_and_classify.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_test_noisy, p, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_test_noisy, to_categorical(y_test), True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
