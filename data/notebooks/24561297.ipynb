{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,classification_report\n",
    "\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04251534",
   "metadata": {},
   "source": [
    "## Loading Train, Validate and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee140180",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../input/autism-prediction/Autism-prediction/train.csv')\n",
    "data_test = pd.read_csv('../input/autism-prediction/Autism-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25fab7",
   "metadata": {},
   "source": [
    "## Detailed EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test and Train Dataset Shape\n",
    "data_train.shape\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e2283",
   "metadata": {},
   "source": [
    "There are 800 datapoints with 21 features and 1 target variable in the train dataset.\n",
    "There are 200 datapoints with 21 features in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18db4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6191a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dtypes.value_counts()\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449e4e2",
   "metadata": {},
   "source": [
    "From above we can see that, there are -\n",
    "- 12 int type features\n",
    "- 8 object type features\n",
    "- 2 float type features\n",
    "\n",
    "**Class/ASD** is the Target Variable.\n",
    "And no NaN Values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing 'Class/ASD' for bias in the dataset\n",
    "data_train['Class/ASD'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519df40f",
   "metadata": {},
   "source": [
    "From above output, we can say that the data is biased.\n",
    "\n",
    "As we have 615 datapoints for Class '0' (No) and only 185 datapoints for Class '1' (Yes), we can say that the data is Imbalanced.\n",
    "\n",
    "And before building the model we will have to oversample the minority Class or apply SMOTE techniques. (I will cover this in my next notebook along with Model Building)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eea656",
   "metadata": {},
   "source": [
    "Lets look at the top and bottom 5 rows of the train data, to understand the features \n",
    "and there possible impact on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 rows of the train dataset\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb95d9",
   "metadata": {},
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0570a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 rows of the 'int64' type fetaures of the test dataset\n",
    "data_train.select_dtypes(include='int64').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff5d99",
   "metadata": {},
   "source": [
    "From above we can see that, all the 'int64' type features have binary values (0 or 1), except for ID, which is unique identification for patient. \n",
    "Since it is not required for model building. Let us drop it from both train and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns='ID', axis=1,inplace=True)\n",
    "test_df = data_test.drop(columns='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718053b",
   "metadata": {},
   "source": [
    "Let's look at the A1 to A10 Scores and there possible relation with target column 'Class/ASD'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('A1_Score')['Class/ASD'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0ac29",
   "metadata": {},
   "source": [
    "Patients with higer score are more likely to have Autism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 rows of the 'int64' type fetaures of the test dataset\n",
    "data_train.select_dtypes(include='object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6e98a",
   "metadata": {},
   "source": [
    "From above output we can see that- \n",
    "\n",
    "**gender,used_app_before** doesn't seem to be features with any importance, lets drop these columns.\n",
    "\n",
    "**jaundice, autism** are the binary variables - We will have to encode these before bulding the model.\n",
    "\n",
    "**ethnicity,contry_of_res,age_desc,relation** are nominal variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=['gender','used_app_before'], axis=1,inplace=True)\n",
    "test_df = test_df.drop(columns=['gender','used_app_before'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94cf28",
   "metadata": {},
   "source": [
    "Let us analyze the distribution of **ethnicity, contry_of_res and age_desc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d71b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['ethnicity'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('ethnicity')['Class/ASD'].mean().sort_values().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3bab7",
   "metadata": {},
   "source": [
    "There are 151 rows with '?' as the value. We will have to impute this before building the model. \n",
    "Also, Majority of the 'White-European' are diagnosed with Autism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182421a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['contry_of_res'].value_counts()\n",
    "data_train[data_train['contry_of_res']== '?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f18f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['age_desc'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056af8b7",
   "metadata": {},
   "source": [
    "**age_desc** column has 0 variance. Hence, this doesn't add any value to model building and can be dropped before building the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd323329",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns='age_desc', axis=1,inplace=True)\n",
    "test_df = test_df.drop(columns='age_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['relation'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('relation')['Class/ASD'].mean().plot.bar()\n",
    "plt.title('Relation of patient who completed the test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b1f66",
   "metadata": {},
   "source": [
    "There are 77 rows with '?' as the value. We will have to impute this (with mode) before building the model. Let us impute '?' with Others.\n",
    "Note - I think this feature is not important for model building, as we already have 'austim' column to checkl for immediate family member. There fore, once I will build the model including this feature and then will check my model performance without this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.loc[data_train.ethnicity == '?', 'ethnicity'] = 'Others'\n",
    "#test_df.loc[test_df.ethnicity == 'others', 'ethnicity'] = 'Others'\n",
    "#data_train.loc[data_train.ethnicity == '?', 'ethnicity'] = 'Others'\n",
    "#test_df.loc[test_df.ethnicity == 'others', 'ethnicity'] = 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e922d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('austim')['Class/ASD'].mean().plot.bar()\n",
    "plt.title('Imediate family member diagnosed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('jaundice')['Class/ASD'].mean().plot.bar()\n",
    "plt.title('Whether the patient had jaundice at the time of birth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=['ethnicity','contry_of_res', 'relation'], axis=1,inplace=True)\n",
    "test_df = test_df.drop(columns=['ethnicity','contry_of_res', 'relation'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e18f5",
   "metadata": {},
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13707a",
   "metadata": {},
   "source": [
    "From the above EDA it is clear that -\n",
    "- Person with higher scores are likely to have autism.\n",
    "- Person who had jaundice at the time of brith are more likely to have autism.\n",
    "- Person whoes immediate family member has autism is more likely to have autism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcd286",
   "metadata": {},
   "source": [
    "## Modelling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4f1b6",
   "metadata": {},
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304546b",
   "metadata": {},
   "source": [
    "#### First we will create a model with the imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the binary variables\n",
    "mapping = { 'yes' : 1 , 'no' : 0}\n",
    "\n",
    "for data in [data_train, test_df]:\n",
    "    data['jaundice']=data['jaundice'].replace(mapping).astype(float)\n",
    "    data['austim']=data['austim'].replace(mapping).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b541367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining feature and Target variables for training model\n",
    "X = data_train.drop('Class/ASD', axis=1)\n",
    "y = data_train['Class/ASD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print shape of X and y \n",
    "print(\"Shape of X is {}, and shape of y is {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train and test data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a40b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the Random Forest Classifier with n_estimator as 150\n",
    "rfc_model = RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b40b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "rfc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98898330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the y_pred_test\n",
    "y_pred_test = rfc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929aef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking accuracy score, confusion matrix and classification report on test data\n",
    "print(\"Accuracy score of RFC model on test dataset is : \")\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ec5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted values of y for test dataset\n",
    "y_pred_test = rfc_model.predict(test_df)\n",
    "\n",
    "#Creating a new dataframe with ID and predicted y values\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df['ID'] = data_test['ID']\n",
    "pred_df['Class/ASD'] = y_pred_test\n",
    "\n",
    "#Exporting the values to a csv file\n",
    "pred_df.to_csv('submission.csv', index = False )"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
