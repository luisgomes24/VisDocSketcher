{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0709583f",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Following cell of code is used everytime FASTAI library is used.\n",
    "#They tell the notebook to reload any changes made to any libraries used.\n",
    "#They also ensure that any graphs are plotted are shown in this notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbf7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\n",
    "skin_df = pd.read_csv(csv_path)\n",
    "skin_df.sort_values(by=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../input/skin-cancer-mnist-ham10000')\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee68ae",
   "metadata": {},
   "source": [
    "## Rename Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_to_full_name_dict = {\n",
    "    \"akiec\" : \"Bowen's disease\", # very early form of skin cancer \n",
    "    \"bcc\" : \"basal cell carcinoma\" , # basal-cell cancer or white skin cancer\n",
    "    \"bkl\" : \"benign keratosis-like lesions\", # non-cancerous skin tumour\n",
    "    \"df\" : \"dermatofibroma\", # non-cancerous rounded bumps \n",
    "    \"mel\" : \"melanoma\", # black skin cancer\n",
    "    \"nv\" : \"melanocytic nevi\", # mole non-cancerous\n",
    "    \"vasc\" : \"vascular lesions\", # skin condition\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9fc0e",
   "metadata": {},
   "source": [
    "# Get Images from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba25c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns only dx and image id column\n",
    "img_to_class_dict = skin_df.loc[:, [\"image_id\", \"dx\"]] \n",
    "# returns columns as lists in a dict\n",
    "img_to_class_dict = img_to_class_dict.to_dict('list')  \n",
    "# returns a dict mapping image id to disease name\n",
    "img_to_class_dict = {img_id : short_to_full_name_dict[disease] for img_id,disease in zip(img_to_class_dict['image_id'], img_to_class_dict['dx']) } \n",
    "[x for x in img_to_class_dict.items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ee925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path.stem returns the filename without suffix\n",
    "def get_label_from_dict(path):\n",
    "    return img_to_class_dict[path.stem] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a489f",
   "metadata": {},
   "source": [
    "# Constructing a DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    # Designation the independent and dependent variables\n",
    "    blocks = (ImageBlock, CategoryBlock), \n",
    "    # To get a list of those files,and returns a list of all of the images in that path\n",
    "    get_items = get_image_files, \n",
    "    # Split our training and validation sets randomly\n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    # We are telling fastai what function to call to create the labels in our dataset, in our case is independet variable\n",
    "    get_y = get_label_from_dict,\n",
    "    # DihedralItem all 4 90 deg roatations and for each: \n",
    "    #2 horizonntal flips -> 8 orientations\n",
    "    item_tfms=[Resize(448), DihedralItem()],\n",
    "    # Picks a random scaled crop of an image and resize it to size\n",
    "    batch_tfms=RandomResizedCrop(size=224, min_scale=0.75, max_scale=1.0))\n",
    "\n",
    "img_path = \"/kaggle/input/skin-cancer-mnist-ham10000\"\n",
    "# create dataloader using img_path   \n",
    "dls = dblock.dataloaders(img_path, bs=64) # bs = batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef679d9c",
   "metadata": {},
   "source": [
    "# Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed8644",
   "metadata": {},
   "source": [
    "Observations from these images will be noted below. First, I'll do some more checks to confirm our categories are just \"Bowen's disease\", 'basal cell carcinoma', 'benign keratosis-like lesions', 'dermatofibroma', 'melanocytic nevi', 'melanoma', 'vascular lesions':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dls.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3fdb6",
   "metadata": {},
   "source": [
    "Let's preview our datasets length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.train_ds), len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccad9f",
   "metadata": {},
   "source": [
    "# Train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a03b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls,\n",
    "                    resnet18,\n",
    "                    metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1542014",
   "metadata": {},
   "source": [
    "**train fit_one_cycle for 3 cycles get an idea of how accurate the model would be with resnet34.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae9c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls,resnet34, metrics = accuracy)\n",
    "learn.fit_one_cycle(3,1e-2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbc302",
   "metadata": {},
   "source": [
    "# Unfreezing and Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30 ,lr_max=slice(1e-4, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d22349",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2579460",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0442596",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675991c",
   "metadata": {},
   "source": [
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(6,6), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ffea4",
   "metadata": {},
   "source": [
    "# Top 6 losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(6, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc0288",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad503ce",
   "metadata": {},
   "source": [
    "[HAM10000 Vision ResNet18](https://www.kaggle.com/code/leonblum/ham10000-vision-resnet18-97-7-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1dc44",
   "metadata": {},
   "source": [
    "#### I hope you like it"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
