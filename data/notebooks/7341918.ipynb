{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "\n",
    "# Classifiers\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf33c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a 12-fold stratified cross-validation (note: shuffle=True)\n",
    "SEED = 42\n",
    "FOLDS = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "X = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/train.csv\")\n",
    "Xt = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/test.csv\")\n",
    "\n",
    "# Separating target and ids\n",
    "y = X.target.values\n",
    "id_train = X.id\n",
    "id_test = Xt.id\n",
    "\n",
    "X.drop(['id', 'target'], axis=1, inplace=True)\n",
    "Xt.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Classifying variables in binary, high and low cardinality nominal, ordinal and dates\n",
    "binary_vars = [c for c in X.columns if 'bin_' in c]\n",
    "\n",
    "nominal_vars = [c for c in X.columns if 'nom_' in c]\n",
    "high_cardinality = [c for c in nominal_vars if len(X[c].unique()) > 16]\n",
    "low_cardinality = [c for c in nominal_vars if len(X[c].unique()) <= 16]\n",
    "\n",
    "ordinal_vars = [c for c in X.columns if 'ord_' in c]\n",
    "\n",
    "time_vars = ['day', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some feature engineering\n",
    "X['ord_5_1'] = X['ord_5'].apply(lambda x: x[0] if type(x) == str else np.nan)\n",
    "X['ord_5_2'] = X['ord_5'].apply(lambda x: x[1] if type(x) == str else np.nan)\n",
    "Xt['ord_5_1'] = Xt['ord_5'].apply(lambda x: x[0] if type(x) == str else np.nan)\n",
    "Xt['ord_5_2'] = Xt['ord_5'].apply(lambda x: x[1] if type(x) == str else np.nan)\n",
    "\n",
    "ordinal_vars += ['ord_5_1', 'ord_5_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting ordinal labels into ordered values\n",
    "ordinals = {\n",
    "    'ord_1' : {\n",
    "        'Novice' : 0,\n",
    "        'Contributor' : 1,\n",
    "        'Expert' : 2,\n",
    "        'Master' : 3,\n",
    "        'Grandmaster' : 4\n",
    "    },\n",
    "    'ord_2' : {\n",
    "        'Freezing' : 0,\n",
    "        'Cold' : 1,\n",
    "        'Warm' : 2,\n",
    "        'Hot' : 3,\n",
    "        'Boiling Hot' : 4,\n",
    "        'Lava Hot' : 5\n",
    "    }\n",
    "}\n",
    "\n",
    "def return_order(X, Xt, var_name):\n",
    "    mode = X[var_name].mode()[0]\n",
    "    el = sorted(set(X[var_name].fillna(mode).unique())|set(Xt[var_name].fillna(mode).unique()))\n",
    "    return {v:e for e, v in enumerate(el)}\n",
    "\n",
    "for mapped_var in ordinal_vars:\n",
    "    if mapped_var not in ordinals:\n",
    "        mapped_values = return_order(X, Xt, mapped_var)\n",
    "        X[mapped_var + '_num'] = X[mapped_var].replace(mapped_values)\n",
    "        Xt[mapped_var + '_num'] = Xt[mapped_var].replace(mapped_values)\n",
    "    else:\n",
    "        X[mapped_var + '_num'] = X[mapped_var].replace(ordinals[mapped_var])\n",
    "        Xt[mapped_var + '_num'] = Xt[mapped_var].replace(ordinals[mapped_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38876eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming all the labels of all variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = [LabelEncoder() for _ in range(X.shape[1])]\n",
    "\n",
    "for col, column in enumerate(X.columns):\n",
    "    unique_values = pd.Series(X[column].append(Xt[column]).unique())\n",
    "    unique_values = unique_values[unique_values.notnull()]\n",
    "    label_encoders[col].fit(unique_values)\n",
    "    X.loc[X[column].notnull(), column] = label_encoders[col].transform(X.loc[X[column].notnull(), column])\n",
    "    Xt.loc[Xt[column].notnull(), column] = label_encoders[col].transform(Xt.loc[Xt[column].notnull(), column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with any residual missing value\n",
    "X = X.fillna(-1)\n",
    "Xt = Xt.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enconding frequencies instead of labels (so we have some numeric variables)\n",
    "def frequency_encoding(column, df, df_test=None):\n",
    "    frequencies = df[column].value_counts().reset_index()\n",
    "    df_values = df[[column]].merge(frequencies, how='left', \n",
    "                                   left_on=column, right_on='index').iloc[:,-1].values\n",
    "    if df_test is not None:\n",
    "        df_test_values = df_test[[column]].merge(frequencies, how='left', \n",
    "                                                 left_on=column, right_on='index').fillna(1).iloc[:,-1].values\n",
    "    else:\n",
    "        df_test_values = None\n",
    "    return df_values, df_test_values\n",
    "\n",
    "for column in X.columns:\n",
    "    train_values, test_values = frequency_encoding(column, X, Xt)\n",
    "    X[column+'_counts'] = train_values\n",
    "    Xt[column+'_counts'] = test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoding of selected variables\n",
    "import category_encoders as cat_encs\n",
    "\n",
    "cat_feat_to_encode = binary_vars + ordinal_vars + nominal_vars + time_vars\n",
    "smoothing = 0.3\n",
    "\n",
    "enc_x = np.zeros(X[cat_feat_to_encode].shape)\n",
    "\n",
    "for tr_idx, oof_idx in skf.split(X, y):\n",
    "    encoder = cat_encs.TargetEncoder(cols=cat_feat_to_encode, smoothing=smoothing)\n",
    "    \n",
    "    encoder.fit(X[cat_feat_to_encode].iloc[tr_idx], y[tr_idx])\n",
    "    enc_x[oof_idx, :] = encoder.transform(X[cat_feat_to_encode].iloc[oof_idx], y[oof_idx])\n",
    "    \n",
    "encoder.fit(X[cat_feat_to_encode], y)\n",
    "enc_xt = encoder.transform(Xt[cat_feat_to_encode]).values\n",
    "\n",
    "for idx, new_var in enumerate(cat_feat_to_encode):\n",
    "    new_var = new_var + '_enc'\n",
    "    X[new_var] = enc_x[:,idx]\n",
    "    Xt[new_var] = enc_xt[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all to dtype float32\n",
    "X = X.astype(np.float32)\n",
    "Xt = Xt.astype(np.float32)\n",
    "\n",
    "# Defining categorical variables\n",
    "cat_features = nominal_vars + ordinal_vars\n",
    "\n",
    "# Setting categorical variables to int64\n",
    "X[cat_features] = X[cat_features].astype(np.int64)\n",
    "Xt[cat_features] = Xt[cat_features].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a CatBoostClassifier with best parameters\n",
    "best_params = {'bagging_temperature': 0.8,\n",
    "               'depth': 5,\n",
    "               'iterations': 1000,\n",
    "               'l2_leaf_reg': 30,\n",
    "               'learning_rate': 0.05,\n",
    "               'random_strength': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV interations\n",
    "roc_auc = list()\n",
    "average_precision = list()\n",
    "oof = np.zeros(len(X))\n",
    "cv_test_preds = np.zeros(len(Xt))\n",
    "best_iteration = list()\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx, :], y[test_idx]\n",
    "    \n",
    "    train = Pool(data=X_train, \n",
    "             label=y_train,            \n",
    "             feature_names=list(X_train.columns),\n",
    "             cat_features=cat_features)\n",
    "\n",
    "    val = Pool(data=X_test, \n",
    "               label=y_test,\n",
    "               feature_names=list(X_test.columns),\n",
    "               cat_features=cat_features)\n",
    "\n",
    "    catb = CatBoostClassifier(**best_params,\n",
    "                          loss_function='Logloss',\n",
    "                          eval_metric = 'AUC',\n",
    "                          nan_mode='Min',\n",
    "                          thread_count=2,\n",
    "                          verbose = False)\n",
    "    \n",
    "    catb.fit(train,\n",
    "             verbose_eval=100, \n",
    "             early_stopping_rounds=50,\n",
    "             eval_set=val,\n",
    "             use_best_model=True,\n",
    "             #task_type = \"GPU\",\n",
    "             plot=False)\n",
    "    \n",
    "    best_iteration.append(catb.best_iteration_)\n",
    "    preds = catb.predict_proba(X_test)\n",
    "    oof[test_idx] = preds[:,1]\n",
    "    \n",
    "    # CV test prediction\n",
    "    Xt_pool = Pool(data=Xt[list(X_train.columns)],\n",
    "               feature_names=list(X_train.columns),\n",
    "               cat_features=cat_features)\n",
    "    \n",
    "    cv_test_preds += catb.predict_proba(Xt_pool)[:,1] / FOLDS\n",
    "    \n",
    "    roc_auc.append(roc_auc_score(y_true=y_test, y_score=preds[:,1]))\n",
    "    average_precision.append(average_precision_score(y_true=y_test, y_score=preds[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results to disk\n",
    "oof = pd.DataFrame({'id':id_train, 'catboost_oof': oof})\n",
    "oof.to_csv(\"oof.csv\", index=False)\n",
    "\n",
    "cv_submission = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/sample_submission.csv\")\n",
    "cv_submission.target = cv_test_preds\n",
    "cv_submission.to_csv(\"./catboost_cv_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b927e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average cv roc auc score %0.3f ± %0.3f\" % (np.mean(roc_auc), np.std(roc_auc)))\n",
    "print(\"Average cv roc average precision %0.3f ± %0.3f\" % (np.mean(average_precision), np.std(average_precision)))\n",
    "\n",
    "print(\"Roc auc score OOF %0.3f\" % roc_auc_score(y_true=y, y_score=oof.catboost_oof))\n",
    "print(\"Average precision OOF %0.3f\" % average_precision_score(y_true=y, y_score=oof.catboost_oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using catboost on all the data for predictions\n",
    "catb = CatBoostClassifier(**best_params,\n",
    "                          loss_function='Logloss',\n",
    "                          eval_metric = 'AUC',\n",
    "                          nan_mode='Min',\n",
    "                          thread_count=2,\n",
    "                          verbose = False)\n",
    "\n",
    "train = Pool(data=X, \n",
    "             label=y,            \n",
    "             feature_names=list(X_train.columns),\n",
    "             cat_features=cat_features)\n",
    "\n",
    "catb.fit(train,\n",
    "         verbose_eval=100,\n",
    "         #task_type = \"GPU\",\n",
    "         plot=False)\n",
    "\n",
    "Xt_pool = Pool(data=Xt[list(X_train.columns)],\n",
    "               feature_names=list(X_train.columns),\n",
    "               cat_features=cat_features)\n",
    "\n",
    "submission = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/sample_submission.csv\")\n",
    "submission.target = catb.predict_proba(Xt_pool)[:,1]\n",
    "submission.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
