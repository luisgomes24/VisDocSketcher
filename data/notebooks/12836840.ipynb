{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e765dc8",
   "metadata": {},
   "source": [
    "# Pose Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd791c",
   "metadata": {},
   "source": [
    "## [Code](https://www.kaggle.com/ashkhagan/pose-estimate)\n",
    "The kernel shows how to use the [tf_pose_estimation](https://github.com/ildoonet/tf-pose-estimation) package in Python on a series of running videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90f3f8",
   "metadata": {},
   "source": [
    "## Repro [Github](https://www.github.com/ildoonet/tf-pose-estimation)\n",
    "Install tf_pose and pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq git+https://www.github.com/ildoonet/tf-pose-estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 125\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tf_pose\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "def video_gen(in_path):\n",
    "    c_cap = cv2.VideoCapture(in_path)\n",
    "    while c_cap.isOpened():\n",
    "        ret, frame = c_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        yield c_cap.get(cv2.CAP_PROP_POS_MSEC), frame[:, :, ::-1]\n",
    "    c_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f037bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = glob('../input/20201112/*.mp4')\t#調整檔案路徑../input/20201112\n",
    "print(video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = glob('../input/20201112/*.mp4')\t#調整檔案路徑\n",
    "c_video = video_gen(video_paths[0])\n",
    "for _ in range(200):\t\t\t\t\t\t\t\t\t#擷取前200張\n",
    "    c_ts, c_frame = next(c_video)\n",
    "plt.imshow(c_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "tfpe = tf_pose.get_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6806184",
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = tfpe.inference(npimg=c_frame, upsample_size=4.0)\n",
    "print(humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a011a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = TfPoseEstimator.draw_humans(c_frame[:, :, ::-1], humans, imgcopy=False)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax1.imshow(new_image[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_to_dict = lambda c_fig: {'bp_{}_{}'.format(k, vec_name): vec_val \n",
    "                              for k, part_vec in c_fig.body_parts.items() \n",
    "                              for vec_name, vec_val in zip(['x', 'y', 'score'],\n",
    "                                                           (part_vec.x, 1-part_vec.y, part_vec.score))}\n",
    "c_fig = humans[0]\n",
    "body_to_dict(c_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1441e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FRAMES = 13000\n",
    "body_pose_list = []\n",
    "for vid_path in tqdm_notebook(video_paths, desc='Files'):\n",
    "    c_video = video_gen(vid_path)\n",
    "    c_ts, c_frame = next(c_video)\n",
    "    out_path = os.path.split(vid_path)[1].replace('.mp4','_out.mp4')\n",
    "    out = cv2.VideoWriter(out_path,\n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                          10, \n",
    "                          (c_frame.shape[1], c_frame.shape[0]))\n",
    "    for (c_ts, c_frame), _ in zip(c_video, \n",
    "                                  tqdm_notebook(range(MAX_FRAMES), desc='Frames')):\n",
    "        bgr_frame = c_frame[:,:,::-1]\n",
    "        humans = tfpe.inference(npimg=bgr_frame, upsample_size=4.0)\n",
    "        for c_body in humans:\n",
    "            body_pose_list += [dict(video=out_path, time=c_ts, **body_to_dict(c_body))]\n",
    "        new_image = TfPoseEstimator.draw_humans(bgr_frame, humans, imgcopy=False)\n",
    "        out.write(new_image)\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd31e8",
   "metadata": {},
   "source": [
    "## Output Body-Pose to .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba523ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "body_pose_df = pd.DataFrame(body_pose_list)\n",
    "body_pose_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71386705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for c_ax, (c_name, c_rows) in zip(m_axs, body_pose_df.groupby('video')):\n",
    "    for i in range(17):\n",
    "        c_ax.plot(c_rows['time'], c_rows['bp_{}_y'.format(i)], label='x {}'.format(i))\n",
    "    c_ax.legend()\n",
    "    c_ax.set_title(c_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for c_ax, (c_name, n_rows) in zip(m_axs, body_pose_df.groupby('video')):\n",
    "    for i in range(17):\n",
    "        c_rows = n_rows.query('bp_{}_score>0.6'.format(i)) # only keep confident results\n",
    "        c_ax.plot(c_rows['bp_{}_x'.format(i)], c_rows['bp_{}_y'.format(i)], label='BP {}'.format(i))\n",
    "    c_ax.legend()\n",
    "    c_ax.set_title(c_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fcb6e",
   "metadata": {},
   "source": [
    "## Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output body-pose .csv for analysis\n",
    "body_pose_df.to_csv('body_pose_ufc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8a7f1",
   "metadata": {},
   "source": [
    "## *Download .csv & .mp4 for sport analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3651417",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
