{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cf41d5",
   "metadata": {},
   "source": [
    "# [TPS-05] What if we assume that data are images ... Can we use convolution for this challange?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85daf63e",
   "metadata": {},
   "source": [
    "I love making AI fun. This is for fun ... or just this is not fun and you can find something cool with this experiment. I appreciate comments, feedback or any improvements for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df9bf7",
   "metadata": {},
   "source": [
    "# 0. PREPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47acb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2021\n",
    "img_rows, img_cols = 5, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd9126",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA AND TRANSFORM FOR NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445aa97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\", index_col = 'id')\n",
    "test = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\", index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates in dataset? This is noise ... kill them ....\n",
    "# I find it thanks @omarvivas: https://www.kaggle.com/c/tabular-playground-series-may-2021/discussion/236561\n",
    "\n",
    "train = train[~train.drop('target', axis = 1).duplicated()]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(train.drop(\"target\", axis = 1))\n",
    "lencoder = LabelEncoder()\n",
    "y = pd.DataFrame(lencoder.fit_transform(train['target']), columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state= RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393adfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype= np.float32) \n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test, dtype= np.float32) \n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test = np.array(test, dtype= np.float32)\n",
    "test = test.reshape(test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'X_test shape: {y_test.shape}')\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "test = test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42921d",
   "metadata": {},
   "source": [
    "# 2. VISUALIZE DATA (IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8a76a",
   "metadata": {},
   "source": [
    "## 2A. Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 25\n",
    "images = X_train[:num]\n",
    "labels = y_train[:num]\n",
    "\n",
    "num_row = 5\n",
    "num_col = 5\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(3*num_col,4*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title('Label: {}'.format(labels[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c3a12",
   "metadata": {},
   "source": [
    "## 2B. TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look on TSNE  \n",
    "train_sub = train.sample(10000, random_state= RANDOM_STATE)\n",
    "model = TSNE(n_components=2, random_state=0, perplexity= 50, n_iter=3000)\n",
    "tsne_data = model.fit_transform(StandardScaler().fit_transform(train_sub.drop('target', axis = 1).astype(float)))\n",
    "tsne_data = np.vstack((tsne_data.T, train_sub.target)).T\n",
    "\n",
    "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"D1\", \"D2\", \"target\"))\n",
    "\n",
    "sns.FacetGrid(tsne_df, hue=\"target\", height=6).map(plt.scatter, 'D1', 'D2').add_legend()\n",
    "plt.title('Perplexity= 50, n_iter=3000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044938f",
   "metadata": {},
   "source": [
    "## 2C. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = train.sample(10000, random_state= RANDOM_STATE)\n",
    "lda_data = LDA(n_components=3).fit_transform(train_sub.drop(columns='target'),train_sub.target)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(x = lda_data[:, 0], y = lda_data[:, 1], hue = 'target', data=train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275793c",
   "metadata": {},
   "source": [
    "## 2D. UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7859ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = train.sample(10000, random_state= RANDOM_STATE)\n",
    "embedding = umap.UMAP(random_state = RANDOM_STATE ,n_components=3).fit_transform(train_sub.drop(columns='target').to_numpy())\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(x = embedding[:, 0], y = embedding[:, 1], hue='target', data=train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3626d77c",
   "metadata": {},
   "source": [
    "# 2. Neural Network (Keras 2DConv)\n",
    "I take just simple NN architecture from cool MNIST dataset. You can just train this network as you can. ** Just play and have fun !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f51d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 4\n",
    "epochs = 50\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c7f97",
   "metadata": {},
   "source": [
    "## 2A. CONVERT TO CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23482ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d32a10",
   "metadata": {},
   "source": [
    "## 2B. DEFINE MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard model ... nothing special ... \n",
    "\n",
    "model = Sequential()\n",
    "x = Conv2D(256, kernel_size=(2, 2), padding='same', activation='relu', input_shape=input_shape)\n",
    "model.add(x)\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (2, 2), padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(32, (2, 2), padding='same', activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(63, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08eb9f",
   "metadata": {},
   "source": [
    "## 2C. TRAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc391879",
   "metadata": {},
   "outputs": [],
   "source": [
    " earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks = earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172c00a",
   "metadata": {},
   "source": [
    "## 2D. VISUALIZE TRAINING LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2a442",
   "metadata": {},
   "source": [
    "## 2E. MODEL EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy on test set: \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9ff4f",
   "metadata": {},
   "source": [
    "## 2F. HACK THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df22fc",
   "metadata": {},
   "source": [
    "### A. FILTERS - first conv layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, biases = x.get_weights()\n",
    "conv_weight = filters[:,:,0,:]\n",
    "\n",
    "# Check the shape of first Conv2D layer\n",
    "print(f'First conv2D shape: {filters.shape}')\n",
    "print(f'First conv2D output size: {x.output.shape} \\n')\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "print(\"First 16 filters of conv2D layer\")\n",
    "for i in range(1,17):\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(conv_weight[:,:,i], interpolation='nearest', cmap='gray', aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3abc4",
   "metadata": {},
   "source": [
    "### B. OUTPUTS\n",
    "How input looks like after filter application  ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d246858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.models import Model\n",
    "\n",
    "# I take one example from test dataset\n",
    "img = expand_dims(X_test[0], axis=0)\n",
    "\n",
    "# Then hijacked output from first layer\n",
    "model_first2D = Model(inputs=model.inputs, outputs=x.output)\n",
    "\n",
    "# Made prediction of first sample\n",
    "feature_maps = model_first2D.predict(img)\n",
    "\n",
    "# Plot all (32) images from our conv2D layer \n",
    "plt.figure(figsize = (40,20))\n",
    "square = 8\n",
    "ix = 1\n",
    "for _ in range(4):\n",
    "    for _ in range(square):\n",
    "        ax = plt.subplot(square, square, ix)\n",
    "        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray', interpolation='nearest')\n",
    "        ix += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce5a18",
   "metadata": {},
   "source": [
    "## 2F. PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3da98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c91dc",
   "metadata": {},
   "source": [
    "# 3. SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe57648",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\")\n",
    "\n",
    "predictions_df = pd.DataFrame(preds, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\n",
    "predictions_df['id'] = sub['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b430040",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"conv_net_submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
