{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037554f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0c0ac",
   "metadata": {},
   "source": [
    "# VARMA - Vector Autoregression with Moving Average\n",
    "The only difference with VAR model is that the error terms are given the moving averag representation of order(q)\n",
    "\n",
    "Data Source https://fred.stlouisfed.org/series/M2SL https://fred.stlouisfed.org/series/PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319732f",
   "metadata": {},
   "source": [
    "## Import Libraries and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12,5)\n",
    "%matplotlib inline\n",
    "\n",
    "# time series related \n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX,VARMAXResults\n",
    "\n",
    "# handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86122c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df = pd.read_csv('/kaggle/input/time-series-data-1/M2SLMoneyStock.csv',index_col=0, parse_dates=True)\n",
    "df.index.freq = 'MS'\n",
    "\n",
    "sp = pd.read_csv('/kaggle/input/time-series-data-1/PCEPersonalSpending.csv',index_col=0, parse_dates=True)\n",
    "sp.index.freq = 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77182a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(sp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the null values if any\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f94ed",
   "metadata": {},
   "source": [
    "## Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'M2 Money Stock vs. Personal Consumption Expenditures'\n",
    "ylabel= 'Billions of dollars'\n",
    "xlabel= ''\n",
    "\n",
    "ax = df['Spending'].plot(figsize=(12,5),title=title,legend=True)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "df['Money'].plot(legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2816fbb",
   "metadata": {},
   "source": [
    "## Test for Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c1aa6",
   "metadata": {},
   "source": [
    "Refer the other notebook https://www.kaggle.com/prakharprasad/time-series-vector-autoregression where the test for stationarity was done on both Money as well as the Spending feature. Order 2 difference makes the data stationary. For sake of brevity, I am skipping this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09872efc",
   "metadata": {},
   "source": [
    "## Decide the order of the VARMA(p,q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(df['Money'],maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed646d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(df['Spending'],maxiter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db471ef6",
   "metadata": {},
   "source": [
    "Order (1,2) is preferred for VARMA. The last term or the third terms is the differencing which will be applied already using differencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5853921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df.diff().diff() # 2nd order difference\n",
    "df_transformed = df_transformed.dropna() # remove the NaNs introduced due to differencing\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a030d0",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 12 # The last 12 months will be the test data. At least 1 year would be a good choice\n",
    "train = df_transformed[0:-nobs]\n",
    "test = df_transformed[-nobs:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aa1d7",
   "metadata": {},
   "source": [
    "## Fit the VARMA(1,2) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VARMAX(train, order=(1,2), trend='c') # c indicates a constant trend\n",
    "results = model.fit(maxiter=1000, disp=False)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a11e9",
   "metadata": {},
   "source": [
    "## Predict the next 12 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = results.forecast(12)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080ebbe",
   "metadata": {},
   "source": [
    "## Invert the Transformations \n",
    "The data used for prediction was of 2nd order difference. The forecast would also be similar and hence it needs to be inverted to retrieve the true values which we can compare the original Money and Spending in the last 12 months dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8d896",
   "metadata": {},
   "source": [
    "To roll back a first-order difference we take the most recent value on the training side of the original series, and add it to a cumulative sum of forecasted values. When working with second-order differences we first must perform this operation on the most recent first-order difference.\n",
    "\n",
    "Here we'll use the <tt>nobs</tt> variable we defined during the train/test/split step.\n",
    "\n",
    "**This was the toughest part to figure out. Best way is to take a small dataset and try this out manually, come out with the step or formula and generalize on the entire dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc187ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the most recent first difference from the training side of the original dataset to the forecast cumulative sum\n",
    "df_forecast['Money1d'] = (df['Money'].iloc[-nobs-1]-df['Money'].iloc[-nobs-2]) + df_forecast['Money'].cumsum()\n",
    "# Now build the forecast values from the first difference set\n",
    "df_forecast['MoneyForecast'] = df['Money'].iloc[-nobs-1] + df_forecast['Money'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the most recent first difference from the training side of the original dataset to the forecast cumulative sum\n",
    "df_forecast['Spending1d'] = (df['Spending'].iloc[-nobs-1]-df['Spending'].iloc[-nobs-2]) + df_forecast['Spending'].cumsum()\n",
    "\n",
    "# Now build the forecast values from the first difference set\n",
    "df_forecast['SpendingForecast'] = df['Spending'].iloc[-nobs-1] + df_forecast['Spending'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89de975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab97053",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.iloc[-12:],df_forecast[['MoneyForecast','SpendingForecast']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adbbf1",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Money'][-nobs:].plot(figsize=(12,5),legend=True).autoscale(axis='x',tight=True)\n",
    "df_forecast['MoneyForecast'].plot(legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62efe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Spending'][-nobs:].plot(figsize=(12,5),legend=True).autoscale(axis='x',tight=True)\n",
    "df_forecast['SpendingForecast'].plot(legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a2075",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1 = rmse(df['Money'][-nobs:], df_forecast['MoneyForecast'])\n",
    "print(f'Money VAR(5) RMSE: {RMSE1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE2 = rmse(df['Spending'][-nobs:], df_forecast['SpendingForecast'])\n",
    "print(f'Spending VAR(5) RMSE: {RMSE2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72fe00e",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed98d0",
   "metadata": {},
   "source": [
    "**The VARMA model fits very poorly for this dataset. Perhaps there is no good relationship between the Spending and and the Personal Disposable Income atleast for the period that I investigated here. Next step could be to compare the results to the ARMA or other models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8100901",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
