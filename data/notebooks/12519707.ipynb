{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48b1558",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">GitHub Bug Prediction Model using BERT</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19652891",
   "metadata": {},
   "source": [
    "In this notebook, I have implemented a BERT-based model that can classify a GitHub title and body into three categories: Bugs, Features and Questions. Here, I have employed BERT-base uncased model for performing the classification task. The notebook has been organized as follows:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "     * Most common terms employed when referring to a GitHub *Bug*\n",
    "     * Most common terms employed when referring to a GitHub *feature*\n",
    "     * Most common terms employed when referring to a GitHub *questions*\n",
    "\n",
    "2. Model Architecture\n",
    "3. Preprocessing GitHub messages\n",
    "4. Importing Transformer, PyTorch library and constructing the BERT model.\n",
    "5. Class definition of GitHub messages\n",
    "6. Creating training, testing and validation data\n",
    "7. Creating data loaders\n",
    "8. Class for BERT-based GitHub Bug Predictor model\n",
    "9. Training the model\n",
    "10. Results and evaluation\n",
    "11. Future improvements\n",
    "12. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2022350",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe out of embol_train.json\n",
    "df = pd.read_json('/kaggle/input/github-bugs-prediction/embold_train.json')\n",
    "df['combined'] = df['title']+'. '+df['body']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bug = df[df['label']==0]\n",
    "df_feature = df[df['label']==1]\n",
    "df_question = df[df['label']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e058232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def punctuation_stopwords_removal(git_text):\n",
    "    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n",
    "    remove_punctuation = [ch for ch in git_text if ch not in punctuation]\n",
    "    # convert them back to sentences and split into words\n",
    "    remove_punctuation = \"\".join(remove_punctuation).split()\n",
    "    filtered_git_text = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n",
    "    return filtered_git_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabeef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_most_common_words(df_category, category):\n",
    "    df_category['combined'] = df_category['combined'].apply(lambda x: x.replace(\"\\\\r\", \"\"))\n",
    "    df_category['combined'] = df_category['combined'].apply(lambda x: clean_text(x))\n",
    "    \n",
    "    df_category[\"combined\"] = df_category[\"combined\"].apply(punctuation_stopwords_removal)\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    for i, j in df_category.iterrows():\n",
    "        for word in j['combined']:\n",
    "            word_list.append(word)\n",
    "        \n",
    "    count_dict = Counter(word_list)\n",
    "    most_common_words_df = pd.DataFrame(count_dict.most_common(20), columns=['word', 'count'])\n",
    "    fig = px.histogram(most_common_words_df,\n",
    "                       x='word', \n",
    "                       y='count',\n",
    "                       title='Most common terms used while refering to a GitHub {}'.format(category),\n",
    "                       color_discrete_sequence=['#843B62'] )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only a subset; since huge dataset\n",
    "plot_most_common_words(df_bug[:10000], 'Bugs üï∑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_words(df_feature[:7000], 'Features üí°')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30232e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_words(df_question[:7000], 'Questions ‚ÅâÔ∏è')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f198101",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Model Architecture</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb857b0",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e8887",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Preprocessing GitHub Messages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f50ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "label 0: Bug\n",
    "label 1: Feature\n",
    "label 2: Question\n",
    "\"\"\"\n",
    "df['combined'] = df['combined'].apply(lambda x: x.replace(\"\\\\r\", \"\"))\n",
    "df['combined'] = df['combined'].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['title', 'body'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e14bb",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Importing Transformer, PyTorch Libraries and constructing BERT model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ec4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading our BERT model\n",
    "BERT_UNCASED = '/kaggle/input/bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the pre-trained BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_UNCASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab924f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic operations to understand how BERT converts a sentence into tokens and then into IDs\n",
    "sample_body = 'script stopped adding videos saenzramiro abc xyz'\n",
    "tokens = tokenizer.tokenize(sample_body)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_body}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using encode_plus to add special tokens : [CLS]:101, [SEP]:102, [PAD]:0\n",
    "encodings = tokenizer.encode_plus(\n",
    "            sample_body,\n",
    "            max_length=32,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    ")\n",
    "\n",
    "encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input IDs : {}'.format(encodings['input_ids'][0]))\n",
    "print('\\nAttention Mask : {}'.format(encodings['attention_mask'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bb42a",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Class for our GitHub messages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab34ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubCommitMessages(Dataset):\n",
    "    \n",
    "    def __init__(self, commit_message, label, tokenizer, max_len):\n",
    "        self.commit_message = commit_message\n",
    "        self.label = label\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.commit_message)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        commit_message = str(self.commit_message[item])\n",
    "        label = self.label[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        commit_message,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt')\n",
    "        return {\n",
    "        'commit_message': commit_message,\n",
    "         'input_ids': encoding['input_ids'],\n",
    "         'attention_mask': encoding['attention_mask'],\n",
    "         'label': torch.tensor(label, dtype=torch.long)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027150d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45577a97",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Creating training, testing and validation data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d69e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "testing_data, validation_data = train_test_split(\n",
    "    testing_data,\n",
    "    test_size=0.5,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c29c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape, testing_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda7be19",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Creating data loaders</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94626d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(data, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    ds = GitHubCommitMessages(commit_message=data.combined.to_numpy(),\n",
    "    label=data.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len)\n",
    "    \n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_data_loader = create_data_loader(training_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
    "testing_data_loader = create_data_loader(testing_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(validation_data, tokenizer, MAX_LENGTH, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(iter(train_data_loader))\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'].squeeze().shape, df['attention_mask'].squeeze().shape, df['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('commit_message  : ', df['commit_message'][0])\n",
    "print('input_ids : ', df['input_ids'].squeeze()[0])\n",
    "print('attention_mask : ', df['attention_mask'].squeeze()[0])\n",
    "print('label : ', df['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(BERT_UNCASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encodings['input_ids'],\n",
    "  attention_mask=encodings['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state.shape, pooled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7af14c",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Class for our BERT-based GitHub Bug Predictor model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(BugPredictor, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_UNCASED)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert_model.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert_model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask = attention_mask\n",
    "        )\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.out(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "label 0: Bug\n",
    "label 1: Feature\n",
    "label 2: Question\n",
    "\"\"\"\n",
    "class_names = [0, 1, 2]\n",
    "bug_predictor_model = BugPredictor(len(class_names))\n",
    "bug_predictor_model = bug_predictor_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bf6bd",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Training the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW(bug_predictor_model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].squeeze().to(device)\n",
    "        attention_mask = d['attention_mask'].squeeze().to(device)\n",
    "        targets = d['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds==targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce51308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d['input_ids'].squeeze().to(device)\n",
    "            attention_mask = d['attention_mask'].squeeze().to(device)\n",
    "            targets = d['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds==targets)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cfdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}/{}'.format(epoch+1,EPOCHS))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    train_acc, train_loss = train_model(bug_predictor_model, train_data_loader, loss_fn, optimizer, device, scheduler, len(training_data))\n",
    "    \n",
    "    print('Train loss : {} accuracy : {}'.format(train_loss, train_acc))\n",
    "    \n",
    "    val_acc, val_loss = eval_model(bug_predictor_model, val_data_loader, loss_fn, device, len(validation_data))\n",
    "    \n",
    "    print('Validation loss : {} accuracy : {}'.format(val_loss, val_acc))\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        print('Saving the best model ...')\n",
    "        torch.save(bug_predictor_model.state_dict(), 'best_model.bin')\n",
    "        best_accuracy = val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5146bd",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Results and Evaluation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c21c0",
   "metadata": {},
   "source": [
    "<h4>So our BERT-based GitHub bug predictor model achieved training accuracy of 96.5% and validation accuracy of 85%. Let us see some sample Git messages and categorize them into bugs, features and questions based on our model!<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bug_message = \"Script stopped adding video's. A recent change in the youtube layout broke the script. Probably caused by element names being altered.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['bug', 'feature', 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_git_category(sample_message, model):\n",
    "    encoded_message = tokenizer.encode_plus(sample_bug_message, max_length=MAX_LENGTH, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
    "    input_ids = encoded_message['input_ids'].to(device)\n",
    "    attention_mask = encoded_message['attention_mask'].to(device)\n",
    "    \n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    _, prediction_idx = torch.max(output, dim=1)\n",
    "        \n",
    "    return class_names[prediction_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample bug message : ', sample_bug_message)\n",
    "print('Predicted GitHub Category : ', predict_git_category(sample_bug_message, bug_predictor_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b3f72",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">Future Improvements</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa1e7f",
   "metadata": {},
   "source": [
    "1. Due to low computational resources,  was not able to leverage the entire dataset for training the BERT model. \n",
    "2. I still need to employ BERT large model to test its accuracy on GitHub message classification use-case.\n",
    "3. The model was trained on only 5 epochs, which I feel can be increased.\n",
    "4. The dataset provided has rich textual information. This can be leveraged for other NLP tasks such as natural language generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bfe57",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#7AE7C7;text-align:center\">References</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39c232",
   "metadata": {},
   "source": [
    "1. https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "2. https://huggingface.co/transformers/\n",
    "3. http://jalammar.github.io"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
