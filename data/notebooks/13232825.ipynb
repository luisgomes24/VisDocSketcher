{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e988703",
   "metadata": {},
   "source": [
    "In the second phase, we will be doing machine learning to estimate porosity\n",
    "We read our three batches as follow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cbe32",
   "metadata": {},
   "source": [
    "First step, reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec10c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TF+CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "fd = '../input/batch-combined/Porosity Image J.xlsx'\n",
    "\n",
    "# tabular data for first and second batches are placed in first and second sheets of our excel sheet, respectively\n",
    "\n",
    "batch_train = pd.DataFrame(pd.read_excel(fd, sheet_name = 0))\n",
    "batch_test = pd.DataFrame(pd.read_excel(fd, sheet_name = 'Batch3'))\n",
    "batch_train['ID'] = batch_train['ID'].str.replace('batch1:', 'batch1_')\n",
    "batch_train['ID'] = batch_train['ID'].str.replace('batch2:', 'batch2_')\n",
    "batch_test['ID'] = batch_test['ID'].str.replace('batch3:', '')\n",
    "batch_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b82d75",
   "metadata": {},
   "source": [
    "Second step, convolutional neural network to classify images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8dcbf",
   "metadata": {},
   "source": [
    "Using convolutional neural network (cnn), we classify images into four different categories\n",
    "0% to 10% is class one\n",
    "10% to 20% is class two\n",
    "20% to 30% is class three\n",
    "30% to 100% is class four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0934d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_porosity=[]\n",
    "for i in range(len(batch_train)):\n",
    "    if batch_train['porosity(%)'][i] <= 10:\n",
    "        class_of_porosity.append(0)\n",
    "    elif batch_train['porosity(%)'][i]> 10 and batch_train['porosity(%)'][i] <= 20:\n",
    "        class_of_porosity.append(1)\n",
    "    elif batch_train['porosity(%)'][i]> 20 and batch_train['porosity(%)'][i] <= 30:\n",
    "        class_of_porosity.append(2)\n",
    "    else:\n",
    "        class_of_porosity.append(3)\n",
    "batch_train['category']=pd.DataFrame(class_of_porosity)\n",
    "batch_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e5113",
   "metadata": {},
   "source": [
    "We do porosity classification for test dataset as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_porosity=[]\n",
    "for i in range(len(batch_test)):\n",
    "    if batch_test['porosity(%)'][i] <= 10:\n",
    "        class_of_porosity.append(0)\n",
    "    elif batch_test['porosity(%)'][i]> 10 and batch_test['porosity(%)'][i] <= 20:\n",
    "        class_of_porosity.append(1)\n",
    "    elif batch_test['porosity(%)'][i]> 20 and batch_test['porosity(%)'][i] <= 30:\n",
    "        class_of_porosity.append(2)\n",
    "    else:\n",
    "        class_of_porosity.append(3)\n",
    "batch_test['category']=pd.DataFrame(class_of_porosity)\n",
    "batch_test.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843d6ef",
   "metadata": {},
   "source": [
    "Then, we represent classified porosity for train(blue) and test(orange) data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train.category.hist();\n",
    "batch_test.category.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28baabdd",
   "metadata": {},
   "source": [
    "Third step, application of cnn for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f24e",
   "metadata": {},
   "source": [
    "Image IDs will be used to help us read images, also the categories will be the labels assigned to each figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_excel(fd, sheet_name = 'Batch2'+'train.excel')\n",
    "file_paths=batch_train['ID'].values\n",
    "labels=batch_train['category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c2b77",
   "metadata": {},
   "source": [
    "In this step, we split file path from labels to define training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train=tf.data.Dataset.from_tensor_slices((file_paths,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32214a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=batch_test['ID'].values\n",
    "labels=batch_test['category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49f549",
   "metadata": {},
   "source": [
    "We also define testing dataset as follow, which has two components (file path and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test=tf.data.Dataset.from_tensor_slices((file_paths,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b45a47",
   "metadata": {},
   "source": [
    "The data from first two batches are combined. Therefore, we have 200 data to train cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_file, label):\n",
    "    image=tf.io.read_file('../input/batch-combined/batch1and2/'+ image_file+'.png')\n",
    "    image=tf.image.decode_image(image,dtype=tf.float32)\n",
    "    return image, label\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label \n",
    "ds_train=ds_train.map(read_image).map(augment).batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6041d9",
   "metadata": {},
   "source": [
    "Similarly, testing data (100 rows of data) is imported to be used as validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_file, label):\n",
    "    image=tf.io.read_file('../input/cee-498-project8-pore-in-concrete/batch3/batch3/'+ image_file+'.png')\n",
    "    image=tf.image.decode_image(image,dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637e045",
   "metadata": {},
   "source": [
    "Batch input dimension is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test=ds_test.map(read_image).batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcea4d9",
   "metadata": {},
   "source": [
    "To avoid overfitting, images will analysis using different preprocessing methods including flip, rotation, resizing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.5),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.5),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.5),\n",
    "        layers.experimental.preprocessing.RandomCrop(100, 100, seed=None, name=None),\n",
    "        layers.experimental.preprocessing.Resizing(100, 100, interpolation='bilinear', name=None),\n",
    "#         layers.experimental.preprocessing.RandomContrast(1, seed=None, name=None)\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 192, 256\n",
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(height, width, 3),\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(height, width, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "\n",
    "# Pre-trained Xception weights requires that input be normalized\n",
    "# from (0, 255) to a range (-1., +1.), the normalization layer\n",
    "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
    "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "mean = np.array([127.5] * 3)\n",
    "var = mean ** 2\n",
    "# Scale inputs to [-1, +1]\n",
    "x = norm_layer(inputs)\n",
    "norm_layer.set_weights([mean, var])\n",
    "\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# outputs = keras.layers.Dense(1)(x)\n",
    "# model = keras.Model(inputs, outputs)\n",
    "\n",
    "num_outputs = 4 # This is the number of output variables we want, 196 in this case.\n",
    "outputs = keras.layers.Dense(num_outputs, activation=\"softmax\")(x) # Use activation=softmax for classification, and activation=None for regression.\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# Configure and compile the model\n",
    "#model = Model(base_model.input, x)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(lr=0.0001),\n",
    "#               metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef401a",
   "metadata": {},
   "source": [
    "cnn hyperparameters are defined to get optimal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5.0e-5\n",
    "# model = tf.keras.models.Sequential()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 75\n",
    "history = model.fit(ds_train, epochs=epochs, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f525c",
   "metadata": {},
   "source": [
    "The next cell represents loss(error) of image classification vs. Epochs, for both training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.plot(history.history['loss'], color='b', label=\"Loss\")\n",
    "plt.plot(history.history['val_loss'], color='g', label=\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d8e66",
   "metadata": {},
   "source": [
    "The next cell represents accuracy of image classification vs. Epochs, for both training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59997297",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='b', label=\"Loss\")\n",
    "# plt.plot(history.history['val_sparse_categorical_accuracy'], color='b', label=\"Loss\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289caae",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "cnn categorized images with 45% accuracy which is desired."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
