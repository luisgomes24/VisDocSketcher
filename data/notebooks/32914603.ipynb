{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretty_midi -q\n",
    "# !apt install fluidsynth -q -y\n",
    "# !cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cac5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pretty_midi\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from tqdm.notebook import tqdm\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d211382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Detect TPU, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    print('Not running on TPU')\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "    print('batch size =', BATCH_SIZE)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "NUMBER_OF_PIANO_NOTES = 128\n",
    "SEQ_LENGTH = 100\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(directory):\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            filenames.append(f)\n",
    "    return filenames\n",
    "\n",
    "def load_roll(path):\n",
    "    return np.load(path, allow_pickle=True)\n",
    "\n",
    "def save_roll(array_map, path):\n",
    "    np.savez_compressed(path, **array_map)\n",
    "\n",
    "def save_string_notes(directory, name):\n",
    "    filenames = get_filenames(directory)\n",
    "    saved_rolls = {}\n",
    "    files_saved = 0\n",
    "    for index, filename in enumerate(tqdm(filenames)):\n",
    "        pm = pretty_midi.PrettyMIDI(filename)\n",
    "        notes = []\n",
    "        try:\n",
    "            instrument = pm.instruments[0]\n",
    "        except IndexError:\n",
    "            print(\"Skipped\")\n",
    "            continue\n",
    "        sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "        if len(sorted_notes) > 100:\n",
    "            prev_start = sorted_notes[0].start\n",
    "            for note in sorted_notes:\n",
    "                notes.append(note.pitch)\n",
    "            saved_rolls[str(index)] = np.array(notes)\n",
    "        if len(saved_rolls) % 5000 == 0 and len(saved_rolls) != 0:\n",
    "            files_saved += 1\n",
    "            save_roll(saved_rolls, name)\n",
    "            print(f\"Saved file {name}\")\n",
    "            saved_rolls = {}\n",
    "    if len(saved_rolls) != 0:\n",
    "        files_saved += 1\n",
    "        save_roll(saved_rolls, name)\n",
    "        print(f\"Saved file {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_roll('/kaggle/input/maestro-merged-npz/maestro_notes.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = np.empty(0,)\n",
    "for item in tqdm(data.values()):\n",
    "    all_notes = np.append(all_notes, item)\n",
    "all_notes = all_notes.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ea82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = tf.data.Dataset.from_tensor_slices(all_notes)\n",
    "train_size = int(0.8 * len(all_notes))\n",
    "test_size = int(0.2 * len(all_notes))\n",
    "\n",
    "full_dataset = full_dataset.shuffle(buffer_size=len(all_notes))\n",
    "train_dataset = full_dataset\n",
    "# train_dataset = full_dataset.take(train_size)\n",
    "# test_dataset = full_dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76075393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "# print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf358227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(dataset, seq_length, vocab_size):\n",
    "  seq_length = seq_length+1\n",
    "\n",
    "  windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True)\n",
    "\n",
    "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "  sequences = windows.flat_map(flatten)\n",
    "\n",
    "  def scale_pitch(x):\n",
    "    x = x/[vocab_size]\n",
    "    return x\n",
    "\n",
    "  def split_labels(sequences):\n",
    "    inputs = sequences[:-1]\n",
    "    labels = sequences[-1]\n",
    "\n",
    "    return scale_pitch(inputs), labels\n",
    "\n",
    "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbabd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = create_sequences(train_dataset, SEQ_LENGTH, NUMBER_OF_PIANO_NOTES)\n",
    "# test_seq = create_sequences(train_dataset, SEQ_LENGTH, NUMBER_OF_PIANO_NOTES)\n",
    "\n",
    "train_loader = (train_seq\n",
    "            .repeat()\n",
    "            .batch(BATCH_SIZE, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "# test_loader = (test_seq\n",
    "#             .repeat()\n",
    "#             .batch(BATCH_SIZE, drop_remainder=True)\n",
    "#             .cache()\n",
    "#             .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (SEQ_LENGTH, 1)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# # opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "\n",
    "model_type = 1\n",
    "\n",
    "if model_type == 1:\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM(512, input_shape=input_shape, recurrent_dropout=0.3, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3))\n",
    "        model.add(tf.keras.layers.LSTM(512))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Dense(256))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Dense(NUMBER_OF_PIANO_NOTES))\n",
    "        model.add(tf.keras.layers.Activation('softmax'))\n",
    "        \n",
    "else:\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM(128, input_shape = input_shape, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LSTM(128))\n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "        model.add(tf.keras.layers.Dense(NUMBER_OF_PIANO_NOTES))\n",
    "        model.add(tf.keras.layers.Activation('softmax'))\n",
    "        \n",
    "if tpu:\n",
    "    steps_per_execution = 32\n",
    "    model.compile(loss=loss, optimizer=opt, steps_per_execution=steps_per_execution)\n",
    "else:\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba492af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "    model = tf.keras.models.load_model('/kaggle/input/tpu-ckpt-50-maestro/tpu_ckpt_5_maestro', options=load_locally)\n",
    "    steps_per_execution = 32\n",
    "    model.compile(loss=loss, optimizer=opt, steps_per_execution=steps_per_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tpu:\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    checkpoints = tf.keras.callbacks.ModelCheckpoint('tpu_checkpoints', options=save_locally)\n",
    "else:\n",
    "    checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath='training_checkpoints/ckpt_{epoch}', save_weights_only=True)\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, verbose=2, restore_best_weights=True),\n",
    "\n",
    "callbacks = [\n",
    "    checkpoints,\n",
    "    es,\n",
    "]\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_loader,\n",
    "  steps_per_epoch= len(train_dataset) // BATCH_SIZE // 10,\n",
    "#   validation_data = test_loader,\n",
    "#   validation_steps = len(test_dataset) // BATCH_SIZE,\n",
    "  epochs=epochs,\n",
    "  callbacks=callbacks,\n",
    ")\n",
    "\n",
    "plt.plot(history.epoch, history.history['loss'], label=f'train loss')\n",
    "# plt.plot(history.epoch, history.history['val_loss'], label=f'val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive('tpu_ckpt_5', 'zip', '/kaggle/working/tpu_checkpoints/ckpt_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    model.save('./best_model', options=save_locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_note(notes, keras_model, temperature) -> int:\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  notes = tf.expand_dims(notes, 0)\n",
    "  predictions = keras_model.predict(notes, verbose = 0)\n",
    "  pitch_logits = predictions\n",
    "#   print(pitch_logits)\n",
    "  pitch_logits /= temperature\n",
    "#   print(np.argmax(pitch_logits))\n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "  while not 40 < pitch < 80:\n",
    "      pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "#   print(pitch)\n",
    "#   print('tf categorical', tf.random.categorical(pitch_logits, num_samples=1))\n",
    "  pitch = tf.squeeze(pitch, axis=-1)\n",
    "  return int(pitch)\n",
    "\n",
    "def predict_sequence(seed, model, num_predictions, temperature):\n",
    "\n",
    "    current_sequence = seed\n",
    "    generated_sequence = []\n",
    "    for _ in tqdm(range(num_predictions)):\n",
    "      pitch = predict_next_note(current_sequence, model, temperature)\n",
    "      generated_sequence.append(pitch)\n",
    "      current_sequence = np.delete(current_sequence, 0, axis=0)\n",
    "\n",
    "      current_sequence = np.append(current_sequence, np.reshape(pitch, (-1, 1)), axis=0)\n",
    "\n",
    "    generated_sequence = np.array(generated_sequence)\n",
    "    return generated_sequence\n",
    "\n",
    "\n",
    "def notes_to_midi(notes, out_file, is_original: bool=False, velocity = 100, step = 0.2, duration = 0.4):\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          \"Acoustic Grand Piano\")\n",
    "      )\n",
    "\n",
    "  prev_start = 0\n",
    "  for note in notes:\n",
    "    start = float(prev_start + step)\n",
    "    end = float(start + duration)\n",
    "    if is_original is True:\n",
    "        input_pitch=int(note * NUMBER_OF_PIANO_NOTES)\n",
    "    else:\n",
    "        input_pitch = int(note)\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=input_pitch,\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm\n",
    "\n",
    "def midi_to_notes(path):\n",
    "    saved_rolls = 0\n",
    "    pm = pretty_midi.PrettyMIDI(path)\n",
    "    notes = []\n",
    "    try:\n",
    "        instrument = pm.instruments[0]\n",
    "    except IndexError:\n",
    "        print(\"Skipped\")\n",
    "        return None\n",
    "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "    if len(sorted_notes) > 100:\n",
    "        prev_start = sorted_notes[0].start\n",
    "        for note in sorted_notes:\n",
    "            notes.append(note.pitch)\n",
    "        saved_rolls = np.array(notes)\n",
    "    if len(saved_rolls) % 5000 == 0 and len(saved_rolls) != 0:\n",
    "        files_saved += 1\n",
    "    return saved_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = midi_to_notes('/kaggle/input/mozart-v2/Wolfgang Amadeus Mozart/Mozart Wolfgang Amadeus Fantasia in C minor K.475 Ui9pyxdVX6Y.mid')\n",
    "# seed = seed[100:200].reshape(-1, 1) / NUMBER_OF_PIANO_NOTES\n",
    "\n",
    "seed = np.random.randint(low=40, high=100, size=(100, 1)) / NUMBER_OF_PIANO_NOTES\n",
    "\n",
    "original = notes_to_midi(seed, f'original_test.mid', is_original=True) \n",
    "generated = notes_to_midi(predict_sequence(seed, model, num_predictions = 200, temperature = 1), f'generated_test.mid', step = 0.25, duration = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# directory = '/kaggle/input/mozart-v2/Wolfgang Amadeus Mozart'\n",
    "# for filename in os.listdir(directory):\n",
    "#     f = os.path.join(directory, filename)\n",
    "#     if os.path.isfile(f):\n",
    "#         try:\n",
    "#             seed = midi_to_notes(f)\n",
    "#         except:\n",
    "#             continue\n",
    "#         start = np.random.randint(50, 150)\n",
    "#         seed = seed[start:start+100].reshape(-1, 1) / NUMBER_OF_PIANO_NOTES\n",
    "#         if seed.shape[0] < 100:\n",
    "#             print(f\"Discarded {f.split(' ')[-1]} {seed.shape}\")\n",
    "#             continue\n",
    "#         else:\n",
    "#             now = datetime.now()\n",
    "#             current_time = now.strftime(\"_%H_%M_%S\")\n",
    "#             print(f'Predicting {f}')\n",
    "#             name = f.split(' ')[-1].split('.')[0]\n",
    "# #           original = notes_to_midi(seed, f'original{current_time}.mid', is_original=True)\n",
    "#             generated = notes_to_midi(predict_sequence(seed, model, num_predictions = 50, temperature = 1), f\"1_GENERATED{current_time}_{name}.mid\")\n",
    "#             generated = notes_to_midi(predict_sequence(seed, model, num_predictions = 50, temperature = 2), f\"2_GENERATED{current_time}_{name}.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398abdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
