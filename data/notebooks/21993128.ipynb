{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import copy\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/nih-chest-xrays-tfrecords/preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = \"../input/nih-chest-xrays-tfrecords/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'No Finding': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Atelectasis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Consolidation': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Infiltration': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumothorax': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Edema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Emphysema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Fibrosis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Effusion': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumonia': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pleural_Thickening': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Cardiomegaly': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Nodule': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Mass': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Hernia': tf.io.FixedLenFeature([], tf.int64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfr_decoder(path, shuffle=True):\n",
    "    def image_decoder(data):\n",
    "        _ = tf.io.parse_single_example(data, feature_map) \n",
    "        image = _['image']\n",
    "        image = tf.io.decode_image(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize_with_pad(image, 150, 150)\n",
    "        image.set_shape([150,150,3])\n",
    "        image = image/255.\n",
    "        \n",
    "        print([label for label in sorted(list(_.keys())) if label!='image' and label!='image_id'])\n",
    "        labels = [tf.cast(_[x], tf.float32) for x in sorted(list(_.keys())) if x!='image_id' and x!='image']\n",
    "        \n",
    "        return image, labels\n",
    "    \n",
    "    data_list = [os.path.join(images_data,x) for x in os.listdir(path)]\n",
    "    split = int(len(data_list)*0.8)\n",
    "    train_data, val_data = data_list[:split], data_list[split:]\n",
    "    \n",
    "    trainds = tf.data.TFRecordDataset(train_data)\n",
    "    trainds = trainds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    valds = tf.data.TFRecordDataset(val_data)\n",
    "    valds = valds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        trainds = trainds.shuffle(1024)\n",
    "        \n",
    "    trainds = trainds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    valds = valds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return trainds, valds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training , validation = tfr_decoder(images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8748919",
   "metadata": {},
   "outputs": [],
   "source": [
    "effic = tf.keras.applications.EfficientNetB2(\n",
    "    include_top=False, weights=None,input_shape=(150,150,3), pooling='avg')\n",
    "\n",
    "incep = tf.keras.applications.InceptionV3(\n",
    "    include_top=False, weights=None, input_shape=(150,150,3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = tf.keras.models.load_model('../input/temp12/MyModel')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    model = tf.keras.Sequential([\n",
    "                incep,\n",
    "                tf.keras.layers.Dense(512, activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dense(32, activation='relu'),\n",
    "                tf.keras.layers.Dense(15, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='Adam',\n",
    "                metrics=[tf.keras.metrics.AUC(multi_label=True),'binary_accuracy'])\n",
    "    model.fit(training, epochs=25)\n",
    "    model.save(\"../input/temp12/MyModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56aec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', \n",
    "              'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', \n",
    "              'Pneumothorax']\n",
    "columns = {}\n",
    "for label in label_list:\n",
    "    columns[label] = []\n",
    "    \n",
    "for element in validation.as_numpy_iterator():\n",
    "    for label in element[1]:\n",
    "        for n, data in enumerate(label):\n",
    "            columns[label_list[n]].append(data)\n",
    "    \n",
    "valdf = pd.DataFrame(columns)\n",
    "valdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example = list(valdf.loc[valdf['Atelectasis'] == 1].head(10).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8847e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_data = []\n",
    "for element in validation.as_numpy_iterator():\n",
    "    for img in element[0]:\n",
    "        img = img*255.0\n",
    "        val_image_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26046ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(baseline,image,alphas):\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "    input_x = tf.expand_dims(image, axis=0)\n",
    "    delta = input_x - baseline_x\n",
    "    images = baseline_x +  alphas_x * delta\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae451315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(images, target_class_idx):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        logits = model(images)\n",
    "        probs = tf.nn.softmax(logits, axis=-1)[:,target_class_idx]\n",
    "        return tape.gradient(probs, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a897519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def integrated_gradients(baseline,image,target_class_idx, m_steps=150, batch_size=64):\n",
    "    # 1. Generate alphas\n",
    "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps)\n",
    "\n",
    "    # Accumulate gradients across batches\n",
    "    integrated_gradients = 0.0\n",
    "\n",
    "    # Batch alpha images\n",
    "    ds = tf.data.Dataset.from_tensor_slices(alphas).batch(batch_size)\n",
    "\n",
    "    for batch in ds:\n",
    "\n",
    "        # 2. Generate interpolated images\n",
    "        batch_interpolated_inputs = interpolate_images(baseline=baseline,\n",
    "                                                   image=image,\n",
    "                                                   alphas=batch)\n",
    "\n",
    "        # 3. Compute gradients between model outputs and interpolated inputs\n",
    "        batch_gradients = compute_gradients(images=batch_interpolated_inputs, \n",
    "                                            target_class_idx=target_class_idx)\n",
    "\n",
    "        # 4. Average integral approximation. Summing integrated gradients across batches.\n",
    "        integrated_gradients += integral_approximation(gradients=batch_gradients)\n",
    "\n",
    "    # 5. Scale integrated gradients with respect to input\n",
    "    scaled_integrated_gradients = (image - baseline) * integrated_gradients\n",
    "    return scaled_integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_attributions(baseline,image,target_class_idx, m_steps=tf.constant(50),cmap=None,\n",
    "                          overlay_alpha=0.4):\n",
    "\n",
    "    attributions = integrated_gradients(baseline=baseline,image=image,target_class_idx=target_class_idx,\n",
    "                                      m_steps=m_steps)\n",
    "\n",
    "    # Sum of the attributions across color channels for visualization.\n",
    "    # The attribution mask shape is a grayscale image with height and width\n",
    "    # equal to the original image.\n",
    "    attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
    "\n",
    "    axs[0, 0].set_title('Baseline image')\n",
    "    axs[0, 0].imshow(baseline)\n",
    "    axs[0, 0].axis('off')\n",
    "\n",
    "    axs[0, 1].set_title('Original image')\n",
    "    axs[0, 1].imshow(image)\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[1, 0].set_title('Attribution mask')\n",
    "    axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    axs[1, 1].set_title('Overlay')\n",
    "    axs[1, 1].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 1].imshow(image, alpha=overlay_alpha)\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845257f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import copy\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "model = tf.keras.models.load_model('../input/temp12/MyModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "baseline = tf.zeros(shape=(150,150,3))\n",
    "for num in Example:\n",
    "    _ = plot_img_attributions(image=val_image_data[num],baseline=baseline,target_class_idx=0, m_steps=2400,\n",
    "                              cmap=plt.cm.inferno, overlay_alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec760944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import copy\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "def plot1(image , prediction ):\n",
    "    _ = plot_img_attributions(image=image,baseline=baseline,target_class_idx=prediction, m_steps=2400,\n",
    "                                  cmap=plt.cm.inferno, overlay_alpha=0.4)\n",
    "    \n",
    "def TestSingle(image):\n",
    "    images_list = []\n",
    "    images_list.append(np.array(image))\n",
    "    x = np.asarray(images_list)\n",
    "    model.predict(x)\n",
    "    prediction = model.predict(x)\n",
    "    plot1(image,np.argmax(prediction))\n",
    "    label_list = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', \n",
    "                  'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', \n",
    "                  'Pneumothorax']\n",
    "    print  (label_list[np.argmax(prediction)])\n",
    "TestSingle(val_image_data[308])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "visualkeras.layered_view(model)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
