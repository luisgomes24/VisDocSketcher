{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87778e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install loss_landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ead765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import loss_landscapes\n",
    "import copy #copying model\n",
    "import tqdm #progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f471b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((150,150)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomVerticalFlip()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((150,150))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_image = torchvision.datasets.ImageFolder(\"../input/automobilepartsindentification/Automobile-parts\",transform = test_transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94403f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = main_image.classes\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(main_image)\n",
    "test_size = 0.1\n",
    "spliter = int(total_len * test_size)\n",
    "print(spliter)\n",
    "print(total_len)\n",
    "\n",
    "train_image,test_image = train_test_split(main_image,test_size = 0.1)\n",
    "print(len(train_image))\n",
    "print(len(test_image))\n",
    "\n",
    "#Normally, the data in the test section should not be mixed, but I did not want to mess with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_image,shuffle= True,batch_size = 16)\n",
    "test_loader = torch.utils.data.DataLoader(test_image,shuffle = False,batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615793d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in train_loader:\n",
    "    \n",
    "    \n",
    "    c= torch.permute(a[0],(1,2,0))\n",
    "    plt.imshow(c)\n",
    "    plt.title(f\"{class_name[b[0]]}\")\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fc292",
   "metadata": {},
   "source": [
    "****Train****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14fdd3",
   "metadata": {},
   "source": [
    "we try weight initializating in resnet and our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained = True) #we dont use gpu because loss landscape dont work gpu \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model_last = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(model_last,128),\n",
    "                        nn.ReLU(inplace = True),\n",
    "                        nn.Linear(128,len(class_name)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0929c2e",
   "metadata": {},
   "source": [
    "scheduler:     Reduce learning rate when a metric has stopped improving.\n",
    "    Models often benefit from reducing the learning rate by a factor\n",
    "    of 2-10 once learning stagnates. This scheduler reads a metrics\n",
    "    quantity and if no improvement is seen for a 'patience' number\n",
    "    of epochs, the learning rate is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf43346",
   "metadata": {},
   "source": [
    "patience (int) – Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea779782",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(),lr = 0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor = 0.001,patience = 5,verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9697f92",
   "metadata": {},
   "source": [
    "**weight initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7758f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weight_initialization():\n",
    "    #for module in model.modules():\n",
    "        #if isinstance(module,nn.Conv2d):\n",
    "            #nn.init.kaiming_uniform_(module.weight)\n",
    "            ##nn.init.constant_(module.bias,0.01)# xavier_normal_, xavier_uniform_, kaiming_normal_, kaiming_uniform_\n",
    "            \n",
    "        #if isinstance(module,nn.Linear):\n",
    "            #nn.init.kaiming_uniform_(module.weight)\n",
    "            ##nn.init.constant_(module.bias,0.01)\n",
    "#weight_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef34544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#??torch.optim.lr_scheduler.ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ffb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 40\n",
    "loss_intitial = copy.deepcopy(model.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc15369",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot = []\n",
    "test_plot = []\n",
    "acc_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26640fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(epoch):\n",
    "    model.train()\n",
    "    train_loss =0\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    test_total = 0\n",
    "    for inputs,label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    for test_inputs,test_labels in test_loader:\n",
    "        \n",
    "        test_output = model(test_inputs)\n",
    "        t_loss = criterion(test_output,test_labels)\n",
    "        \n",
    "        test_loss += t_loss.item() * test_inputs.size(0)\n",
    "        \n",
    "        _,pred = torch.max(test_output,1)\n",
    "        t_acc = torch.sum(pred == test_labels.data)\n",
    "        acc += t_acc\n",
    "        \n",
    "        test_total += len(test_labels)\n",
    "        \n",
    "        \n",
    "    test_counter = test_loss / len(test_image)\n",
    "    train_plot.append(train_loss/len(train_image))\n",
    "    test_plot.append(test_counter)\n",
    "    acc_plot.append(acc/len(test_image))\n",
    "    scheduler.step(test_counter)\n",
    "    \n",
    "    print(f\"Train {train_loss/len(train_image)}  Test: {test_counter} ACC: {acc/len(test_image)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b48695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb30c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"car_part_dedection.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10708d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained = False)\n",
    "model.fc = nn.Sequential(nn.Linear(2048,128),\n",
    "                        nn.ReLU(inplace = True),\n",
    "                        nn.Linear(128,len(class_name)))\n",
    "model.load_state_dict(torch.load(\"car_part_dedection.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd946014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = copy.deepcopy(model.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce803959",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = iter(train_loader).__next__()\n",
    "metric = loss_landscapes.metrics.Loss(criterion,x,y)\n",
    "loss_data = loss_landscapes.linear_interpolation(loss_intitial,model_final,metric,10,deepcopy_model = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f74a3",
   "metadata": {},
   "source": [
    "loss_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1/10 *i for i in range(10)],loss_data)\n",
    "plt.title(\" interpolasyon linear loss \")\n",
    "plt.xlabel(\"interpolasyon katsayı\")\n",
    "plt.ylabel(\"loss\")\n",
    "axes = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_plot)\n",
    "plt.plot(test_plot)\n",
    "plt.plot(acc_plot)\n",
    "plt.legend([\"train loss\",\"test loss\",\"acc\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_folder = [\"../input/automobilepartsindentification/Automobile-parts/Bevel-gear/image (101).jpg\",\"../input/automobilepartsindentification/Automobile-parts/clutch/image (14).jpg\",\"../input/automobilepartsindentification/Automobile-parts/piston/image (66).jpg\",\"../input/automobilepartsindentification/Automobile-parts/shocker/image (22).jpeg\",\"../input/automobilepartsindentification/Automobile-parts/cylincer/image (12).jpeg\"]\n",
    "names = [\"bevel-gear\",\"clutch\",\"piston\",\"shocker\",\"cylincer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img_folder = [Image.open(a) for a in pred_folder]\n",
    "pred_stacked = torch.stack([test_transform(b) for b in pred_img_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(pred_stacked)\n",
    "    output = F.softmax(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22feb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,len(names),figsize = (20,5))\n",
    "for i,img in enumerate(pred_img_folder):\n",
    "    axs = ax[i]\n",
    "    axs.axis(\"off\")\n",
    "    axs.set_title(f\"Prediction: {class_name[torch.argmax(output[i])]}  Real: {names[i]}\")\n",
    "    axs.imshow(img)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
