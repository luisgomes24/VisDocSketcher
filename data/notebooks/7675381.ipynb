{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2a3ce9",
   "metadata": {},
   "source": [
    "# How to convert a Kaggle dataset into a GCS bucket full of TFrecord files\n",
    "* adapted form https://codelabs.developers.google.com/codelabs/keras-flowers-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7bcaf",
   "metadata": {},
   "source": [
    "*Step 1: Import Python Modules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e9c76",
   "metadata": {},
   "source": [
    "*Step 2: Define Variables and Helper Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4576bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For uploading to GCS buckets:\n",
    "STORAGE_CLIENT = storage.Client(project='kaggle-playground-170215')\n",
    "# For converting images to TFRecord files:\n",
    "WORKING_DIRECTORY = \"./\"\n",
    "BASE_DIR = '/kaggle/input/flowers-recognition/flowers/flowers'\n",
    "FILE_PATTERN = BASE_DIR + '/*/*.jpg'\n",
    "TARGET_SIZE = [512, 512]\n",
    "CLASSES = os.listdir(BASE_DIR)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "SHARDS = 16\n",
    "\n",
    "def create_bucket(dataset_name):\n",
    "    \"\"\"Creates a new bucket. https://cloud.google.com/storage/docs/ \"\"\"\n",
    "    bucket = STORAGE_CLIENT.create_bucket(dataset_name)\n",
    "    print('Bucket {} created'.format(bucket.name))\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket. https://cloud.google.com/storage/docs/ \"\"\"\n",
    "    bucket = STORAGE_CLIENT.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    print('File {} uploaded to {}.'.format(\n",
    "        source_file_name,\n",
    "        destination_blob_name))\n",
    "    \n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket. https://cloud.google.com/storage/docs/\"\"\"\n",
    "    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "        \n",
    "def download_to_kaggle(bucket_name,destination_directory,file_name):\n",
    "    \"\"\"Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook\"\"\"\n",
    "    os.makedirs(destination_directory, exist_ok = True)\n",
    "    full_file_path = os.path.join(destination_directory, file_name)\n",
    "    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n",
    "    for blob in blobs:\n",
    "        blob.download_to_filename(full_file_path)\n",
    "    \n",
    "def decode_jpeg_and_label(filename):\n",
    "  bits = tf.io.read_file(filename)\n",
    "  image = tf.image.decode_jpeg(bits)\n",
    "  label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n",
    "  label = label.values[-2]\n",
    "  return image, label\n",
    "\n",
    "def resize_and_crop_image(image, label):\n",
    "  # Resize and crop using \"fill\" algorithm:\n",
    "  # always make sure the the resulting image\n",
    "  # is cut out from the source image so that\n",
    "  # it fills the TARGET_SIZE entirely with no\n",
    "  # black bars and a preserved aspect ratio.\n",
    "  w = tf.shape(image)[0]\n",
    "  h = tf.shape(image)[1]\n",
    "  tw = TARGET_SIZE[1]\n",
    "  th = TARGET_SIZE[0]\n",
    "  resize_crit = (w * th) / (h * tw)\n",
    "  image = tf.cond(resize_crit < 1,\n",
    "                  lambda: tf.image.resize(image, [w*tw/w, h*tw/w]), # if true\n",
    "                  lambda: tf.image.resize(image, [w*th/h, h*th/h])  # if false\n",
    "                 )\n",
    "  nw = tf.shape(image)[0]\n",
    "  nh = tf.shape(image)[1]\n",
    "  image = tf.image.crop_to_bounding_box(image, (nw - tw) // 2, (nh - th) // 2, tw, th)\n",
    "  return image, label\n",
    "\n",
    "def recompress_image(image, label):\n",
    "  height = tf.shape(image)[0]\n",
    "  width = tf.shape(image)[1]\n",
    "  image = tf.cast(image, tf.uint8)\n",
    "  image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
    "  return image, label, height, width\n",
    "\n",
    "# Three types of data can be stored in TFRecords: bytestrings, integers and floats\n",
    "# They are always stored as lists, a single data element will be a list of size 1\n",
    "\n",
    "def _bytestring_feature(list_of_bytestrings):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
    "\n",
    "def _int_feature(list_of_ints): # int64\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "\n",
    "def _float_feature(list_of_floats): # float32\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
    "  \n",
    "def to_tfrecord(tfrec_filewriter, img_bytes, label, height, width):  \n",
    "  class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)\n",
    "  one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses\n",
    "  feature = {\n",
    "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
    "      \"class\": _int_feature([class_num]),        # one class in the list\n",
    "      # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
    "      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
    "      \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n",
    "      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n",
    "  }\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
    "        \n",
    "        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
    "        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
    "        \"size\":          tf.io.FixedLenFeature([2], tf.int64),  # two integers\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)        # a certain number of floats\n",
    "    }\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    # FixedLenFeature fields are now ready to use: exmple['size']\n",
    "    # VarLenFeature fields require additional sparse_to_dense decoding\n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.reshape(image, [*TARGET_SIZE, 3])\n",
    "    class_num = example['class']\n",
    "    label  = example['label']\n",
    "    height = example['size'][0]\n",
    "    width  = example['size'][1]\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    return image, class_num, label, height, width, one_hot_class\n",
    "\n",
    "def display_9_images_from_dataset(dataset):\n",
    "  plt.figure(figsize=(13,13))\n",
    "  subplot=331\n",
    "  for i, (image, label) in enumerate(dataset):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.numpy().astype(np.uint8))\n",
    "    plt.title(label.numpy().decode(\"utf-8\"), fontsize=16)\n",
    "    subplot += 1\n",
    "    if i==8:\n",
    "      break\n",
    "  plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451a8ed",
   "metadata": {},
   "source": [
    "*Step 3: Write a function to return an image dataset as a collection of TFRecords files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_dataset_to_tfrecords_format(BASE_DIR,FILE_PATTERN,\n",
    "                                              TARGET_SIZE,CLASSES,\n",
    "                                              WORKING_DIRECTORY,\n",
    "                                              SHARDS,AUTO):\n",
    "    '''\n",
    "    Converts an image dataset into TFRecords format.\n",
    "    Note that the image dataset should be organized\n",
    "    such that different classes of images in different \n",
    "    folders.\n",
    "    '''\n",
    "    nb_images = len(tf.io.gfile.glob(FILE_PATTERN))\n",
    "    shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
    "    #print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))\n",
    "    filenames = tf.data.Dataset.list_files(FILE_PATTERN, seed=35155) # This also shuffles the images\n",
    "    dataset1 = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)\n",
    "    #display_9_images_from_dataset(dataset1)\n",
    "    dataset2 = dataset1.map(resize_and_crop_image, num_parallel_calls=AUTO)  \n",
    "    #display_9_images_from_dataset(dataset2)\n",
    "    dataset3 = dataset2.map(recompress_image, num_parallel_calls=AUTO)\n",
    "    dataset3 = dataset3.batch(shard_size) # sharding: there will be one \"batch\" of images per file \n",
    "    #print(\"Writing TFRecords\")\n",
    "    for shard, (image, label, height, width) in enumerate(dataset3):\n",
    "      # batch size used as shard size here\n",
    "      shard_size = image.numpy().shape[0]\n",
    "      # good practice to have the number of records in the filename\n",
    "      filename = WORKING_DIRECTORY + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
    "      with tf.io.TFRecordWriter(filename) as out_file:\n",
    "        for i in range(shard_size):\n",
    "          example = to_tfrecord(out_file,\n",
    "                                image.numpy()[i], # re-compressed image: already a byte string\n",
    "                                label.numpy()[i],\n",
    "                                height.numpy()[i],\n",
    "                                width.numpy()[i])\n",
    "          out_file.write(example.SerializeToString())\n",
    "        #print(\"Wrote file {} containing {} records\".format(filename, shard_size))\n",
    "    # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n",
    "    # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "    dataset4 = tf.data.Dataset.list_files(WORKING_DIRECTORY + \"*.tfrec\")\n",
    "    dataset4 = dataset4.with_options(option_no_order)\n",
    "    dataset4 = dataset4.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
    "    dataset4 = dataset4.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "    dataset4 = dataset4.shuffle(300)\n",
    "    display_dataset = dataset4.map(lambda image, class_num, label, height, width, one_hot_class: (image, label))\n",
    "    #display_9_images_from_dataset(display_dataset)\n",
    "    return dataset4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77c17a",
   "metadata": {},
   "source": [
    "*Step 4: Convert your image dataset to TFRecords format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc929417",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_image_dataset_to_tfrecords_format(BASE_DIR,FILE_PATTERN,\n",
    "                                              TARGET_SIZE,CLASSES,\n",
    "                                              WORKING_DIRECTORY,\n",
    "                                              SHARDS,AUTO)\n",
    "#!rm '__notebook_source__.ipynb'\n",
    "#!rm -r '.ipynb_checkpoints'\n",
    "\n",
    "list_of_files = os.listdir('/kaggle/working/')\n",
    "print(list_of_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a71b06",
   "metadata": {},
   "source": [
    "*Step 5: Create a new GCS Bucket*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9379bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'flowers_dataset_1'         \n",
    "try:\n",
    "    create_bucket(bucket_name)   \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7d021",
   "metadata": {},
   "source": [
    "*Step 6: Upload your data to the GCS Bucket*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fcdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_of_files:\n",
    "    local_data = WORKING_DIRECTORY+file\n",
    "    file_name = file\n",
    "    upload_blob(bucket_name, local_data, file_name)\n",
    "\n",
    "print('\\nData inside of the GCS Bucket ',bucket_name,':\\n')\n",
    "list_blobs(bucket_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db53898",
   "metadata": {},
   "source": [
    "*Step 7: Download the data from GCS back into your notebook to verify that it really exists*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15286490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('/kaggle/working/flowers/')\n",
    "    \n",
    "# # FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/flowers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87196b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_directory = '/kaggle/working/flowers/'       \n",
    "for file_name in list_of_files:\n",
    "    download_to_kaggle(bucket_name,destination_directory,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb45d8b",
   "metadata": {},
   "source": [
    "*Step 8: Preview the data you just downloaded*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/working/flowers/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc41b6",
   "metadata": {},
   "source": [
    "*Step 9: Use your GCS bucket full of TFRecord files to train a machine learning model using a TPU.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44935383",
   "metadata": {},
   "source": [
    "**Example notebook:**\n",
    "* https://www.kaggle.com/mgornergoogle/flowers-with-keras-and-xception-fine-tuned-on-gpu"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
