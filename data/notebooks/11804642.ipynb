{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb59c7c",
   "metadata": {},
   "source": [
    "# Reading the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas and Reading the Data:\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n",
    "data = data.iloc[0:10000,:]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519eef5b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee58da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the null values in the data:\n",
    "null = pd.DataFrame(pd.isnull(data).sum())\n",
    "null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188f23f",
   "metadata": {},
   "source": [
    "## Removing Unnecessary Columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa5ac2",
   "metadata": {},
   "source": [
    "I think the first step to starting to work on something which as a lot of columns is by removing the columns which are unnecessary given that they provide no value to the data but rather make it messy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of coursing throught the 43 columns, lets make a list of the features which have more than 10K null values:\n",
    "droplist = []\n",
    "for i in null.index:\n",
    "    if int(null.loc[i].values) > 2000:\n",
    "        droplist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how it looks:\n",
    "droplist.append('Description')\n",
    "droplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be04a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally dropping the useless columns:\n",
    "newdata = data.drop(droplist, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0598b6",
   "metadata": {},
   "source": [
    "## Filling in Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ceacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Cateogircal Columns:\n",
    "c = (newdata.dtypes == 'object')\n",
    "catcol = list(c[c].index)\n",
    "catcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Numerical Columns:\n",
    "n = (newdata.dtypes != 'object')\n",
    "numcol = list(n[n].index)\n",
    "numcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18327ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we must deal with the features who have null values but less than 10K in count:\n",
    "from sklearn.impute import SimpleImputer\n",
    "CatSimp = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "CatSimp.fit(newdata[catcol])\n",
    "newdata[catcol] = CatSimp.transform(newdata[catcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its time to fill in the missing values in the Numerical Columns:\n",
    "NumSimp = SimpleImputer(strategy = 'median')\n",
    "\n",
    "NumSimp.fit(newdata[numcol])\n",
    "newdata[numcol] = NumSimp.transform(newdata[numcol])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af0dac",
   "metadata": {},
   "source": [
    "Before converting my categorical columns to numerical to process it for insights, I'll copy the dataset first so that I don't make changes to the newdata dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d0738",
   "metadata": {},
   "source": [
    "## Dealing with Special Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc67c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding longitudes and latitudes:\n",
    "latlong = newdata['Location'].str.strip('()').str.split(', ', expand = True)\n",
    "newdata['Latitude'] = latlong[[0]]\n",
    "newdata['Longitude'] = latlong[[1]]\n",
    "\n",
    "newdata.drop(['Location'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which produces day, month and year columns from a single date column:\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "def getdate(x, c):\n",
    "    d = []\n",
    "    m = []\n",
    "    y = []\n",
    "    x[c] = pd.to_datetime(x[c])\n",
    "    for n in range(0,10000):\n",
    "        d.append(x[c].iloc[n].day)\n",
    "        m.append(x[c].iloc[n].month)\n",
    "        y.append(x[c].iloc[n].year)\n",
    "        \n",
    "        \n",
    "    x[c + \" \" + \"Day\"] = d\n",
    "    x[c + \" \" + \"Month\"] = m\n",
    "    x[c + \" \" + \"Year\"] = y\n",
    "    x.drop([c], axis = 1, inplace = True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dates as the collection all the features with dates:\n",
    "dates = ['Permit Creation Date', 'First Construction Document Date', 'Filed Date', 'Current Status Date', 'Issued Date']\n",
    "\n",
    "# Lets produce some day, month and year columns:\n",
    "for d in dates:\n",
    "    getdate(newdata, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the Values of Longitude and Latitudes were in the \"object\" dtype, lets convert it to float:\n",
    "newdata['Longitude'] = newdata['Longitude'].astype('float64')\n",
    "newdata['Latitude'] = newdata['Latitude'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont't want to mess up the newdata dataset since converting its categorical values into numerical values will affect data visualization,\n",
    "# lets copy it to another dataset:\n",
    "encdata = pd.DataFrame(newdata, columns = newdata.columns)\n",
    "PermitNumber = encdata['Permit Number']\n",
    "encdata.drop(['Permit Number'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b5965",
   "metadata": {},
   "source": [
    "## Converting Categorical Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0792507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that converts a dataset's categorical values to Numerical Values\n",
    "def convertcat(data, target):\n",
    "\n",
    "# Defining the Categorical Columns:\n",
    "    c = (data.dtypes == 'object')\n",
    "    datacatcol = list(c[c].index)\n",
    "\n",
    "\n",
    "# Importing the bad boy needed to convert Categorical Values to Numerical Values:\n",
    "    from category_encoders import CatBoostEncoder\n",
    "    cbe = CatBoostEncoder()\n",
    "\n",
    "# CatBoostEncoder demands a target value becuase it changes the cate\n",
    "    for i in datacatcol:\n",
    "        cbe.fit(data[i], data[target])\n",
    "        data[i] = cbe.transform(data[i], data[target])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertin encdat:\n",
    "convertcat(encdata, 'Estimated Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8ff0c",
   "metadata": {},
   "source": [
    "# Data Visualization and Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a957a7",
   "metadata": {},
   "source": [
    "## HeatMap\n",
    "Here's a correlation heatmap which will help us get insights on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize  = (17, 20))\n",
    "sns.set_context(\"paper\", font_scale = 1)\n",
    "sns.heatmap(encdata.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525aef6c",
   "metadata": {},
   "source": [
    "## Scatter Maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the permits on a map with their Current Status:\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(newdata, lat = \"Latitude\", lon=\"Longitude\",\n",
    "                        zoom = 10, height = 300, \n",
    "                        color = \"Current Status\")\n",
    "fig.update_layout(mapbox_style = \"carto-positron\")\n",
    "fig.update_layout(margin = {\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing this again but on a map to have a better idea:\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(newdata, lat = \"Latitude\", lon=\"Longitude\",\n",
    "                        zoom = 10, height = 300, \n",
    "                        color = \"Plansets\")\n",
    "fig.update_layout(mapbox_style = \"carto-positron\")\n",
    "fig.update_layout(margin = {\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f35cd",
   "metadata": {},
   "source": [
    "What I can conclude from above is that the north west regions have more plansets, clustered around the San Francisco-Oakland bridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9c468",
   "metadata": {},
   "source": [
    "## Countplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a countplot for the Current Status' of permits:\n",
    "\n",
    "plt.figure(figsize = (20, 6))\n",
    "sns.set_context(\"poster\", font_scale = 0.9)\n",
    "sns.countplot(newdata['Current Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Countplot for Filed Date Month:\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.set_context(\"poster\")\n",
    "sns.countplot(newdata['Filed Date Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Countplot for Issued Date Month:\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.set_context(\"poster\")\n",
    "sns.countplot(newdata['Issued Date Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b38d",
   "metadata": {},
   "source": [
    "It is plausible to conclude by just looking at the two countplots above that most **filings** and **issues** occur during the **first four months** of a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for the days on which permits are issued:\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot(newdata['Issued Date Day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8851134",
   "metadata": {},
   "source": [
    "The Fourth of every months seems to be the favourite date of the authorities for issuing permits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658fcb8",
   "metadata": {},
   "source": [
    "I would like to thank you for going through this notebook :D\n",
    "Check out my other notebooks if you feel like!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
