{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08204b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/cell_images/cell_images/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186449f",
   "metadata": {},
   "source": [
    "import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c99fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af74a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transfrom to the data\n",
    "data_transform = transforms.Compose(\n",
    "       [transforms.Resize((108,108)),\n",
    "        transforms.Pad(2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "#import photo data \n",
    "cell_dataset = datasets.ImageFolder(root='../input/cell_images/cell_images/',transform=data_transform)\n",
    "\n",
    "#define dataloader\n",
    "dataset_loader = DataLoader(cell_dataset,batch_size=4, shuffle=True,num_workers=4)\n",
    "\n",
    "split1 = int(0.1 * len(cell_dataset))\n",
    "split2 = int(0.9 * len(cell_dataset))\n",
    "index_list = list(range(len(cell_dataset)))\n",
    "np.random.shuffle(index_list) \n",
    "test_idx = index_list[:split1]+index_list[split2:]\n",
    "train_idx=index_list[split1:split2]\n",
    "\n",
    "## create training and validation sampler objects\n",
    "tr_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(test_idx)\n",
    "#trainset=cell_dataset[split1:split2]\n",
    "\n",
    "## create iterator objects for train and valid datasets\n",
    "trainloader = DataLoader(cell_dataset, batch_size=4,sampler=tr_sampler,num_workers=1)\n",
    "validloader = DataLoader(cell_dataset, batch_size=4,sampler=val_sampler,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4408edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "classes=(\"Parasitized\",\"Uninfected\")\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(dataset_loader)\n",
    "images, labels = dataiter.next()\n",
    "#encode = autoencoder2(images)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4429c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a667f",
   "metadata": {},
   "source": [
    "build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58895453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        self.conv_layer1=nn.Sequential(\n",
    "        nn.Conv2d(3, 16, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(16,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(16, 16, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(16,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #x.size=16*56*56\n",
    "        \n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "        nn.Conv2d(16, 32, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(32,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(32, 32, 3,padding=1,bias=False),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(32, 32, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(32,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #x.size=32*28*28\n",
    "        \n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "        nn.Conv2d(32, 64, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(64,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(64, 64, 3,padding=1),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(64, 64, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(64,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #x.size=64*14*14\n",
    "        \n",
    "        self.conv_layer4 = nn.Sequential(\n",
    "        nn.Conv2d(64, 128, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(128,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(128, 128, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(128,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #x.size=128*7*7\n",
    "        \n",
    "        self.conv_layer5 = nn.Sequential(\n",
    "        nn.Conv2d(128, 256, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(256,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.Conv2d(256, 256, 3,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(256,momentum=0.9),\n",
    "        nn.PReLU(),\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #x.size=256*3*3\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "        nn.Linear(2304,1024),\n",
    "        nn.PReLU(),\n",
    "        nn.Linear(1024,256),\n",
    "        nn.PReLU(),\n",
    "        nn.Linear(256,2),\n",
    "        nn.Tanhshrink()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)    \n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.conv_layer4(x)\n",
    "        x = self.conv_layer5(x)\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, 256*3*3)\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 0, 0.01)\n",
    "        init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7df801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea967a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "net3_2=Net3()\n",
    "net3_2.apply(weights_init_kaiming)\n",
    "#send net to GPU and train on it\n",
    "net3_2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b369aad",
   "metadata": {},
   "source": [
    "define the optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b457be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer3_1 = optim.Adam(net3_2.parameters(),lr=0.0001,betas=(0.9,0.999),eps=1e-20,weight_decay=0.0002,amsgrad=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer3_1,mode= 'min',factor=0.1,patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36093ace",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss=0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer3_1.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net3_2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer3_1.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            #image_num=(i+1)*50\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i+1, running_loss/1000))\n",
    "            running_loss = 0\n",
    "            \n",
    "    scheduler.step(running_loss)\n",
    "                  \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c75c1",
   "metadata": {},
   "source": [
    "send the model to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "net3_2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c312eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for param in net3_2.parameters():\n",
    "    print(param.size())\n",
    "    print('{}:grad->{}'.format(param, param.grad))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e9743f",
   "metadata": {},
   "source": [
    "test on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        outputs = net3_2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f0817",
   "metadata": {},
   "source": [
    "test on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        outputs = net3_2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db9867",
   "metadata": {},
   "source": [
    "Test model on deifferent kinds of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff07b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        outputs = net3_2(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(2):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"number of correct:\",class_correct[i], \"number of total:\",class_total[i])\n",
    "    print('Accuracy of %5s : %.2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaddb91",
   "metadata": {},
   "source": [
    "save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net3_2.state_dict(), 'net3_2params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b484ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "FileLinks('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b95952",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*1309/2695"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
