{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b73548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import cv2\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3404780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43a636",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "NB_CHANNELS = 3\n",
    "MAX_TRAIN_STEPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 40\n",
    "weight_path = './'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91660620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "x_train,x_test,y_train,y_test = train_test_split(train['id_code'].values,train['diagnosis'].values,test_size=0.1,random_state=42)\n",
    "train_image_dir = '../input/aptos2019-blindness-detection/train_images/'\n",
    "def make_image_gen(img_file_list,class_list, batch_size = 4):\n",
    "    all_batches = img_file_list\n",
    "    all_classes = class_list\n",
    "    out_rgb = []\n",
    "    yield_rgb = []\n",
    "    yield_label = []\n",
    "    out_label = []\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        #np.random.shuffle(all_batches)\n",
    "        out_rgb = []\n",
    "        out_label = []\n",
    "        for idx, c_img_id in enumerate(all_batches):\n",
    "            imgname  = c_img_id + '.png'\n",
    "            c_img = cv2.imread(os.path.join(train_image_dir,imgname))\n",
    "            c_img = cv2.cvtColor(c_img, cv2.COLOR_BGR2HSV)\n",
    "            c_img = cv2.resize(c_img,(IMG_SIZE,IMG_SIZE),interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            label = class_list[idx]\n",
    "            out_rgb += [c_img]\n",
    "            out_label += [label]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield_rgb = out_rgb\n",
    "                yield_label = out_label\n",
    "                out_rgb = []\n",
    "                out_label = []\n",
    "                #print(\"size\",sys.getsizeof(out_rgb))\n",
    "                yield np.stack(yield_rgb, 0)/255.0, to_categorical(np.stack(yield_label, 0),num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_gen = make_image_gen(x_train,y_train,4)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x, valid_y = next(make_image_gen(x_test,y_test,4))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D , Input, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = False,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        g_y = in_y\n",
    "        yield next(g_x)/255.0 , g_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = make_image_gen(x_train,y_train,4)\n",
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a922aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mathormad/aptos-resnet50-baseline\n",
    "function = \"softmax\"\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation=function, name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_SIZE,IMG_SIZE,NB_CHANNELS)\n",
    "n_out = 5\n",
    "model = create_model(input_shape,n_out)\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam, adadelta,adagrad,adam,RMSprop,SGD\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-5,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef96d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping , ReduceLROnPlateau , ModelCheckpoint\n",
    "step_count = min(MAX_TRAIN_STEPS, len(x_train)//BATCH_SIZE)\n",
    "train_gen = make_image_gen(x_train,y_train,BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(train_gen)\n",
    "valid_gen = make_image_gen(x_test,y_test,2)\n",
    "\n",
    "\n",
    "#earlyStopper = EarlyStopping(monitor=\"acc\", mode=\"max\", patience=15)\n",
    "#checkPointer = ModelCheckpoint(weight_path, monitor='acc', verbose=1, \n",
    "#                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "checkpoint = ModelCheckpoint('../working/aptos.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='min', min_delta=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "callbacks_list = [checkpoint, reduceLROnPlat, early]\n",
    "model.fit_generator(aug_gen,\n",
    "                            steps_per_epoch=step_count, \n",
    "                            epochs=NB_EPOCHS, \n",
    "                            validation_data=valid_gen,\n",
    "                            validation_steps=len(x_test)//BATCH_SIZE, \n",
    "                            callbacks=callbacks_list,\n",
    "                            workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99192a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mathormad/aptos-resnet50-baseline\n",
    "from tqdm import tqdm\n",
    "submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "# model.load_weights('../working/Resnet50.h5')\n",
    "model.load_weights('../working/aptos.h5')\n",
    "predicted = []\n",
    "for i, name in tqdm(enumerate(submit['id_code'])):\n",
    "    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    score_predict = model.predict((image[np.newaxis])/255)\n",
    "    label_predict = np.argmax(score_predict)\n",
    "    # label_predict = score_predict.astype(int).sum() - 1\n",
    "    predicted.append(str(label_predict))\n",
    "submit['diagnosis'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
