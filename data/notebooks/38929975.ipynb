{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e4f622",
   "metadata": {},
   "source": [
    "# Use hyperparameters from: https://www.kaggle.com/code/tauilabdelilah/icr-hyperparameter-tuning-optuna version 12 Trial 1790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04349d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df   = pd.read_csv('/kaggle/input/icr-create-folds/train_folds.csv')\n",
    "Test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EJ']   = df['EJ'].replace({'A': 0, 'B': 1})\n",
    "Test['EJ'] = Test['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "df   = df.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'})\n",
    "Test = Test.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', #'BC', \n",
    "            'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ',\n",
    "            'CB', 'CC', 'CD', 'CF', 'CH', #'CL', \n",
    "            'CR', 'CS', 'CU', 'CW',\n",
    "            'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "            'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU',\n",
    "            'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS',\n",
    "            'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'EJ']\n",
    "label    = df.columns[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e111fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_logloss(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    y_pred / np.sum(y_pred, axis=1)[:, None]\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    \n",
    "    logloss = (-w0/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(y_pred[:,0]))) - w1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred[:,1])))) / (w0+w1)\n",
    "    \n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb301437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_loss_weight(y_true):\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4da1b",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a07e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_valid_predictions = {}\n",
    "final_test_predictions = []\n",
    "bs = []\n",
    "\n",
    "\n",
    "for k in range(5):\n",
    "    print('------------------ Fold: '+str(k))\n",
    "    train     = df[df['kfold'] !=k].reset_index(drop=True)\n",
    "    val       = df[df['kfold'] ==k].reset_index(drop=True)\n",
    "    valid_ids = val.Id.values.tolist()\n",
    "    \n",
    "    train_w0, train_w1 = calc_log_loss_weight(train[label])\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(val[label])\n",
    "\n",
    "    train_dataset = lgb.Dataset(train[features], train[label],weight=train[label].map({0: train_w0, 1: train_w1}), categorical_feature=[\"EJ\"] )\n",
    "    eval_dataset  = lgb.Dataset(val[features], val[label], weight=val[label].map({0: valid_w0, 1: valid_w1}), categorical_feature=[\"EJ\"])\n",
    "    lgb_params = {\n",
    "        'objective': 'binary', \n",
    "        'metric': 'binary_logloss', \n",
    "        'boosting': 'goss',\n",
    "        'learning_rate': 0.09110460114828077,\n",
    "        'num_leaves': 8,\n",
    "        'feature_fraction': 0.4989639912997521,\n",
    "        'bagging_fraction': 0.54872439795985,\n",
    "        'lambda_l1': 1.4522184914523175, \n",
    "        'lambda_l2': 1.7873553090132748e-08,\n",
    "        'n_jobs': -1,\n",
    "        'is_unbalance':True, \n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "                params = lgb_params,\n",
    "                train_set = train_dataset,\n",
    "                num_boost_round = 50000,\n",
    "                valid_sets = [train_dataset, eval_dataset],\n",
    "                early_stopping_rounds = 20,\n",
    "                verbose_eval = 10000,\n",
    "            )\n",
    "\n",
    "    preds_valid = model.predict(val[features])\n",
    "    preds_test  = model.predict(Test[features])\n",
    "    preds_valid = np.vstack([1 - preds_valid, preds_valid]).T\n",
    "    preds_test  = np.vstack([1 - preds_test, preds_test]).T\n",
    "    \n",
    "    final_test_predictions.append(preds_test)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    blogloss = balance_logloss(val[label], preds_valid)\n",
    "\n",
    "    bs.append(blogloss)\n",
    "    print(k, blogloss)\n",
    "print('Balance Log loss:')\n",
    "print(bs)\n",
    "print(np.mean(bs), np.std(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = ['Id', 'class_0', 'class_1']\n",
    "final_valid_predictions.to_csv(r\"oof.csv\", index=False)\n",
    "\n",
    "final_test_predictions = (final_test_predictions[0] + final_test_predictions[1] + final_test_predictions[2] + final_test_predictions[3] + final_test_predictions[4])/5\n",
    "test_dict = {}\n",
    "test_dict.update(dict(zip(Test.Id.values.tolist(), final_test_predictions)))\n",
    "submission = pd.DataFrame.from_dict(test_dict, orient=\"index\").reset_index()\n",
    "submission.columns = ['Id', 'class_0', 'class_1']                       \n",
    "\n",
    "submission.to_csv(r\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fba747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Befor checking accuracy let's first make sure that we have the data are sorted in the same way :)\n",
    "final_valid_predictions   = final_valid_predictions.sort_values('Id')\n",
    "Train                     = df.sort_values('Id')\n",
    "\n",
    "print('balanced logarithmic loss for the baseline: '+str(balance_logloss(df['Class'], final_valid_predictions[['class_0', 'class_1']].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
