{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a66349f",
   "metadata": {},
   "source": [
    "In many notebooks, models predict actions corresponding to ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp'] and take mean/median of them. In order to improve the utility score, we consider linear combination instead of taking mean/median of them, and optimize the weights using the CMA-ES.\n",
    "\n",
    "The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a stochastic method for black-box continuous optimization, where the gradient of the objective function cannot be accessed such as the utility score in this competition. The CMA-ES defines a Gaussian distribution on the search space and iteratively updates the parameters of the distribution (the mean vector and the covariance matrix) to improve the objective function value of the samples generated from the distribution. \n",
    "\n",
    "â†“ Illustration of CMA-ES optimizing a simple two-dimensional function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92c4bd",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/Concept_of_directional_optimization_in_CMA-ES_algorithm.png\" width=\"500px\">\n",
    "\n",
    "https://en.wikipedia.org/wiki/CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm\n",
    "from random import choices\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "from cmaes import CMA\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    n_fold: int\n",
    "    dropouts: List[float]\n",
    "    n_units: List[int]\n",
    "    lr: float\n",
    "    ls: float\n",
    "    wd: float\n",
    "    patience: int\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "    seed: int\n",
    "    train: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7e185",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Swith 'train=True' when you train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    n_fold=4,\n",
    "    dropouts=[0.1, 0.5, 0.5],\n",
    "    n_units=[256, 256],\n",
    "    lr=1e-3,\n",
    "    ls=1e-2,\n",
    "    wd=1e-5,\n",
    "    patience=10,\n",
    "    batch_size=4096,\n",
    "    epochs=300,\n",
    "    seed=36,\n",
    "    train=False\n",
    ")\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd420ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateKFold:\n",
    "    __i: int = -1\n",
    "        \n",
    "    def __init__(self, data: pd.DataFrame, n_fold: int):\n",
    "        self.data = data\n",
    "        self.n_fold = n_fold\n",
    "        self.uni_date = np.unique(data['date'].values)\n",
    "        self.date_block = np.array_split(self.uni_date, n_fold)\n",
    "        self.block_idxs = [(np.delete(np.arange(n_fold), i), i) for i in range(n_fold)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_fold\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.__i = -1\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.__i += 1\n",
    "        if self.__i < 0 or self.n_fold <= self.__i:\n",
    "            raise StopIteration()\n",
    "        return self.split()\n",
    "    \n",
    "    def __split_date(self) -> Tuple[List[int], List[int]]:\n",
    "        return np.hstack([self.date_block[j] for j in self.block_idxs[self.__i][0]]).tolist(), self.date_block[self.block_idxs[self.__i][1]].tolist()\n",
    "    \n",
    "    def split(self):\n",
    "        tr_date, va_date = self.__split_date()\n",
    "        return self.data.query(f'date in {tr_date}'), self.data.query(f'date in {va_date}')\n",
    "    \n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 4))\n",
    "        for i in range(self.n_fold):\n",
    "            self.__i = i\n",
    "            tr_date, va_date = self.__split_date()\n",
    "            if i == 0:\n",
    "                ax.scatter(tr_date, [i] * len(tr_date), label='train', color='blue')\n",
    "                ax.scatter(va_date, [i] * len(va_date), label='valid', color='red')\n",
    "            else:\n",
    "                ax.scatter(tr_date, [i] * len(tr_date), color='blue')\n",
    "                ax.scatter(va_date, [i] * len(va_date), color='red')\n",
    "        ax.set_title('K-fold by date')\n",
    "        ax.set_ylabel('fold')\n",
    "        ax.set_xlabel('date')\n",
    "        ax.set_yticks(list(range(self.n_fold)))\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2443599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtilityScoreCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, df: pd.DataFrame, features: List[str]):\n",
    "        super().__init__()\n",
    "        self.__weight = df['weight'].values\n",
    "        self.__resp = df['resp'].values\n",
    "        self.__date = df['date'].values\n",
    "        self.__X = df[features].values\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.scores = list()\n",
    "        self.__best = -np.inf\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        preds = self.model(self.__X, training=False).numpy()\n",
    "        us = self.bincount(preds=preds.mean(axis=1))\n",
    "        self.scores.append(us)\n",
    "        print(f\"\\nEpoch {epoch + 1}: utility score = {us}\")\n",
    "    \n",
    "    def bincount(self, preds: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        preds: np.ndarray predictions for 'action' (resp > 0)\n",
    "        \"\"\"\n",
    "        action = np.where(preds > 0.5, 1, 0)\n",
    "        count_i = len(np.unique(self.__date))\n",
    "        Pi = np.bincount(self.__date, self.__weight * self.__resp * action)\n",
    "        t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "        u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "        u = 0 if np.isnan(u) else u\n",
    "        return u\n",
    "    \n",
    "    def get_scores(self) -> List[float]:\n",
    "        return self.scores\n",
    "    \n",
    "\n",
    "def create_model(input_dim: int, output_dim: int, n_units: List[int], dropouts: List[float], lr: float, ls: float, wd: float):\n",
    "    i = Input(input_dim)\n",
    "    x = BatchNormalization()(i)\n",
    "    x = Dropout(dropouts[0])(x)\n",
    "    \n",
    "    for unit, dropout in zip(n_units, dropouts[1:]):\n",
    "        x = Dense(unit)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(tf.keras.activations.swish)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(output_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=i, outputs=x)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=lr, weight_decay=wd),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=ls),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.read_feather('../input/janestreetmarketprediction/train.feather')\n",
    "train = train.query('date > 86 & weight != 0').reset_index(drop=True)\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "train['rtn'] = train['weight'] * train['resp']\n",
    "\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "resp_cols = [c for c in train.columns if 'resp' in c]\n",
    "\n",
    "for i, c in enumerate(resp_cols):\n",
    "    train[f'action_{i}'] = (train[c] > 0).astype('int8')\n",
    "\n",
    "action_cols = [c for c in train.columns if 'action' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a177ddc",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "In this notebook, I used a simple K-Fold (K=4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkf = DateKFold(data=train, n_fold=config.n_fold)\n",
    "dkf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.train:\n",
    "    for fold, (tr_df, va_df) in enumerate(dkf):\n",
    "        print(f'fold {fold}')\n",
    "\n",
    "        utility_score = UtilityScoreCallback(df=va_df, features=features)\n",
    "        model = create_model(\n",
    "            input_dim=len(features), \n",
    "            output_dim=len(action_cols), \n",
    "            n_units=config.n_units,\n",
    "            dropouts=config.dropouts,\n",
    "            lr=config.lr,\n",
    "            ls=config.ls,\n",
    "            wd=config.wd,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            tr_df[features].values,\n",
    "            tr_df[action_cols].values,\n",
    "            validation_data=(va_df[features].values, va_df[action_cols].values),\n",
    "            epochs=config.epochs,\n",
    "            batch_size=config.batch_size,\n",
    "            verbose=1,\n",
    "            callbacks=[\n",
    "                utility_score,\n",
    "                EarlyStopping(monitor='val_loss', min_delta=0, patience=config.patience, verbose=1, mode='min'),\n",
    "                ReduceLROnPlateau(monitor='val_loss', foctor=0.2, patience=int(config.patience * 0.5), min_lr=1e-5, verbose=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model.save(f'./model-f{fold}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf166e9",
   "metadata": {},
   "source": [
    "### Load Models\n",
    "The utility scores of each validation data is like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad48c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score(action: np.ndarray, df: pd.DataFrame) -> float:\n",
    "    date, rtn = df['date'].values, df['rtn'].values\n",
    "    count_i = len(np.unique(date))\n",
    "    Pi = np.bincount(date, rtn * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    u = 0 if np.isnan(u) else u\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [keras.models.load_model(f'../input/janestreetmarketprediction/model-f{fold}.h5') for fold in range(config.n_fold)]\n",
    "\n",
    "preds_list = list()\n",
    "for fold, (_, va_df) in enumerate(dkf):\n",
    "    preds = models[fold](va_df[features].values, training=False).numpy()\n",
    "    preds_list.append(preds)\n",
    "    print(f'fold {fold + 1}/{config.n_fold}: utility score = {utility_score(action=(np.mean(preds, axis=1) > 0.5).astype(int), df=va_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81db5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCombination:\n",
    "    def __init__(self, w_init: np.ndarray):\n",
    "        self.w = w_init\n",
    "\n",
    "    def __call__(self, X: np.ndarray, step: bool = True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        :param X: np.ndarray shape=(n_data, n_dim)\n",
    "        :return np.ndarray shape=(n_data, )\n",
    "        \"\"\"\n",
    "        y = np.dot(X, self.w)\n",
    "        if step:\n",
    "            y = np.where(y > 0.5, 1, 0)\n",
    "        return y\n",
    "\n",
    "\n",
    "def split_tr_val_fold(preds_list: List[np.ndarray], fold: int, dkf: DateKFold) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    tr_set = list()\n",
    "    va_set = None\n",
    "    for i, ((_, va_df), preds) in enumerate(zip(dkf, preds_list)):\n",
    "        if fold == i:\n",
    "            va_set = (va_df, preds)\n",
    "        else:\n",
    "            tr_set.append((va_df, preds))\n",
    "    return tr_set, va_set\n",
    "\n",
    "\n",
    "def train_fold_i(dkf: DateKFold, preds_list: List[np.ndarray], fold: int, n_iters: int = 50, sigma=1.) -> LinearCombination:\n",
    "    tr_set, va_set = split_tr_val_fold(preds_list=preds_list, fold=fold, dkf=dkf)\n",
    "\n",
    "    ordinary = utility_score(action=(np.mean(va_set[1], axis=1) > 0.5).astype(int), df=va_set[0])\n",
    "\n",
    "    lc = LinearCombination(w_init=np.array([0.2] * 5))\n",
    "    lc = optimize_utility_score(\n",
    "        train_set=tr_set, \n",
    "        valid_set=va_set,\n",
    "        lc=lc, \n",
    "        step=True, \n",
    "        n_iters=n_iters, \n",
    "        sigma=sigma\n",
    "    )\n",
    "    opt = utility_score(action=lc(X=va_set[1], step=True), df=va_set[0])\n",
    "    \n",
    "    print('### valid')\n",
    "    print(f'{ordinary} â‡¨ {opt}')\n",
    "    return lc\n",
    "\n",
    "\n",
    "def optimize_utility_score(train_set: List[Tuple[pd.DataFrame, np.ndarray]], valid_set: Tuple[pd.DataFrame, np.ndarray],\n",
    "                           lc: LinearCombination, step: bool, patience: int = 5, n_iters: int = 50, sigma: float = 1.):\n",
    "    \n",
    "    optimizer = CMA(mean=lc.w, sigma=sigma, seed=2020)\n",
    "    init_value = np.sum([utility_score(action=lc(X=X, step=step), df=df) for df, X in train_set])\n",
    "\n",
    "    best = np.inf\n",
    "    val_best = -np.inf\n",
    "    wait = 0\n",
    "    best_x = None\n",
    "    __stop = False\n",
    "    for generation in tqdm(range(n_iters)):\n",
    "        solutions = list()\n",
    "        for _ in range(optimizer.population_size):\n",
    "\n",
    "            x = optimizer.ask()\n",
    "            lc.w = x\n",
    "            value = -np.sum([utility_score(action=lc(X=X, step=step), df=df) for df, X in train_set])\n",
    "            solutions.append((x, value))\n",
    "\n",
    "            if best > value:\n",
    "                best = value\n",
    "                val_values = utility_score(action=lc(X=valid_set[1], step=step), df=valid_set[0]) # warning: using the original utility score\n",
    "                print(f'train best={-best}, valid value={val_values}')\n",
    "                if val_best < val_values:\n",
    "                    best_x = x\n",
    "                    val_best = val_values\n",
    "                    wait = 0\n",
    "                else:\n",
    "                    wait += 1\n",
    "                    if wait > patience:\n",
    "                        print(f'Early Stopping at {generation}: score={val_best}')\n",
    "                        __stop = True\n",
    "        \n",
    "        optimizer.tell(solutions)\n",
    "        if __stop:\n",
    "              break\n",
    "    \n",
    "    print(\"\\n### train\")\n",
    "    print(f'f0={init_value} â‡¨ fbest={-best}')\n",
    "    print(f'best_x={best_x}')\n",
    "    \n",
    "    lc.w = best_x\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b95a1",
   "metadata": {},
   "source": [
    "### Optimize the weights using the CMA-ES\n",
    "Initial values of the mean vector is set to [0.2, 0.2, 0.2, 0.2, 0.2], which is equivalent to taking mean of predictions.\n",
    "The Scale of distribution ('sigma') and the number of iterations is also set to 0.1 and 50.\n",
    "\n",
    "The algorithm is terminated when it reaches 50 iterations or the utility score for the validation data does not improve for 5 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs = [train_fold_i(dkf=dkf, preds_list=preds_list, fold=i, n_iters=50, sigma=0.1) for i in range(config.n_fold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d348eb",
   "metadata": {},
   "source": [
    "### the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0045a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "for i, c in enumerate(resp_cols):\n",
    "    ax.plot([lc.w[i] for lc in lcs], label=f'action ({c})')\n",
    "ax.set_xticks(list(range(config.n_fold)))\n",
    "ax.set_xlabel('fold')\n",
    "ax.set_ylabel('weight')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc88fc",
   "metadata": {},
   "source": [
    "### We can see the utility scores improve on every fold!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (_, va_df) in enumerate(dkf):\n",
    "    action_mean = utility_score(action=(np.mean(preds_list[fold], axis=1) > 0.5).astype(int), df=va_df)\n",
    "    action_lc = utility_score(action=lcs[fold](X=preds_list[fold], step=True), df=va_df)\n",
    "    print(f'fold {fold + 1}/{config.n_fold}: utility score = {action_mean} â‡¨ {action_lc}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
