{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense,Flatten,Input\n",
    "from keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping ,ReduceLROnPlateau\n",
    "#from tensorflow.keras.applications.vgg19 import VGG19\n",
    "#from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0910935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Walk through the directory\n",
    "train = '../input/animals10/raw-img'\n",
    "translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\", \"dog\": \"cane\", \"cavallo\": \"horse\", \"elefante\" : \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"ragno\": \"spider\"}\n",
    "print(\"Animals & directory info: \")\n",
    "dataset = []\n",
    "for i in os.listdir('../input/animals10/raw-img'):\n",
    "    dataset.append(os.path.join(train , i))\n",
    "for i in dataset:\n",
    "    name = i.split('/')[-1]\n",
    "    #print(name)\n",
    "    print(name , \"is translated as\" , translate[name] , \"and folder length is\" , len(os.listdir(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "image_label = []\n",
    "for i in dataset:\n",
    "    for n , j in enumerate(os.listdir(i)):\n",
    "        if(n<1001):\n",
    "            img_path = os.path.join(i , j)\n",
    "            #print(img_path)\n",
    "            e = cv2.resize(cv2.cvtColor(cv2.imread(img_path),cv2.COLOR_BGR2RGB),(224,224))\n",
    "            image_array.append(e)\n",
    "            l = i.split('/')[-1]\n",
    "            image_label.append(translate[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_array[1234])\n",
    "plt.title(image_label[1234])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels into One Hot encoded sparse matrix\n",
    "image_label = pd.get_dummies(image_label).values\n",
    "\n",
    "# Converting train_images to array\n",
    "image_array = np.array(image_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test ,y_train ,y_test = train_test_split(image_array ,image_label ,test_size = 0.25 , random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09081248",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15348bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = 224\n",
    "size = [IMG_SIZE, IMG_SIZE]\n",
    "\n",
    "en7 = tf.keras.applications.EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=size+[3],\n",
    "    pooling=None,\n",
    "    classes=10,\n",
    "    classifier_activation=\"softmax\",\n",
    "    \n",
    ")\n",
    "for layer in en7.layers:\n",
    "    layer.trainable = False\n",
    "t7 = Flatten()(en7.output)\n",
    "\n",
    "prediction7 = Dense(10, activation = 'softmax')(t7)\n",
    "modelen7 = Model(inputs = en7.input , outputs = prediction7)\n",
    "modelen7._name = 'model_effi_b7'\n",
    "modelen7.summary()\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('model_effi_b7.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "modelen7.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
    "\n",
    "histen7 = modelen7.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=15, verbose=1 , steps_per_epoch = 50 ,batch_size = 2, callbacks = [earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_hist(histen7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
