{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cd756",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import torch.optim as torch_optim\n",
    "import torch.optim.lr_scheduler as torch_lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import Pool, CatBoostClassifier, cv, CatBoostRegressor\n",
    "\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "data_path = '/kaggle/input/digit-recognizer/'\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c438c",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf931c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "X, y = df.drop('label', axis=1).values, df['label'].values\n",
    "\n",
    "X = X.reshape(-1, 28, 28) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b158c",
   "metadata": {},
   "source": [
    "## Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5265fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(X, y):\n",
    "    fig, axm = plt.subplots(nrows=5, ncols=5, figsize=(8, 10))\n",
    "\n",
    "    for i, axs in enumerate(axm):\n",
    "        for j, ax in enumerate(axs):\n",
    "            idx = i * 5 + j\n",
    "            ax.imshow(X[idx], cmap='gray')\n",
    "            ax.set_title(f'Digit {y[idx]}')\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f'We have {X.shape[0]} training images with {X.shape[1:]} H*W.')\n",
    "    print(f'Value ranges for each image is between {X.min()} and {X.max()}.')\n",
    "    print(f'We have {len(np.unique(y))} classes: {list(np.unique(y))}.')\n",
    "    \n",
    "plot_grid(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afab744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_for(X, y, y_val=0):\n",
    "    fig, axm = plt.subplots(nrows=5, ncols=5, figsize=(8, 10))\n",
    "\n",
    "    idx = 0\n",
    "    for i, axs in enumerate(axm):\n",
    "        for j, ax in enumerate(axs):\n",
    "            while y[idx] != y_val:\n",
    "                idx += 1\n",
    "            ax.imshow(X[idx], cmap='gray')\n",
    "            ax.set_title(f'Digit {y[idx]}')\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "            idx += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f'We have {X.shape[0]} training images with {X.shape[1:]} H*W.')\n",
    "    print(f'Value ranges for each image is between {X.min()} and {X.max()}.')\n",
    "    print(f'We have {len(np.unique(y))} classes: {list(np.unique(y))}.')\n",
    "    \n",
    "plot_grid_for(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "plt.bar(keys, counts)\n",
    "\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title(\"Number of digit classes\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b92bea",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3cf3f",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X.reshape(-1, 28 * 28), y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy score {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision score {precision_score(y_test, y_pred, average='weighted', zero_division=0)}\")\n",
    "print(f\"Recall score {recall_score(y_test, y_pred, average='weighted', zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94441d91",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X.reshape(-1, 28 * 28), y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "svc = SVC(kernel='rbf', C=10, random_state=42)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy score {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision score {precision_score(y_test, y_pred, average='weighted', zero_division=0)}\")\n",
    "print(f\"Recall score {recall_score(y_test, y_pred, average='weighted', zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfb141",
   "metadata": {},
   "source": [
    "### DigitsPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c37033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsPCA:\n",
    "    def __init__(self, n_components=10):\n",
    "        self.n_components = n_components\n",
    "        self.pca = dict()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        for i in np.unique(y_train):\n",
    "            X_i = X_train[y_train == i]\n",
    "            self.pca[i] = PCA(n_components=self.n_components).fit(X_i)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "\n",
    "        return accuracy_score(y_test, predictions)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for X_i in X:\n",
    "            X_i = X_i.reshape(1, -1)\n",
    "            reconstructed = {\n",
    "                i: mean_squared_error(\n",
    "                    X_i, self.pca[i].inverse_transform(self.pca[i].transform(X_i))\n",
    "                )\n",
    "                for i in self.pca\n",
    "            }\n",
    "            predictions.append(min(reconstructed, key=reconstructed.get))\n",
    "        return np.array(predictions)\n",
    "        \n",
    "    @property\n",
    "    def explained_variance_ratio_(self):\n",
    "        return [self.pca[i].explained_variance_ratio_ for i in self.pca]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DigitsPCA(n_components={self.n_components})\"\n",
    "\n",
    "    def print_explained_variance_ratio(self):\n",
    "        for i, var in zip(self.pca, self.explained_variance_ratio_):\n",
    "            var_total = var.sum()\n",
    "            print(f'[Digit {i}]: Explained variation per principal component: {var} with a total of {var_total} variance captured.')\n",
    "\n",
    "    def plot_explained_variance_ratio(self):\n",
    "        nlabels = len(self.pca)\n",
    "        fig, axs = plt.subplots(nrows=nlabels, ncols=1, figsize=(16,16))\n",
    "        for i, var, ax in zip(self.pca, self.explained_variance_ratio_, axs):\n",
    "            ax.bar(np.arange(self.n_components), var)\n",
    "            ax.set_xlabel('Principal components')\n",
    "            ax.set_ylabel('Variance')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X.reshape(-1, 28 * 28), y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "pca = DigitsPCA(n_components=28)\n",
    "\n",
    "pca.fit(X_train, y_train)\n",
    "y_pred = pca.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy score {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision score {precision_score(y_test, y_pred, average='weighted', zero_division=0)}\")\n",
    "print(f\"Recall score {recall_score(y_test, y_pred, average='weighted', zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc55013",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "while y_test[idx] != 0:\n",
    "    idx += 1\n",
    "    \n",
    "inv = pca.pca[0].inverse_transform(pca.pca[0].transform(X_test.reshape(-1, 28*28)[idx].reshape(1, -1)))\n",
    "\n",
    "plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(inv.reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da988e",
   "metadata": {},
   "source": [
    "### Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOBEL_KERNEL = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1407bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s1 = np.concatenate([cv2.filter2D(x, -1, SOBEL_KERNEL) for x in X.reshape(-1, 1, 28, 28)])\n",
    "X_s2 = np.concatenate([cv2.filter2D(x, -1, SOBEL_KERNEL.T) for x in X.reshape(-1, 1, 28, 28)])\n",
    "X_s = np.concatenate([X_s1.reshape(-1, 28*28), X_s2.reshape(-1, 28*28)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X_s, y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "pca_f = DigitsPCA(n_components=56)\n",
    "\n",
    "pca_f.fit(X_train, y_train)\n",
    "y_pred = pca_f.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy score {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision score {precision_score(y_test, y_pred, average='weighted', zero_division=0)}\")\n",
    "print(f\"Recall score {recall_score(y_test, y_pred, average='weighted', zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X_s, y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "svc_f = SVC(kernel='rbf', C=10, random_state=42)\n",
    "\n",
    "svc_f.fit(X_train, y_train)\n",
    "y_pred = svc_f.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy score {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision score {precision_score(y_test, y_pred, average='weighted', zero_division=0)}\")\n",
    "print(f\"Recall score {recall_score(y_test, y_pred, average='weighted', zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bb4a2",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3329f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = pd.read_csv(os.path.join(data_path, 'test.csv')).values / 255\n",
    "predictions = svc.predict(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(X_submission.reshape(-1, 28, 28), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "submission['Label'] = predictions\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
