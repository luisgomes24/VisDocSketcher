{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "# Start Python Imports\n",
    "import math, time, random, datetime\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv as csv\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n",
    "\n",
    "# Machine learning\n",
    "import catboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "#Shuffle the datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Learning curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Let's be rebels and ignore warnings for now\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import seaborn as sns\n",
    "#Output plots in notebook\n",
    "#%matplotlib inline \n",
    "\n",
    "addpoly = True\n",
    "plot_lc = 0   # 1--display learning curve/ 0 -- don't display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55971d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data sets from the csv files\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "gender_submission = pd.read_csv('../input/gender_submission.csv')\n",
    "\n",
    "print('train dataset: %s, test dataset %s' %(str(train.shape), str(test.shape)) )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fae5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphic of missing values\n",
    "missingno.matrix(train, figsize = (30,10))\n",
    "# Let's write a little function to show us how many missing values\n",
    "# there are\n",
    "def find_missing_values(df, columns):\n",
    "    \"\"\"\n",
    "    Finds number of rows where certain columns are missing values.\n",
    "    ::param_df:: = target dataframe\n",
    "    ::param_columns:: = list of columns\n",
    "    \"\"\"\n",
    "    missing_vals = {}\n",
    "    print(\"Number of missing or NaN values for each column:\")\n",
    "    df_length = len(df)\n",
    "    for column in columns:\n",
    "        total_column_values = df[column].value_counts().sum()\n",
    "        missing_vals[column] = df_length-total_column_values\n",
    "        #missing_vals.append(str(column)+ \" column has {} missing or NaN values.\".format())\n",
    "    return missing_vals\n",
    "\n",
    "missing_values = find_missing_values(train, columns=train.columns)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ef780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = pd.DataFrame() # for discretised continuous variables\n",
    "df_con = pd.DataFrame() # for continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42230aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1300c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people survived?\n",
    "fig = plt.figure(figsize=(10,1))\n",
    "sns.countplot(y='Survived', data=train);\n",
    "print(train.Survived.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97311ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add this to our subset dataframes\n",
    "df_bin['Survived'] = train['Survived']\n",
    "df_con['Survived'] = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin['Pclass'] = train['Pclass']\n",
    "df_con['Pclass'] = train['Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the distribution of Sex\n",
    "plt.figure(figsize=(10, 1))\n",
    "sns.countplot(y=\"Sex\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Sex to the subset dataframes\n",
    "df_bin['female'] = train['Sex']\n",
    "df_bin['female'] = np.where(df_bin['female'] == 'female', 1, 0) # change sex to 0 for male and 1 for female\n",
    "\n",
    "df_con['Sex'] = train['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the Sex variable look compared to Survival?\n",
    "# We can see this because they're both binarys.\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "sns.distplot(df_bin.loc[df_bin['Survived'] == 1]['female'], kde_kws={'label': 'Survived'});\n",
    "sns.distplot(df_bin.loc[df_bin['Survived'] == 0]['female'], kde_kws={'label': 'Did not survive'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_dist(data, bin_df, label_column, target_column, figsize=(20, 5), use_bin_df=False):\n",
    "    \"\"\"\n",
    "    Function to plot counts and distributions of a label variable and \n",
    "    target variable side by side.\n",
    "    ::param_data:: = target dataframe\n",
    "    ::param_bin_df:: = binned dataframe for countplot\n",
    "    ::param_label_column:: = binary labelled column\n",
    "    ::param_target_column:: = column you want to view counts and distributions\n",
    "    ::param_figsize:: = size of figure (width, height)\n",
    "    ::param_use_bin_df:: = whether or not to use the bin_df, default False\n",
    "    \"\"\"\n",
    "    if use_bin_df: \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(y=target_column, data=bin_df);\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.distplot(data.loc[data[label_column] == 1][target_column], \n",
    "                     kde_kws={\"label\": \"Survived\"});\n",
    "        sns.distplot(data.loc[data[label_column] == 0][target_column], \n",
    "                     kde_kws={\"label\": \"Did not survive\"});\n",
    "    else:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(y=target_column, data=data);\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.distplot(data.loc[data[label_column] == 1][target_column], \n",
    "                     kde_kws={\"label\": \"Survived\"});\n",
    "        sns.distplot(data.loc[data[label_column] == 0][target_column], \n",
    "                     kde_kws={\"label\": \"Did not survive\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680789a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What values are there?\n",
    "train.SibSp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SibSp to subset dataframes\n",
    "df_bin['SibSp'] = train['SibSp']\n",
    "df_con['SibSp'] = train['SibSp']\n",
    "# Visualise the counts of SibSp and the distribution of the values\n",
    "# against Survived\n",
    "plot_count_dist(train, \n",
    "                bin_df=df_bin, \n",
    "                label_column='Survived', \n",
    "                target_column='SibSp', \n",
    "                figsize=(25,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What values are there?\n",
    "train.Parch.value_counts()\n",
    "# Add Parch to subset dataframes\n",
    "df_bin['Parch'] = train['Parch']\n",
    "df_con['Parch'] = train['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the counts of Parch and the distribution of the values\n",
    "# against Survived\n",
    "plot_count_dist(train, \n",
    "                bin_df=df_bin,\n",
    "                label_column='Survived', \n",
    "                target_column='Parch', \n",
    "                figsize=(25,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c53bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa86a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many kinds of ticket are there?\n",
    "train.Ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many kinds of fare are there?\n",
    "train.Fare.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5823a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Fare to sub dataframes\n",
    "df_con['Fare'] = train['Fare'] \n",
    "df_bin['Fare'] = pd.cut(train['Fare'], bins=5) # discretised \n",
    "# What do our Fare bins look like?\n",
    "df_bin.Fare.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the Fare bin counts as well as the Fare distribution versus Survived.\n",
    "plot_count_dist(data=train,\n",
    "                bin_df=df_bin,\n",
    "                label_column='Survived', \n",
    "                target_column='Fare', \n",
    "                figsize=(25,7), \n",
    "                use_bin_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bf32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Embarked to sub dataframes\n",
    "df_bin['Embarked'] = train['Embarked']\n",
    "df_con['Embarked'] = train['Embarked']\n",
    "# Remove Embarked rows which are missing values\n",
    "print(len(df_con))\n",
    "df_con = df_con.dropna(subset=['Embarked'])\n",
    "df_bin = df_bin.dropna(subset=['Embarked'])\n",
    "print(len(df_con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode binned variables\n",
    "one_hot_cols = df_bin.columns.tolist()\n",
    "one_hot_cols.remove('Survived')\n",
    "df_bin_enc = pd.get_dummies(df_bin, columns=one_hot_cols)\n",
    "\n",
    "df_bin_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode all continuous values using LabelEncoder()\n",
    "df_con_enc = df_con.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "df_con_enc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seclect the dataframe we want to use first for predictions\n",
    "selected_df = df_con_enc\n",
    "# Split the dataframe into data and labels\n",
    "X_train = selected_df.drop('Survived', axis=1) # data\n",
    "y_train = selected_df.Survived # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data for the CatBoost model\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the labels for the CatBoost model\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features for the CatBoost model\n",
    "cat_features = np.where(X_train.dtypes != np.float)[0]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CatBoost Pool() function to pool together the training data and categorical feature labels\n",
    "train_pool = Pool(X_train, \n",
    "                  y_train,\n",
    "                  cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost model definition\n",
    "catboost_model = CatBoostClassifier(iterations=10000,\n",
    "                                    custom_loss=['Accuracy'],\n",
    "                                    loss_function='Logloss')\n",
    "\n",
    "# Fit CatBoost model\n",
    "catboost_model.fit(train_pool,\n",
    "                   plot=True)\n",
    "\n",
    "# CatBoost accuracy\n",
    "acc_catboost = round(catboost_model.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CatBoost cross-validation\n",
    "start_time = time.time()\n",
    "\n",
    "# Set params for cross-validation as same as initial model\n",
    "cv_params = catboost_model.get_params()\n",
    "\n",
    "# Run the cross-validation for 10-folds (same as the other models)\n",
    "cv_data = cv(train_pool,\n",
    "             cv_params,\n",
    "             fold_count=10,\n",
    "             plot=True)\n",
    "\n",
    "# How long did it take?\n",
    "catboost_time = (time.time() - start_time)\n",
    "\n",
    "# CatBoost CV results save into a dataframe (cv_data), let's withdraw the maximum accuracy score\n",
    "acc_cv_catboost = round(np.max(cv_data['test-Accuracy-mean']) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the CatBoost model metrics\n",
    "print(\"---CatBoost Metrics---\")\n",
    "print(\"Accuracy: {}\".format(acc_catboost))\n",
    "print(\"Accuracy CV 10-Fold: {}\".format(acc_cv_catboost))\n",
    "print(\"Running Time: {}\".format(datetime.timedelta(seconds=catboost_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to be used for the predictions\n",
    "wanted_test_columns = X_train.columns\n",
    "wanted_test_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the CatBoost model on the wanted columns\n",
    "predictions = catboost_model.predict(test[wanted_test_columns]\n",
    "                                     .apply(LabelEncoder().fit_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02380569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our predictions array is comprised of 0's and 1's (Survived or Did Not Survive)\n",
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submisison dataframe and append the relevant columns\n",
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = test['PassengerId']\n",
    "submission['Survived'] = predictions # our model predictions on the test dataset\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert our submission dataframe 'Survived' column to ints\n",
    "submission['Survived'] = submission['Survived'].astype(int)\n",
    "print('Converted Survived column to integers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are our test and submission dataframes the same length?\n",
    "if len(submission) == len(test):\n",
    "    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\n",
    "else:\n",
    "    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39567aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert submisison dataframe to csv for submission to csv \n",
    "# for Kaggle submisison\n",
    "submission.to_csv('catboost_submission.csv', index=False)\n",
    "print('Submission CSV is ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
