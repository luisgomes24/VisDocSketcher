{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950a52af",
   "metadata": {},
   "source": [
    "# NVTabular on the GPU from an Internet enabled notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70b0dd",
   "metadata": {},
   "source": [
    "# NVTabular on the GPU without Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb7d2b",
   "metadata": {},
   "source": [
    "We unfortunately have to be a bit tricky here. Kaggle automatically unpacks archives in datasets, and Python packages are just that, archives. I zipped everything in order to avoid this problem, but Kaggle would still unarchive my main archive and continue unarchiving things.\n",
    "\n",
    "In order to work around the issue I mention above I removed the file extension on my archive. Below we are able to extract it regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a53ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q ../input/nvtabular-with-dependencies/nvt_all -d nvtabular-with-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f13f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-index --find-links ./nvtabular-with-dependencies nvtabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb678841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commands I used to download the dependencies.\n",
    "\n",
    "# !mkdir nvtabular_with_dependencies && cd nvtabular_with_dependencies && pip download nvtabular wheel pybind11\n",
    "# !cd nvtabular_with_dependencies  && zip -r nvt_all.zip .\n",
    "\n",
    "# from IPython.lib.display import FileLink\n",
    "# FileLink('nvtabular_with_dependencies/nvt_all.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08a378",
   "metadata": {},
   "source": [
    "# Check that everything worked and NVTabular runs on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'cats': np.random.randint(0, 100_000, 300_000_000), 'values': np.random.randn(300_000_000)})\n",
    "ds = nvt.Dataset(df, cpu=False, npartitions=10)\n",
    "\n",
    "out = ['cats', 'values'] >> nvt.ops.Groupby('cats', aggs=['min', 'std', 'last', 'max', 'mean'])\n",
    "cats_hashed = ['cats'] >> nvt.ops.HashBucket(10)\n",
    "\n",
    "wf = nvt.Workflow(out + cats_hashed)\n",
    "o = wf.fit_transform(ds)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
