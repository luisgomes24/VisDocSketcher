{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65576301",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2becf",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils import shuffle # Shuffle arrays or sparse matrices in a consistent way\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard,ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea875ebb",
   "metadata": {},
   "source": [
    "# Labels in order of severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CONTROL', 'AD', 'PD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd7c7f",
   "metadata": {},
   "source": [
    "# What is tqdm?\n",
    "<br><br>\n",
    "1. tqdm is a Python library that allows you to output a smart progress bar by wrapping around any iterable. \n",
    "<br><br>\n",
    "2. A tqdm progress bar not only shows you how much time has elapsed, but also shows the estimated time remaining for the iterable.\n",
    "<br><br>\n",
    "3. Resulting tqdm progress bar gives us information that includes the task completion percentage, number of iterations complete, time elapsed, estimated time remaining, and the iterations completed per second.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [] #Training Dataset\n",
    "Y_train = [] #Training Labels\n",
    "\n",
    "image_size=150\n",
    "\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/alzheimer-diseases-3-class/3_cls/', 'train', i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        image = cv2.imread(os.path.join(folderPath, j))\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        X_train.append(image)\n",
    "        Y_train.append(i)\n",
    "        \n",
    "        \n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/alzheimer-diseases-3-class/3_cls/', 'test', i) # Join two or more pathname components\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        image = cv2.imread(os.path.join(folderPath, j))\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        X_train.append(image)\n",
    "        Y_train.append(i)\n",
    "        \n",
    "#Image and Label is appended as list, now is to be converted into array\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape #No of sample = 7839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e605e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After shuffling sample size remains same\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cfaacd",
   "metadata": {},
   "source": [
    "# Converting String Label to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97578e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "y_test_new = []\n",
    "\n",
    "for i in Y_train:\n",
    "    y_train_new.append(labels.index(i))#Converting String Label to integer i.e\n",
    "                                       # CONTROL ---> 0, AD---> 1, PD ---> 2\n",
    "Y_train = to_categorical(y_train_new) #Converts a class vector (integers) to binary class matrix\n",
    "\n",
    "for i in Y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "\n",
    "Y_test = to_categorical(y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801ebc0",
   "metadata": {},
   "source": [
    "![image.png](attachment:dbe6dd77-bbb7-4233-b64d-833cf8ed7932.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input of model\n",
    "efficientnet_B0 = EfficientNetB0(include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of model\n",
    "model = efficientnet_B0.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(0.5)(model)\n",
    "model = tf.keras.layers.Dense(3, activation='softmax')(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge input and Output of model\n",
    "model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca97222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configures the model for training\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef655472",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "![image.png](attachment:6abbe112-ae3d-4ada-8c43-d45f4a010b2f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c4ce7",
   "metadata": {},
   "source": [
    "# ModelCheckpoint\n",
    "![image.png](attachment:740791f4-85d2-4f87-a42e-977e08e62a4d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275b139",
   "metadata": {},
   "source": [
    "# Verbose\n",
    "verbose: 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311594e4",
   "metadata": {},
   "source": [
    "# ReduceLROnPlateau\n",
    "![image.png](attachment:508a3aa0-7a37-402a-a96b-c9f63c7728de.png)\n",
    "<br>\n",
    "1. Models often benefit from reducing the learning rate by a factor\n",
    "of 2-10 once learning stagnates. \n",
    "<br>\n",
    "2. This callback monitors a quantity and if no improvement is seen for a 'patience' number\n",
    "of epochs, the learning rate is reduced.\n",
    "<br>\n",
    "3. monitor: quantity to be monitored.\n",
    "<br>\n",
    "4. factor: factor by which the learning rate will be reduced.\n",
    "<br>\n",
    "       <b> new_lr = lr * factor`. </b>\n",
    "<br>\n",
    "5. patience: number of epochs with no improvement after which learning rate\n",
    "      will be reduced.\n",
    "<br>\n",
    "6. min_delta: threshold for measuring the new optimum, to only focus on\n",
    "      significant changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58308a7c",
   "metadata": {},
   "source": [
    "# EarlyStopping\n",
    "![image.png](attachment:e4fadc60-f3ba-4c74-9c94-33887ac7478f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorBoard = TensorBoard(log_dir=\"logs\")\n",
    "checkPoint = ModelCheckpoint(\"efficient_net_B0.h5\",\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=0.3,\n",
    "                             patience=2,\n",
    "                             verbose=1,\n",
    "                             mode='auto',\n",
    "                             min_delta=0.001)\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   patience=5,\n",
    "                   verbose=1,\n",
    "                   mode='auto',\n",
    "                   restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorBoard, checkPoint, reduce_lr, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac83fc",
   "metadata": {},
   "source": [
    "![image.png](attachment:4b2dd021-61aa-4f29-af5c-897bba70c11b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188063ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "actual_label = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(actual_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(actual_label, pred)\n",
    "plt.figure(figsize=(8,6), dpi=70, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(cnf, cmap='Blues',annot=True, fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Alzheimer\\'s Disease Classification')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727c1bd",
   "metadata": {},
   "source": [
    "# plot_model\n",
    "![image.png](attachment:75c53aec-61f8-4d39-9b60-c644c0ae457e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model(\"./efficient_net_B0.h5\")\n",
    "\n",
    "#Show Model Architecture\n",
    "plot_model(saved_model,\n",
    "          to_file='efficient_net_B0.png',\n",
    "          show_shapes=True,\n",
    "          show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a48d3",
   "metadata": {},
   "source": [
    "# Uploading Image and Showing its Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f0870",
   "metadata": {},
   "source": [
    "1. BytesIO is used to read locally stored image\n",
    "2. FileUpload() ---> Upload file(s) from browser to Python kernel as bytes\n",
    "3. <b>display</b>\n",
    "<br>\n",
    "    a. Display a Python object in all frontends.\n",
    "<br>\n",
    "    b. By default all representations will be computed and sent to the frontends.\n",
    "<br>\n",
    "    c. Frontends can decide which representation is used and how.\n",
    "4. <b>Button widget</b>\n",
    "   <br>\n",
    "   This widget has an `on_click` method that allows you to listen for the user clicking on the button\n",
    "5. <b> Output </b> \n",
    "   <br>\n",
    "Widget used as a context manager to display output\n",
    "6. <b> clear_output() </b>\n",
    "   <br>\n",
    "   Clear the output of the current cell receiving output\n",
    "7. <b> on_click()</b>\n",
    "<br>\n",
    "Register a callback to execute when the button is clicked.\n",
    "8. <b> VBox</b>\n",
    "<br>\n",
    "Displays multiple widgets vertically using the flexible box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagePrediction(upload):\n",
    "    for name, fileinfo  in uploader.value.items():\n",
    "        image = Image.open(io.BytesIO(fileinfo['content']))\n",
    "        \n",
    "    images = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    images = cv2.resize(images,(150, 150))\n",
    "    images = images.reshape(1, 150, 150, 3)\n",
    "    prd = model.predict(images)\n",
    "    prd = np.argmax(prd, axis = 1)[0]\n",
    "    \n",
    "    \n",
    "    if prd == 0:\n",
    "        prd = \"CONTROL\"\n",
    "    elif prd == 1:\n",
    "        prd = \"AD\"\n",
    "    elif prd ==2:\n",
    "        prd = \"PD\"\n",
    "        \n",
    "    print(f'Model Predict That is  a {prd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad98c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader = widgets.FileUpload()\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(description= \"Predict\")\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_button_click(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            imagePrediction(uploader)\n",
    "        except:\n",
    "            print(\"Please Enter the Correct Image files\")\n",
    "            \n",
    "            \n",
    "button.on_click(on_button_click)\n",
    "widgets.VBox([button, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcf80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
