{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16a2f9c",
   "metadata": {},
   "source": [
    "*This is my first kernel on Pytorch-Lightning*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab7454",
   "metadata": {},
   "source": [
    "Please UpVote if you like this kernel..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f5138",
   "metadata": {},
   "source": [
    "*Import  the required Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626923c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as pe\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from transformers import (BertTokenizer,BertModel,AdamW,get_linear_schedule_with_warmup)\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from pytorch_lightning.metrics.functional.classification import auroc\n",
    "import warnings\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14085c3d",
   "metadata": {},
   "source": [
    "*General Configuration parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED =42\n",
    "sns.set(style='whitegrid',palette='muted',font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = ['#f0d407','#fbec7e','#04345b','#596e3e','#948304','#2f524f']\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize']=12,8\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b6dfd",
   "metadata": {},
   "source": [
    "*Lets check the files present for this competetion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e36f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIR = '../input/jigsaw-toxic-comment-classification-challenge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c64510",
   "metadata": {},
   "source": [
    "*Importing the datasets* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad628cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PARENT_DIR,'train.csv.zip'))\n",
    "test_df = pd.read_csv(os.path.join(PARENT_DIR,'test.csv.zip'))\n",
    "test_lab_df = pd.read_csv(os.path.join(PARENT_DIR,'test_labels.csv.zip'))\n",
    "sample_df = pd.read_csv(os.path.join(PARENT_DIR,'sample_submission.csv.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a2b58",
   "metadata": {},
   "source": [
    "*Lets take a look into the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5d14e",
   "metadata": {},
   "source": [
    "*Below some sample of toxic comment can be seen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6629c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_toxic_words = train_df.head(100)[train_df.head(5000).sum(axis=1)>=3]\n",
    "sample_toxic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09106c9c",
   "metadata": {},
   "source": [
    "*Lets build a wordcloud for a visual representation of toxic words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(df):\n",
    "    comment_words = ''   \n",
    "    stopwords = set(STOPWORDS) \n",
    "    # iterate through the csv file \n",
    "    for val in df.comment_text: \n",
    "        # typecaste each val to string \n",
    "        val = str(val) \n",
    "\n",
    "        # split the value \n",
    "        tokens = val.split() \n",
    "\n",
    "        # Converts each token into lowercase \n",
    "        for i in range(len(tokens)): \n",
    "            tokens[i] = tokens[i].lower() \n",
    "\n",
    "        comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white',  \n",
    "                stopwords=stopwords,\n",
    "                min_font_size = 10).generate(comment_words) \n",
    "\n",
    "\n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(sample_toxic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636dd39e",
   "metadata": {},
   "source": [
    "*Lets check of there is multiple comment present from same ID,s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also there is exactly one comment from each ID,s\n",
    "train_df.id.value_counts()[train_df.id.value_counts(ascending=False)>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2db78",
   "metadata": {},
   "source": [
    "*Now lets split the data training dataset into training and validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e316c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,val_df = model_selection.train_test_split(train_df,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f8ea2",
   "metadata": {},
   "source": [
    "*Lets create a list of labels for modelling purpose*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31830c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959b29a",
   "metadata": {},
   "source": [
    "*Lets check the distribution of different type of toxic comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ade62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_c = pd.DataFrame(train_df[LABEL_COLUMNS].sum()).reset_index()\n",
    "lab_c.columns = ['Type','Count']\n",
    "fig = pe.bar(lab_c, x='Type', y='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4b7a6",
   "metadata": {},
   "source": [
    "*Lets Handle the imbalence in the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_toxic_clean_mix = pd.DataFrame(train_df[LABEL_COLUMNS].sum()).reset_index()\n",
    "lab_toxic_clean_mix.columns = ['Type','Count'] \n",
    "lab_toxic_clean_mix.loc[len(lab_toxic_clean_mix.index)] = ['Clean',len(train_df) -lab_toxic_clean_mix.Count.sum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab9d54",
   "metadata": {},
   "source": [
    "*Lets plot toxic and clean data count*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2daa23b",
   "metadata": {},
   "source": [
    "*In Below plot we can clearly notice that there is a huge count gap between the toxic and regular comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462df262",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pe.bar(lab_toxic_clean_mix, x='Type', y='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88a710",
   "metadata": {},
   "source": [
    "*I am creating a dataframe with equal number of samples from clean and toxic lables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_df = train_df[train_df[LABEL_COLUMNS].sum(axis=1)>0]\n",
    "clean_df = train_df[train_df[LABEL_COLUMNS].sum(axis=1)==0]\n",
    "\n",
    "train_df = pd.concat([\n",
    "    toxic_df,\n",
    "    clean_df.sample(15_000)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c401e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c64fb",
   "metadata": {},
   "source": [
    "*Lets Experiment with a single comment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d77168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = train_df[train_df.id=='325cd3656d865766']\n",
    "sample_row = sample_row.iloc[0]\n",
    "sample_comment = sample_row.comment_text\n",
    "sample_labels = sample_row[LABEL_COLUMNS]\n",
    "\n",
    "print(sample_comment)\n",
    "print()\n",
    "print(sample_labels.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394806a4",
   "metadata": {},
   "source": [
    "*Defining the tokenizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6755a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding  = tokenizer.encode_plus(sample_comment,\n",
    "                     add_special_tokens=True,\n",
    "                     max_length=512,\n",
    "                     return_token_type_ids=False,\n",
    "                     padding = 'max_length',\n",
    "                     return_attention_mask=True,\n",
    "                     return_tensors='pt'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding consist of input_ids and attenssion mask\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding['input_ids'].shape,encoding['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding['input_ids'].squeeze()[:50])\n",
    "print(encoding['attention_mask'].squeeze()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d96938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'].squeeze()[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed257baf",
   "metadata": {},
   "source": [
    "*Before Strting the dataset creation lets find out the max length from dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "length = []\n",
    "for sent in train_df.comment_text:\n",
    "    lent = len(word_tokenize(sent))\n",
    "    length.append(lent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c30947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7201d",
   "metadata": {},
   "source": [
    "*Here we can notoce that the mean length is very less so i am going to use my max token length as 128*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0397ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753d831",
   "metadata": {},
   "source": [
    "*Now lets create our dataset for modeling , We can override few functions as per our need to create a custom dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self,data:pd.DataFrame,tokenizer:BertTokenizer,max_token_len:int=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx:int):\n",
    "        data_row = self.data.iloc[idx]\n",
    "        comment_text = data_row.comment_text\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "                 comment_text,\n",
    "                 add_special_tokens=True,\n",
    "                 max_length=self.max_token_len,\n",
    "                 return_token_type_ids=False,\n",
    "                 padding = 'max_length',\n",
    "                 truncation = True,\n",
    "                 return_attention_mask=True,\n",
    "                 return_tensors='pt'\n",
    "                 )\n",
    "\n",
    "        return dict(\n",
    "            comment_text = comment_text,\n",
    "            input_ids = encoding['input_ids'].flatten(),\n",
    "            attention_mask = encoding['attention_mask'].flatten(),\n",
    "            labels = torch.FloatTensor(labels)\n",
    "\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb544f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ToxicCommentsDataset(train_df,tokenizer)\n",
    "sample_row = train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394a02b",
   "metadata": {},
   "source": [
    "*Lets see the size of our return values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196992a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row['input_ids'].shape,sample_row['attention_mask'].shape,sample_row['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_text = sample_row['comment_text']\n",
    "input_id = sample_row['input_ids']\n",
    "attention_m = sample_row['attention_mask']\n",
    "text_lab = sample_row['labels']\n",
    "\n",
    "print(comment_text)\n",
    "print()\n",
    "print(input_id)\n",
    "print()\n",
    "print(attention_m)\n",
    "print()\n",
    "print(text_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6202732",
   "metadata": {},
   "source": [
    "*Lets Define our bert model for testing , Ignore below section not requied*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fac43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(BERT_MODEL_NAME,return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction = bert_model(sample_row['input_ids'].unsqueeze(dim=0),sample_row['attention_mask'].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eecdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction.last_hidden_state.shape,sample_prediction.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ac7e6",
   "metadata": {},
   "source": [
    "*Below is the code to create dataloader which will take Dataset class as input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,train_df,test_df,tokenizer,batch_size=8,max_token_len=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len=max_token_len\n",
    "        \n",
    "    def setup(self):\n",
    "        self.train_dataset = ToxicCommentsDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        self.test_dataset = ToxicCommentsDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers = 4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size = 1,num_workers = 4)\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size = 1,num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecf92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ToxicCommentDataModule(train_df,val_df,tokenizer,batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e8253",
   "metadata": {},
   "source": [
    "*Lets create class for actually model configuration , loss and metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7608be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentClassifier(pl.LightningModule):\n",
    "    def __init__(self,n_classes:int,steps_per_epoch:None,n_epochs=None):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME,return_dict = True)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size,n_classes)\n",
    "        \n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        \n",
    "        \n",
    "    def forward(self,input_ids,attention_mask,labels=None):\n",
    "        output = self.bert(input_ids,attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output,labels)\n",
    "        return loss ,output\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        loss,outputs = self(input_ids,attention_mask,labels)\n",
    "        self.log('train_loss',loss,prog_bar=True,logger=True)\n",
    "        return {\"loss\":loss,\"predictions\":outputs,\"labels\":labels}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss,outputs = self(input_ids,attention_mask,labels)\n",
    "        self.log('val_loss',loss,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        loss,outputs = self(input_ids,attention_mask,labels)\n",
    "        self.log('test_loss',loss,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self,outputs):\n",
    "        labels = []\n",
    "        predictions=[]\n",
    "        \n",
    "        for output in outputs:\n",
    "            for out_labels in output['labels'].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output['predictions'].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "                \n",
    "        labels = torch.stack(labels)\n",
    "        predictions = torch.stack(predictions)\n",
    "        \n",
    "        for i,name in enumerate(LABEL_COLUMNS):\n",
    "            roc_score = auroc(predictions[:,i],labels[:,i])\n",
    "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\",roc_score,self.current_epoch)\n",
    "            \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer =  AdamW(self.parameters(), lr=2e-5)\n",
    "        \n",
    "        \n",
    "        warmup_steps = self.steps_per_epoch // 3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "        \n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            warmup_steps,\n",
    "            total_steps\n",
    "        )\n",
    "        \n",
    "        return [optimizer],[scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToxicCommentClassifier(n_classes=6,\n",
    "                               steps_per_epoch=len(train_df)//BATCH_SIZE,\n",
    "                              n_epochs=N_EPOCHS\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05115b69",
   "metadata": {},
   "source": [
    "*Lets run our trainer enable fast_dev_run if you want to just do a quick run its helps in dubugging the code *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=N_EPOCHS,\n",
    "                     gpus=1,\n",
    "                     progress_bar_refresh_rate=30\n",
    "#                      fast_dev_run=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92328396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extension and start TensorBoard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./lightning_logs\n",
    "# %reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09883563",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ed298",
   "metadata": {},
   "source": [
    "*Save the best model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"final_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a6990",
   "metadata": {},
   "source": [
    "*Load the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dae522",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = ToxicCommentClassifier.load_from_checkpoint('./final_checkpoint.ckpt',\n",
    "                                                            n_classes=6,\n",
    "                                                            steps_per_epoch=len(train_df)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144f6e9",
   "metadata": {},
   "source": [
    "# Work in progress below i have just checked for a single comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603b920",
   "metadata": {},
   "source": [
    "*Lets test on a small sample *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3841ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = \"Nonsense cocksucker Fuck? Kiss off,geek.What i said is true.I will have you account terminated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356369c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding  = tokenizer.encode_plus(test_comment,\n",
    "                     add_special_tokens=True,\n",
    "                     max_length=128,\n",
    "                     return_token_type_ids=False,\n",
    "                     padding = 'max_length',\n",
    "                     return_attention_mask=True,\n",
    "                     return_tensors='pt'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,prediction = trained_model(encoding['input_ids'],encoding['attention_mask'])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15748ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = prediction.detach().numpy()\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b593000",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "\n",
    "for i,label in enumerate(LABEL_COLUMNS):\n",
    "    label_prob = test_prediction[:,i]\n",
    "    \n",
    "    if label_prob>0.5:\n",
    "        prediction_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94362b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b167ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
