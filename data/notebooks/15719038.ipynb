{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Import Tensorflow modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files :) \n",
    "for dirname, _, filenames in os.walk('/content/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de294c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6344143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_data(fullpath):\n",
    "    data = pd.read_csv(fullpath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b590b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths where data for training and testing are.\n",
    "train_path = \"/kaggle/input/digit-recognizer/train.csv\"\n",
    "test_path =  \"/kaggle/input/digit-recognizer/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb917fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the training path \n",
    "raw_data = read_input_data(train_path)\n",
    "# get size of dataset\n",
    "dataset_size = raw_data.shape[0]\n",
    "# get training size to be 80% of all data\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "# split between training set and validation set\n",
    "train_features = raw_data.iloc[:train_size,1:]\n",
    "train_labels = raw_data.iloc[:train_size, :1]\n",
    "# get validation set features and labels\n",
    "val_features = raw_data.iloc[train_size:,1:]\n",
    "val_labels = raw_data.iloc[train_size:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c72384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_features.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98616aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
    "training_ds = tf.reshape(training_ds,[train_features.shape[0],28,28])\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((training_ds, train_labels))\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset to tensor\n",
    "validation_ds = tf.convert_to_tensor(val_features, dtype=tf.float32)\n",
    "validation_ds = tf.reshape(validation_ds,[val_features.shape[0],28,28])\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((validation_ds, val_labels))\n",
    "val_dataset = val_dataset.repeat()\n",
    "val_dataset = val_dataset.shuffle(1000)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE,  drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ebf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data for testing using Pandas read_csv\n",
    "test_ds = pd.read_csv(test_path).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b00876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_test_data():\n",
    "    # get size of the test dataset\n",
    "    len_test_ds = test_ds.shape[0]\n",
    "    print(len_test_ds)\n",
    "    # Convert the data to be a tensor \n",
    "    test_data = tf.convert_to_tensor(test_ds, dtype=tf.float32)\n",
    "    # reshape the test dataset to be 28000 x 28 x 28 \n",
    "    test_data = tf.reshape(test_data,[len_test_ds,28,28])\n",
    "    test_data = tf.data.Dataset.from_tensor_slices((test_data))\n",
    "    test_data = test_data.batch(BATCH_SIZE)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc973c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = reshape_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the first features ( labels  + pixels)\n",
    "for features, label in train_dataset.take(1):\n",
    "    print(label[:3])\n",
    "    for i, feature in enumerate(features):\n",
    "        if i>1:\n",
    "            break\n",
    "        print(f\" {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(features, labels):\n",
    "    image = tf.stack(features, axis=0)\n",
    "    image = tf.reshape(image, [-1,28,28,1])\n",
    "\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.map(make_features)\n",
    "train_data = train_data.cache()\n",
    "\n",
    "val_data = val_dataset.map(make_features)\n",
    "val_data = val_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aec976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in train_dataset.take(1):\n",
    "    print(features[0][0])\n",
    "    print(label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90154a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img_batch, label_batch):\n",
    "    plt.figure(figsize=(4,4), dpi=120)\n",
    "\n",
    "    # Show 4 images in a row from the batch passed by args\n",
    "    for n in range(4):\n",
    "        plt.subplot(1,4,n+1)\n",
    "        plt.imshow(img_batch[:4][n])\n",
    "        plt.title(label_batch[n].numpy())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the data \n",
    "img_batch, label_batch = next(iter(train_dataset))\n",
    "show_images(img_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fed3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(28,28,1), name='Rescale_layer'),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu', name='conv2d_1'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu', name='conv2d_2'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu', name='conv2d_3'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Flatten(name='flatten'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=int(train_size//BATCH_SIZE),\n",
    "    validation_data=val_data,\n",
    "    validation_steps=int(val_size//BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd681a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9675f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4), dpi=120)\n",
    "\n",
    "# Show 4 images in a row from the batch passed by args\n",
    "for n in range(4):\n",
    "    plt.subplot(1,4,n+1)\n",
    "    plt.imshow(test_batch[:4][n])\n",
    "    plt.title(f\"Pred:{preds[n]}\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890870be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_size = preds.shape[0]\n",
    "test_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47494837",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(1, test_dataset_size+1)\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV with Predictions \n",
    "pred_df = pd.DataFrame({'ImageId': ids,'Label': preds})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('lu_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
