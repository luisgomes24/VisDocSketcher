{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90df89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['label']).copy()\n",
    "y_train = train.label\n",
    "\n",
    "X_test = test.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ae3a1",
   "metadata": {},
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтабы ускорить процессы\n",
    "#subsample_size = 5000\n",
    "\n",
    "#np.random.seed(42)\n",
    "#subsample_index = np.random.choice(train.shape[0], subsample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xs_train = X_train.iloc[subsample_index]\n",
    "#ys_train = y_train.iloc[subsample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf76fa",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1, verbose=1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab3d96",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6d930",
   "metadata": {},
   "source": [
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 1) \n",
    "param_grid = {'n_estimators': [400,500,700,800], 'criterion':['gini','entropy'],\n",
    "              'bootstrap': [True], 'max_depth': [15, 20, 25], \n",
    "              'max_features': ['auto','sqrt', 10], \n",
    "              'min_samples_leaf': [2,3], \n",
    "              'min_samples_split': [2,3]}\n",
    "\n",
    "clf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1) \n",
    "best_clf_rf = clf_rf.fit(X_train,y_train) \n",
    "clf_performance(best_clf_rf,'Random Forest') \n",
    "rf_score = str(best_clf_rf.bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, X_test.shape[0] + 1),\n",
    "    'Label': y_test_pred_rfc\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
