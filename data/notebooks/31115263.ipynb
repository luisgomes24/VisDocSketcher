{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import math\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43883493",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5490fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
    "#print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "plain_datagen = ImageDataGenerator()\n",
    "scaled_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# prepare an iterators to scale images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63de0e",
   "metadata": {},
   "source": [
    "Reference: https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c96466",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_image_raw_dict = {}\n",
    "lr_image_raw_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_images(standardize= False, resize = False, resize_width = None, resize_height = None):\n",
    "    hr_image_list = glob.glob('/kaggle/input/super-image-resolution/Data/HR/*')\n",
    "    \n",
    "    for i in tqdm(hr_image_list):\n",
    "        filename_wo_ext = i.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        if resize:\n",
    "            hr_image_raw_dict[filename_wo_ext] = cv2.resize(cv2.imread(i),fx = resize_height,\n",
    "                                                           fy = resize_width)\n",
    "        else:\n",
    "            \n",
    "            hr_image_raw_dict[filename_wo_ext] = cv2.imread(i)\n",
    "        \n",
    "        if standardize:\n",
    "            hr_image_raw_dict[filename_wo_ext] = hr_image_raw_dict[filename_wo_ext]/255.0 \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    lr_image_list = glob.glob('/kaggle/input/super-image-resolution/Data/LR/*')\n",
    "    \n",
    "    for i in tqdm(lr_image_list):\n",
    "        filename_wo_ext = i.split('/')[-1].split('.')[0]\n",
    "        if resize:\n",
    "            lr_image_raw_dict[filename_wo_ext] = cv2.resize(cv2.imread(i),fx = resize_height,\n",
    "                                                           fy = resize_width)\n",
    "        else:\n",
    "            \n",
    "            lr_image_raw_dict[filename_wo_ext] = cv2.imread(i)\n",
    "        #lr_image_raw_dict[filename_wo_ext] = cv2.imread(i)    \n",
    "        \n",
    "        if standardize:\n",
    "            lr_image_raw_dict[filename_wo_ext] = lr_image_raw_dict[filename_wo_ext]/255.0 \n",
    "            \n",
    "        \n",
    "    return hr_image_raw_dict, lr_image_raw_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c13fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_image_raw_dict, lr_image_raw_dict = load_images(standardize = False, resize = False, resize_width = None, resize_height = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    a = str(np.random.randint(0,99))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "    plt.imshow(hr_image_raw_dict[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(lr_image_raw_dict[a])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ea872",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_image_raw_dict[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_image_raw_dict[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd57521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1)))) / 2.303\n",
    "\n",
    "def SSIM(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n",
    "\n",
    "\n",
    "def model_train_plot(history):\n",
    "    \n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.plot(history.history['SSIM'])\n",
    "    plt.plot(history.history['val_SSIM'])\n",
    "    plt.title('model SSIM')\n",
    "    plt.ylabel('SSIM')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['PSNR'])\n",
    "    plt.plot(history.history['val_PSNR'])\n",
    "    plt.title('model PSNR')\n",
    "    plt.ylabel('PSNR')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape = (96,96,3)))\n",
    "    model.add(layers.Conv2D(filters = 32, kernel_size= 3, padding = 'same', strides = 1,activation='relu'))\n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size= 3, padding = 'same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters = 128, kernel_size= 9, padding = 'same', activation='relu' ))\n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size= 9, padding = 'same', activation='relu'))\n",
    "    model.add(layers.UpSampling2D(size = (2,2)))\n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size= 3, padding = 'same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters = 128, kernel_size= 9, padding = 'same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters = 32, kernel_size= 3, padding = 'same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters = 32, kernel_size= 3, padding = 'same', activation='relu'))\n",
    "    model.add(layers.UpSampling2D(size = (2,2)))\n",
    "    model.add(layers.Dense(3, activation=\"relu\"))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = 'MSE', metrics = [PSNR, 'accuracy', SSIM])\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = lr_image_raw_dict.values()\n",
    "y_train = hr_image_raw_dict.values()\n",
    "x_train = np.array(list(x_train))\n",
    "y_train = np.array(list(y_train))\n",
    "\n",
    "train_iterator_plain = plain_datagen.flow(x_train, y_train, batch_size=2)\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136875b",
   "metadata": {},
   "source": [
    "# Unscaled Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_iterator_plain, batch_size=2, epochs=2000, verbose= 0 )\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=2, epochs=2000, verbose= 0,\n",
    "                   callbacks=[earlystop_callback], validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038eee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd5ea4",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ad213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    a = str(np.random.randint(0,99))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "    plt.imshow(hr_image_raw_dict[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(lr_image_raw_dict[a])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Super Resolved Image ', color = 'red', fontsize = 20)\n",
    "    plt.imshow(model.predict(np.array(list(lr_image_raw_dict[a])).reshape(1, 96,96,3)).reshape(384,384,3))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51347734",
   "metadata": {},
   "source": [
    "# Scaled Data Visualisation\n",
    "Reference: https://machinelearningmastery.com/how-to-evaluate-pixel-scaling-methods-for-image-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcf886",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_image_raw_dict_scale, lr_image_raw_dict_scale = load_images(standardize = True, resize = False, resize_width = None, resize_height = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    a = str(np.random.randint(0,99))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "    plt.imshow(hr_image_raw_dict_scale[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(lr_image_raw_dict_scale[a])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator_scaled = scaled_datagen.flow(x_train, y_train, batch_size=2)\n",
    "\n",
    "# train_iterator_scaled = scaled_datagen.flow(x_train[0].reshape(1,96, 96, 3) , \n",
    "#                                             y_train[0].reshape(1, 384, 384, 3), \n",
    "#                                                                batch_size=1)\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888d90d",
   "metadata": {},
   "source": [
    "# Scaled Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_iterator_scaled, batch_size=2, epochs=2000, verbose= 2 )\n",
    "\n",
    "x_train = lr_image_raw_dict_scale.values()\n",
    "y_train = hr_image_raw_dict_scale.values()\n",
    "x_train = np.array(list(x_train))\n",
    "y_train = np.array(list(y_train))\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=2, epochs=2000, verbose= 0,\n",
    "                   callbacks=[earlystop_callback], validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3b142",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b49704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the data in X_train, y_train variables by iterating over the batches\n",
    "# train_iterator_scaled.reset()\n",
    "# X_train, Y_train = next(train_iterator_scaled)\n",
    "# for i in tqdm(range(int(len(train_iterator_scaled))-1)): #1st batch is already fetched before the for loop.\n",
    "#     img, label = next(train_iterator_scaled)\n",
    "#     X_train = np.append(X_train, img, axis=0 )\n",
    "#     Y_train = np.append(Y_train, label, axis=0)\n",
    "# print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in range(4):\n",
    "#     a = np.random.randint(0,99)\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "#     plt.imshow(Y_train[a])\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "#     plt.imshow(X_train[a])\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.title('Super Resolved Image ', color = 'red', fontsize = 20)\n",
    "#     plt.imshow(model.predict(np.array(list(X_train[a])).reshape(1, 96,96,3)).reshape(384,384,3))\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77742d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    a = str(np.random.randint(0,99))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
    "    plt.imshow(hr_image_raw_dict_scale[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(lr_image_raw_dict_scale[a])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Super Resolved Image ', color = 'red', fontsize = 20)\n",
    "    plt.imshow(model.predict(np.array(list(lr_image_raw_dict_scale[a])).reshape(1, 96,96,3)).reshape(384,384,3))\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
