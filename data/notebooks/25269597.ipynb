{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14351d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cded80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_text(text):\n",
    "    text = text.lower()  # covert the text to lowercase\n",
    "    text = re.sub('<.*?>','',text).strip() # remove html chars\n",
    "    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n",
    "    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.comment_text = train_df.comment_text.astype(str)\n",
    "train_df.comment_text = train_df.comment_text.apply(clean_review_text)\n",
    "train_df.comment_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "def apply_stemmer(text):\n",
    "    words = text.split()\n",
    "    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ffc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.comment_text = train_df.comment_text.apply(apply_stemmer)\n",
    "train_df.comment_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002358b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.comment_text\n",
    "y = train_df.drop(['id','comment_text'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',     \n",
    "    analyzer='word',            \n",
    "    token_pattern=r'\\w{1,}',    \n",
    "    ngram_range=(1, 3),         \n",
    "    stop_words='english',\n",
    "    sublinear_tf=True)\n",
    "\n",
    "word_vectorizer.fit(x_train)    \n",
    "train_word_features = word_vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37280054",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = word_vectorizer.transform(x_train)\n",
    "X_test_transformed = word_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed=100\n",
    "\n",
    "log_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n",
    "\n",
    "# fit model\n",
    "classifier_ovr_log = OneVsRestClassifier(log_reg)\n",
    "classifier_ovr_log.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\n",
    "y_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_predictions(df,classifier):\n",
    "    df.comment_text = df.comment_text.apply(clean_review_text)\n",
    "    df.comment_text = df.comment_text.apply(apply_stemmer)\n",
    "    X_test = df.comment_text\n",
    "    X_test_transformed = word_vectorizer.transform(X_test)\n",
    "    y_test_pred = classifier.predict_proba(X_test_transformed)\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=make_test_predictions(test_df,classifier_ovr_log)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.concat([test_df.id, y_pred_df], axis=1)\n",
    "submission_df.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
