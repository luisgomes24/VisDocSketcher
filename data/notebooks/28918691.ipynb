{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47698cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/adult-income-dataset/adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f130b5",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfa525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1eb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "categorical = df.loc[:, ~df.columns.isin(numerical)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid', palette = 'deep', font_scale = 1.1, rc = {'figure.figsize' : [8,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize = (20,10))\n",
    "\n",
    "for variable, subplot in zip(numerical, ax.flatten()):\n",
    "    \n",
    "    sns.histplot(df[variable],kde = True, ax = subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, figsize = (25, 25))\n",
    "\n",
    "for variable, subplot in zip(categorical, ax.flatten()):\n",
    "    \n",
    "    sns.countplot(x = variable, ax = subplot, hue = 'income', data = df)\n",
    "    \n",
    "    for label in subplot.get_xticklabels():\n",
    "        \n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ad8f2",
   "metadata": {},
   "source": [
    "# Cleanup the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1c1e0",
   "metadata": {},
   "source": [
    "It is observed that few column have '?' as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a26657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    \n",
    "    df[i].replace('?', 'otheres', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbc824",
   "metadata": {},
   "source": [
    "# Scaling and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffaee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6806137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae563e03",
   "metadata": {},
   "source": [
    "*One hot encoding for following columns:*\n",
    "* gender (Gender count has some weightage for both male (1) and female(0))\n",
    "* race (Races Black (1) and White (1) have considerable count, rest have very low count (0))\n",
    "\n",
    "*Marital status, Occupation, Relationship, Education and Workclass have considerable population count across all categories*\n",
    "* marital status \n",
    "* occupation \n",
    "* relationship\n",
    "* education\n",
    "* workclass\n",
    "\n",
    "*For country, we can encode based on the Min and Max of the count of population*\n",
    "\n",
    "\n",
    "*For Numerical Data, we will use MinMax scaling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9443770",
   "metadata": {},
   "source": [
    "**Categorical Data Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf619c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_one_hot(col):\n",
    "    \n",
    "    if col == '<=50K':\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "df1['if_<=50K'] = df['income'].apply(income_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoding(col):\n",
    "    \n",
    "    if col == 'White':\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "def Encoding_black(col):\n",
    "    \n",
    "    if col == 'Black':\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "df1['if_white'] = df['race'].apply(Encoding)\n",
    "df1['is_black'] =  df['race'].apply(Encoding_black)\n",
    "df1.drop(['race'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'] = pd.get_dummies(df['gender'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(pd.get_dummies(df['marital-status'], drop_first = True))\n",
    "df1.drop('marital-status', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(pd.get_dummies(pd.get_dummies(df['occupation'], drop_first = True)))\n",
    "df1.drop('occupation', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(pd.get_dummies(pd.get_dummies(df['relationship'], drop_first = True)))\n",
    "df1.drop('relationship', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da86fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(pd.get_dummies(pd.get_dummies(df['education'], drop_first = True)))\n",
    "df1.drop('education', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7455843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(pd.get_dummies(pd.get_dummies(df['workclass'],prefix = 'workclass_', drop_first = True)))\n",
    "df1.drop('workclass', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('income', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd526e93",
   "metadata": {},
   "source": [
    "To scale the country, we first have to map the countries with their population count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_incoding_list = dict(df['native-country'].value_counts())\n",
    "df1['native-country'] = df1['native-country'].map(count_incoding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['native-country']] = scaler.fit_transform(df1[['native-country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda72058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[numerical] = scaler.fit_transform(df1[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041865be",
   "metadata": {},
   "source": [
    "We have encoded all the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44e0f1",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2731089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e569574",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.loc[:, df1.columns!= 'if_<=50K']\n",
    "y = df1['if_<=50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5bbc8",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = {}\n",
    "acc_test = {}\n",
    "for i in range(1,15,2):\n",
    "    classification_model = neighbors.KNeighborsClassifier(i) \n",
    "    classification_model.fit(x_train, y_train)\n",
    "    acc_train[i] = classification_model.score(x_train, y_train)\n",
    "    acc_test[i] = classification_model.score(x_test, y_test)  \n",
    "    \n",
    "    print('\\nk = ', i )\n",
    "    print('train acc = ', classification_model.score(x_train, y_train) )\n",
    "    print('test acc  = ', classification_model.score(x_test, y_test)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c52830",
   "metadata": {},
   "source": [
    "*Plotting bias and variance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c57d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_train.keys(),acc_train.values())\n",
    "plt.plot(acc_test.keys(),acc_test.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da4bd3",
   "metadata": {},
   "source": [
    "From above calculation and plot, it is observed that bias and variance converge around k = 13.\n",
    "\n",
    "So, we can use K = 13 for further parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 13\n",
    "\n",
    "\n",
    "metric_acc_training = {}\n",
    "metric_acc_testing = {}\n",
    "\n",
    "dist_calc = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "\n",
    "for calculation in dist_calc:\n",
    "    \n",
    "    classification_model = neighbors.KNeighborsClassifier(k, metric = calculation) \n",
    "    classification_model.fit(x_train, y_train)\n",
    "    metric_acc_training[calculation] = classification_model.score(x_train, y_train)\n",
    "    metric_acc_testing[calculation] = classification_model.score(x_test, y_test) \n",
    "    \n",
    "    print('\\nCalculation : ', calculation)\n",
    "    print('Training accuracy :  ', classification_model.score(x_train, y_train))\n",
    "    print('Testing accuracy : ', classification_model.score(x_test, y_test) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06488f9c",
   "metadata": {},
   "source": [
    "There is not much difference in accuracy between the distance calculations. So, let's go with Euclidean\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4053eb",
   "metadata": {},
   "source": [
    "Final Parameters:\n",
    "\n",
    "k = 13\n",
    "\n",
    "Distance = Euclidean\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
