{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ff628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../input/questionanswer-dataset/S08_question_answer_pairs.txt', sep='\\t')\n",
    "df2 = pd.read_csv('../input/questionanswer-dataset/S09_question_answer_pairs.txt', sep='\\t')\n",
    "df3 = pd.read_csv('../input/questionanswer-dataset/S10_question_answer_pairs.txt', sep='\\t', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df1.append([df2, df3])\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Question'] = all_data['ArticleTitle'].str.replace('_', ' ') + ' ' + all_data['Question']\n",
    "all_data = all_data[['Question', 'Answer']]\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(10)[\"Question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5450e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop_duplicates(subset='Question')\n",
    "all_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.dropna()\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    \n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n",
    "    \n",
    "    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n",
    "    \n",
    "    lemmas = []\n",
    "    for w in non_punctuation:\n",
    "        if w[1].startswith('J'):\n",
    "            pos = wordnet.ADJ\n",
    "        elif w[1].startswith('V'):\n",
    "            pos = wordnet.VERB\n",
    "        elif w[1].startswith('N'):\n",
    "            pos = wordnet.NOUN\n",
    "        elif w[1].startswith('R'):\n",
    "            pos = wordnet.ADV\n",
    "        else:\n",
    "            pos = wordnet.NOUN\n",
    "        \n",
    "        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tuple(all_data['Question']))\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbad1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    query_vect = tfidf_vectorizer.transform([question])\n",
    "    similarity = cosine_similarity(query_vect, tfidf_matrix)\n",
    "    max_similarity = np.argmax(similarity, axis=None)\n",
    "    \n",
    "    print('Your question:', question)\n",
    "    print('Closest question found:', all_data.iloc[max_similarity]['Question'])\n",
    "    print('Similarity: {:.2%}'.format(similarity[0, max_similarity]))\n",
    "    print('Answer:', all_data.iloc[max_similarity]['Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question('When Abraham Lincoln started his political career')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question('Where was Nicola Tesla born')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question('Can whales fly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dab80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question('Was Alessandro Volta taught in public schools?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12659f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question('How high are crime rates in Brazil')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
