{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e232c5",
   "metadata": {},
   "source": [
    "# **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc79e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1c1c7",
   "metadata": {},
   "source": [
    "# **Reading input csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44548ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_data=pd.read_csv('/kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff740146",
   "metadata": {},
   "source": [
    "**Lets have a look at**\n",
    "\n",
    "* Shape of the dataset\n",
    "* Description\n",
    "* Columns \n",
    "* Dataypes of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c411d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7647d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cf5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91349e2",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138bfcf",
   "metadata": {},
   "source": [
    "Plotting out the distribution of Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1092667",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data['Age'],kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21138a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data['Age'].fillna(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fbc206",
   "metadata": {},
   "source": [
    "Out of 871 entries, 677 entries of Cabin are null. Hence it is better to drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Cabin'],axis=1)\n",
    "test_data = test_data.drop(['Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0a430",
   "metadata": {},
   "source": [
    "Embarked is a categorical feature which has only 2 null values. Hence the null values will be filled by calculating the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189217df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Embarked']=train_data['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66c91d",
   "metadata": {},
   "source": [
    "Converting categorical features Embarked and Sex into numerical and float variable Fare into int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Sex'] = pd.get_dummies(train_data['Sex'])\n",
    "test_data['Sex'] = pd.get_dummies(test_data['Sex'])\n",
    "train_data['Fare']=train_data['Fare'].astype('int32')\n",
    "train_data['Embarked'] = pd.factorize(train_data['Embarked'])[0]\n",
    "test_data['Embarked'] = pd.factorize(test_data['Embarked'])[0]\n",
    "test_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].mean())\n",
    "test_data['Fare']=test_data['Fare'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be7341",
   "metadata": {},
   "source": [
    "Plotting graphs to get insights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e59079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_data.corr(),annot=True,linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data['Pclass'],hue=train_data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data['Embarked'],hue=train_data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f900ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data['Age'],hue=train_data['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e90951",
   "metadata": {},
   "source": [
    "Converting Age into 5 groups as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train_data)):\n",
    "    if train_data['Age'][i] <= 15:\n",
    "        train_data['Age'][i] = 0\n",
    "    elif (train_data['Age'][i] > 15) & (train_data['Age'][i] <=35):\n",
    "        train_data['Age'][i]=1\n",
    "    elif (train_data['Age'][i] > 35) & (train_data['Age'][i] <=55):\n",
    "        train_data['Age'][i]=2\n",
    "    elif (train_data['Age'][i] > 55) & (train_data['Age'][i] <=75):\n",
    "        train_data['Age'][i]=3\n",
    "    else:\n",
    "        train_data['Age'][i]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test_data)):\n",
    "    if test_data['Age'][i] <= 15:\n",
    "        test_data['Age'][i] = 0\n",
    "    elif (test_data['Age'][i] > 15) & (test_data['Age'][i] <=26):\n",
    "        test_data['Age'][i]=1\n",
    "    elif (test_data['Age'][i] > 35) & (test_data['Age'][i] <=55):\n",
    "        test_data['Age'][i]=2\n",
    "    elif (test_data['Age'][i] > 55) & (test_data['Age'][i] <=75):\n",
    "        test_data['Age'][i]=3\n",
    "    else:\n",
    "        test_data['Age'][i]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data['Fare'],hue=train_data['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94d03b",
   "metadata": {},
   "source": [
    "Converting Fare into 3 groups based on above visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train_data)):\n",
    "    if train_data['Fare'][i] <= 50:\n",
    "        train_data['Fare'][i] = 3\n",
    "    elif (train_data['Fare'][i] > 50) & (train_data['Fare'][i] <=150 ):\n",
    "        train_data['Fare'][i]=2\n",
    "    else:\n",
    "        train_data['Fare'][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test_data)):\n",
    "    if test_data['Fare'][i] <= 50:\n",
    "        test_data['Fare'][i] = 3\n",
    "    elif (test_data['Fare'][i] > 50) & (test_data['Fare'][i] <=150 ):\n",
    "        test_data['Fare'][i]=2\n",
    "    else:\n",
    "        test_data['Fare'][i]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38dee1",
   "metadata": {},
   "source": [
    "Combining SibSp and Parch into a single feature Fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Fam'] = train_data['Parch'] + train_data['SibSp']\n",
    "test_data['Fam'] = test_data['Parch'] + test_data['SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b873dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_data['Fam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca1a26",
   "metadata": {},
   "source": [
    "Dividing Fam into 5 groups as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train_data)):\n",
    "    if train_data['Fam'][i] == 0:\n",
    "        train_data['Fam'][i] = 0\n",
    "    elif (train_data['Fam'][i] >= 1) & (train_data['Fam'][i] <=3):\n",
    "        train_data['Fam'][i]=1\n",
    "    elif (train_data['Fam'][i] >= 4) & (train_data['Fam'][i] <=6):\n",
    "        train_data['Fam'][i]=2\n",
    "    elif (train_data['Fam'][i] >= 7) & (train_data['Fam'][i] <=9):\n",
    "        train_data['Fam'][i]=3\n",
    "    else:\n",
    "        train_data['Fam'][i]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be963a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test_data)):\n",
    "    if test_data['Fam'][i] == 0:\n",
    "        test_data['Fam'][i] = 0\n",
    "    elif (test_data['Fam'][i] >= 1) & (test_data['Fam'][i] <=3):\n",
    "        test_data['Fam'][i]=1\n",
    "    elif (test_data['Fam'][i] >= 4) & (test_data['Fam'][i] <=6):\n",
    "        test_data['Fam'][i]=2\n",
    "    elif (test_data['Fam'][i] >= 7) & (test_data['Fam'][i] <=9):\n",
    "        test_data['Fam'][i]=3\n",
    "    else:\n",
    "        test_data['Fam'][i]=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a69f2",
   "metadata": {},
   "source": [
    "# **Selecting X and Y and splitting the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b86525",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[['Sex','Pclass','Age','Parch','Fam','Fare','Embarked']]\n",
    "y = train_data[['Survived']]\n",
    "X_test = test_data[['Sex','Pclass','Age','Parch','Fam','Fare','Embarked']]\n",
    "train_X , test_X , train_y , test_y = train_test_split(X,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3b5d4",
   "metadata": {},
   "source": [
    "# **Training on different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=500,max_depth=3)\n",
    "classifier.fit(train_X,train_y)\n",
    "classifier.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96328160",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xb.XGBClassifier(base_score=0.5,n_estimators=1000, learning_rate=0.05)\n",
    "xgb_model.fit(train_X, train_y, early_stopping_rounds=5, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)\n",
    "xgb_model.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78517c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_X,train_y)\n",
    "log_reg.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872f202",
   "metadata": {},
   "source": [
    "# **Making predictions and saving into output csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
