{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7f34af",
   "metadata": {},
   "source": [
    "Load data from a CSV file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ff8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3de56",
   "metadata": {},
   "source": [
    "Review the first few rows of the data to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abaad5",
   "metadata": {},
   "source": [
    "Tokenize text data into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "data['tokenized'] = data['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608334e",
   "metadata": {},
   "source": [
    "Lemmatize the words and convert them to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1699a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['lemmatized'] = data['tokenized'].apply(lambda x: [lemmatizer.lemmatize(word.lower()) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e7297",
   "metadata": {},
   "source": [
    "Convert words to sequences of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd109beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['lemmatized'])\n",
    "sequences = tokenizer.texts_to_sequences(data['lemmatized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc523a",
   "metadata": {},
   "source": [
    "Pad the sequences to ensure uniform length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences = pad_sequences(sequences, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ddf79",
   "metadata": {},
   "source": [
    "Build an embedding matrix with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d88684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_matrix = np.random.normal(size=(len(tokenizer.word_index)+1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2cdb5",
   "metadata": {},
   "source": [
    "Build a Convolutional Neural Network (CNN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, weights=[embedding_matrix]))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de6343",
   "metadata": {},
   "source": [
    "Train the CNN model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(padded_sequences, data['labels'], epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfeb598",
   "metadata": {},
   "source": [
    "Validate the model by assessing its performance on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(padded_sequences, data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef71f",
   "metadata": {},
   "source": [
    "Make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['lemmatized'])\n",
    "padded_test_sequences = pad_sequences(test_sequences, padding='post')\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c7e3d",
   "metadata": {},
   "source": [
    "Review the predicted results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "# Review the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75865ec4",
   "metadata": {},
   "source": [
    "Submit the predictions by saving them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_data['id'], 'prediction': predictions.flatten()})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
