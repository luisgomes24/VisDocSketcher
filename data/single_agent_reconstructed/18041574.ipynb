{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7c5fee",
   "metadata": {},
   "source": [
    "Load data from a CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28db985",
   "metadata": {},
   "source": [
    "Display the first few rows of the DataFrame for an overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bea19",
   "metadata": {},
   "source": [
    "Show summary information about the DataFrame including types and non-null counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5642d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2bd59",
   "metadata": {},
   "source": [
    "Check for missing values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc5793",
   "metadata": {},
   "source": [
    "Generate descriptive statistics of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bbdbe",
   "metadata": {},
   "source": [
    "Count the unique values of the 'school_type' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12850ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['school_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490ffbc",
   "metadata": {},
   "source": [
    "Count the unique values of the 'school_setting' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e47121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['school_setting'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face296a",
   "metadata": {},
   "source": [
    "Check for outliers by computing the 1st and 99th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile([0.01, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e02627",
   "metadata": {},
   "source": [
    "Remove any unwanted columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['unwanted_column'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4ed70",
   "metadata": {},
   "source": [
    "Visualize school settings using a count plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4dd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x='school_setting', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e10e7",
   "metadata": {},
   "source": [
    "Visualize teaching methods using a count plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='teaching_method', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2abb41",
   "metadata": {},
   "source": [
    "Create a boxplot for the 'pretest' scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7001651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='pretest', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878b1d7",
   "metadata": {},
   "source": [
    "Create a boxplot for the 'posttest' scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e57e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='posttest', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bf66e",
   "metadata": {},
   "source": [
    "Generate a scatter plot to see the relationship between pretest and posttest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9abc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='pretest', y='posttest', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597289f2",
   "metadata": {},
   "source": [
    "Create a KDE plot for both pretest and posttest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x='pretest', fill=True)\n",
    "sns.kdeplot(data=df, x='posttest', fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0573a38",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ec221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea9dea",
   "metadata": {},
   "source": [
    "Scale features to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791271b3",
   "metadata": {},
   "source": [
    "Train a Random Forest Regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92972c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a8160",
   "metadata": {},
   "source": [
    "Train a Decision Tree Regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5257b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb746ec",
   "metadata": {},
   "source": [
    "Evaluate model performance using Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_rf = mean_squared_error(y_test, model_rf.predict(X_test_scaled))\n",
    "mse_dt = mean_squared_error(y_test, model_dt.predict(X_test_scaled))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
