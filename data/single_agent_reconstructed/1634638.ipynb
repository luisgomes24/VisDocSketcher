{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5455ea14",
   "metadata": {},
   "source": [
    "Load the dataset from a CSV file into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35a30e",
   "metadata": {},
   "source": [
    "Get a quick overview of the dataset's structure and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8624636",
   "metadata": {},
   "source": [
    "Randomly sample 10% of the data for preliminary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f20df5",
   "metadata": {},
   "source": [
    "Clean the data by removing rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a50a6",
   "metadata": {},
   "source": [
    "Tokenize the text data to split it into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73413844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokens = word_tokenize(data_cleaned['text_column'].str.cat(sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689cd72",
   "metadata": {},
   "source": [
    "Tag each token with its corresponding part of speech (POS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "pos_tags = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35e6e7",
   "metadata": {},
   "source": [
    "Visualize the frequency of different part of speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.countplot(x=[tag for word, tag in pos_tags])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4b225",
   "metadata": {},
   "source": [
    "Remove common stopwords that don't contribute much to meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaee82a",
   "metadata": {},
   "source": [
    "Analyze word frequency distribution according to Zipf's Law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "zipf_counts = Counter(filtered_tokens)\n",
    "plt.loglog(zipf_counts.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c36faf",
   "metadata": {},
   "source": [
    "Identify the most common words in the filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb517390",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = zipf_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1e259",
   "metadata": {},
   "source": [
    "Prepare data by separating features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab640adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_cleaned.drop('target', axis=1)\n",
    "y = data_cleaned['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f751bdc",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed351c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7066e9e",
   "metadata": {},
   "source": [
    "Train a Naive Bayes model using all predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cc874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbc4dd",
   "metadata": {},
   "source": [
    "Train a Naive Bayes model specifically for job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description_model = MultinomialNB()\n",
    "job_description_model.fit(X_train['job_description'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d9cad",
   "metadata": {},
   "source": [
    "Evaluate the model's performance using accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821fb3b3",
   "metadata": {},
   "source": [
    "Identify the top indicators for predicting high/low salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab49e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_log_prob_\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883a20c",
   "metadata": {},
   "source": [
    "Summarize the outcomes and suggest further action based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Conclusion: Evaluate findings and implications based on the models trained.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
