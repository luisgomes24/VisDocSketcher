# Titanic Predictions 

## Get the Data

This Python 3 environment comes with many helpful analytics libraries installed. For example, here's several helpful packages to load:

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Read the train and test datasets
train_data = pd.read_csv("/kaggle/input/titanic/train.csv")
test_data = pd.read_csv("/kaggle/input/titanic/test.csv")

## Explore the Data

train_data.info()
test_data.info()

train_data.describe()

train_data.hist(bins=10, figsize=(20,15))

train_data.plot(kind='scatter', x='Age', y='Survived')

### Looking for Correlations

corr_matrix = train_data.corr()
corr_matrix['Survived'].sort_values(ascending=False)

# Feature Engineering
train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1
test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1

# Handle missing values
train_data['Fare'].fillna(train_data['Fare'].median(), inplace=True)
test_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)

# Gender analysis
women = train_data.loc[train_data['Sex']=='female']['Survived']
rate_women = sum(women)/len(women)

men = train_data.loc[train_data['Sex']=='male']['Survived']
rate_men = sum(men)/len(men)

# One-Hot encoding for 'Sex'
train_data.Sex = pd.get_dummies(train_data.Sex)
test_data.Sex = pd.get_dummies(test_data.Sex)

# Age processing
train_data['Age'].fillna(train_data['Age'].median(), inplace=True)
test_data['Age'].fillna(test_data['Age'].median(), inplace=True)

train_data['IsAlone'] = 0
train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1
test_data['IsAlone'] = 0
test_data.loc[test_data['FamilySize'] == 1, 'IsAlone'] = 1

train_data['Age*Class'] = train_data.Age * train_data.Pclass
test_data['Age*Class'] = test_data.Age * test_data.Pclass

# Age categorization
train_data['Age'] = pd.cut(train_data['Age'], bins=[0., 10., 25., 50, 80, np.inf], labels=[0,1,2,3,4]).astype(int)
test_data['Age'] = pd.cut(test_data['Age'], bins=[0., 10., 25., 50, 80, np.inf], labels=[0,1,2,3,4]).astype(int)

# Encoding Embarked
from sklearn.preprocessing import LabelEncoder
train_data.Embarked = train_data.Embarked.fillna('None')
test_data.Embarked = test_data.Embarked.fillna('None')

label_encoder = LabelEncoder()
train_data.Embarked = label_encoder.fit_transform(train_data.Embarked)
test_data.Embarked = label_encoder.transform(test_data.Embarked)

# Prepare data for modeling
features = ["Pclass", "Sex", "Fare", "SibSp", "Parch", "FamilySize", "Embarked", "IsAlone"]
X = train_data[features]
y = train_data["Survived"]
X_test = test_data[features]

## Modelling
# Random Forest
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier()

rf_params = {
    'bootstrap': [True, False],
    'max_depth': [10, None],
    'max_features': ['auto', 'sqrt'],
    'min_samples_leaf': [1, 2, 4],
    'min_samples_split': [2, 5, 10],
    'n_estimators': [100]
}

from sklearn.model_selection import GridSearchCV
rf_gs = GridSearchCV(rf_model, rf_params, scoring='f1', cv=8, n_jobs=4)

rf_gs.fit(X, y)

# Predictions
predictions = rf_gs.predict(X_test)

# Output submission file
output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})
output.to_csv('my_submission.csv', index=False)