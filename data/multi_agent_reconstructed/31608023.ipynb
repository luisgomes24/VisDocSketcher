{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05e28b4",
   "metadata": {},
   "source": [
    "Load the CSV files into DataFrames using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "sample_submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472d33a",
   "metadata": {},
   "source": [
    "Initialize the tokenizer and fit it on the training text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b60def",
   "metadata": {},
   "source": [
    "Convert the test text data to sequences using the fitted tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c620d",
   "metadata": {},
   "source": [
    "Pad the test sequences to ensure uniform input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 100  # Define maximum length\n",
    "\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2317b",
   "metadata": {},
   "source": [
    "Create a random embedding matrix for the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, 100)  # Random embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43727c69",
   "metadata": {},
   "source": [
    "Convert training labels to categorical format for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c680a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels_categorical = to_categorical(train_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888764a",
   "metadata": {},
   "source": [
    "Define the CNN model structure with an embedding layer and convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa27ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(units=len(train_df['label'].unique()), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f0caf",
   "metadata": {},
   "source": [
    "Compile the model with appropriate loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d867df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f896b66",
   "metadata": {},
   "source": [
    "Train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe06e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, train_labels_categorical, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d98697",
   "metadata": {},
   "source": [
    "Make predictions on the padded test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98059f82",
   "metadata": {},
   "source": [
    "Convert predicted probabilities to class labels using argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.argmax(predicted_labels, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
