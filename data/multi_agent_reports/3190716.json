{"data_sources": [],"data_variables": [{"name": "X","description": "Input data with shape (2, number of examples)."},{"name": "Y","description": "True label vector, shape (1, number of examples)."},{"name": "layers_dims","description": "List containing the size of each layer in the neural network."},{"name": "learning_rate","description": "Learning rate for the optimization algorithm."},{"name": "mini_batch_size","description": "Number of examples to consider in each mini-batch during training."},{"name": "beta","description": "Momentum hyperparameter for optimizers."},{"name": "beta1","description": "Exponential decay hyperparameter for past gradients estimates in Adam."},{"name": "beta2","description": "Exponential decay hyperparameter for past squared gradients estimates in Adam."},{"name": "epsilon","description": "Small constant to prevent division by zero in Adam updates."},{"name": "num_epochs","description": "Total number of iterations for training."},{"name": "print_cost","description": "Boolean flag to print cost during training."},{"name": "parameters","description": "Dictionary containing the neural network parameters after optimization."},{"name": "costs","description": "List to track the cost at each epoch."},{"name": "minibatches","description": "List of mini-batches created from X and Y for training."},{"name": "caches","description": "Contains intermediate values computed in forward propagation."}],"data_flow": [{"variable": "X","creation": "Input data provided to the model function.","flow": "Used in forward propagation during model training."},{"variable": "Y","creation": "True label vector provided to the model function.","flow": "Used in cost computation and backward propagation."},{"variable": "layers_dims","creation": "Defined as an argument in the model function.","flow": "Used in parameter initialization and layer definition."},{"variable": "costs","creation": "Initialized as an empty list.","flow": "Populated during model training to keep track of cost values."},{"variable": "parameters","creation": "Initialized by calling initialize_parameters with layers_dims.","flow": "Updated during parameter optimization and returned by the model."},{"variable": "caches","creation": "Created during the forward propagation step.","flow": "Used in backward propagation to calculate gradients."},{"variable": "minibatches","creation": "Generated from random_mini_batches function.","flow": "Iterated over for parameter updates during training."}],"models": [{"model_type": "3-layer Neural Network","input_features": "Two input features from X.","target_variable": "Y (labels for classification).","hyperparameters": {"learning_rate": "0.0007","mini_batch_size": "64","beta": "0.9","beta1": "0.9","beta2": "0.999","epsilon": "1e-8","num_epochs": "10000"}}]}